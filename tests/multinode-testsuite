#! /bin/sh
# Generated from multinode-testsuite.at by GNU Autoconf 2.71.
#
# Copyright (C) 2009-2017, 2020-2021 Free Software Foundation, Inc.
#
# This test suite is free software; the Free Software Foundation gives
# unlimited permission to copy, distribute and modify it.
#
# Copyright (c) 2022 Red Hat,
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at:
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
## -------------------- ##
## M4sh Initialization. ##
## -------------------- ##

# Be more Bourne compatible
DUALCASE=1; export DUALCASE # for MKS sh
as_nop=:
if test ${ZSH_VERSION+y} && (emulate sh) >/dev/null 2>&1
then :
  emulate sh
  NULLCMD=:
  # Pre-4.2 versions of Zsh do word splitting on ${1+"$@"}, which
  # is contrary to our usage.  Disable this feature.
  alias -g '${1+"$@"}'='"$@"'
  setopt NO_GLOB_SUBST
else $as_nop
  case `(set -o) 2>/dev/null` in #(
  *posix*) :
    set -o posix ;; #(
  *) :
     ;;
esac
fi



# Reset variables that may have inherited troublesome values from
# the environment.

# IFS needs to be set, to space, tab, and newline, in precisely that order.
# (If _AS_PATH_WALK were called with IFS unset, it would have the
# side effect of setting IFS to empty, thus disabling word splitting.)
# Quoting is to prevent editors from complaining about space-tab.
as_nl='
'
export as_nl
IFS=" ""	$as_nl"

PS1='$ '
PS2='> '
PS4='+ '

# Ensure predictable behavior from utilities with locale-dependent output.
LC_ALL=C
export LC_ALL
LANGUAGE=C
export LANGUAGE

# We cannot yet rely on "unset" to work, but we need these variables
# to be unset--not just set to an empty or harmless value--now, to
# avoid bugs in old shells (e.g. pre-3.0 UWIN ksh).  This construct
# also avoids known problems related to "unset" and subshell syntax
# in other old shells (e.g. bash 2.01 and pdksh 5.2.14).
for as_var in BASH_ENV ENV MAIL MAILPATH CDPATH
do eval test \${$as_var+y} \
  && ( (unset $as_var) || exit 1) >/dev/null 2>&1 && unset $as_var || :
done

# Ensure that fds 0, 1, and 2 are open.
if (exec 3>&0) 2>/dev/null; then :; else exec 0</dev/null; fi
if (exec 3>&1) 2>/dev/null; then :; else exec 1>/dev/null; fi
if (exec 3>&2)            ; then :; else exec 2>/dev/null; fi

# The user is always right.
if ${PATH_SEPARATOR+false} :; then
  PATH_SEPARATOR=:
  (PATH='/bin;/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 && {
    (PATH='/bin:/bin'; FPATH=$PATH; sh -c :) >/dev/null 2>&1 ||
      PATH_SEPARATOR=';'
  }
fi


# Find who we are.  Look in the path if we contain no directory separator.
as_myself=
case $0 in #((
  *[\\/]* ) as_myself=$0 ;;
  *) as_save_IFS=$IFS; IFS=$PATH_SEPARATOR
for as_dir in $PATH
do
  IFS=$as_save_IFS
  case $as_dir in #(((
    '') as_dir=./ ;;
    */) ;;
    *) as_dir=$as_dir/ ;;
  esac
    test -r "$as_dir$0" && as_myself=$as_dir$0 && break
  done
IFS=$as_save_IFS

     ;;
esac
# We did not find ourselves, most probably we were run as `sh COMMAND'
# in which case we are not to be found in the path.
if test "x$as_myself" = x; then
  as_myself=$0
fi
if test ! -f "$as_myself"; then
  printf "%s\n" "$as_myself: error: cannot find myself; rerun with an absolute file name" >&2
  exit 1
fi


if test "x$CONFIG_SHELL" = x; then
  as_bourne_compatible="as_nop=:
if test \${ZSH_VERSION+y} && (emulate sh) >/dev/null 2>&1
then :
  emulate sh
  NULLCMD=:
  # Pre-4.2 versions of Zsh do word splitting on \${1+\"\$@\"}, which
  # is contrary to our usage.  Disable this feature.
  alias -g '\${1+\"\$@\"}'='\"\$@\"'
  setopt NO_GLOB_SUBST
else \$as_nop
  case \`(set -o) 2>/dev/null\` in #(
  *posix*) :
    set -o posix ;; #(
  *) :
     ;;
esac
fi
"
  as_required="as_fn_return () { (exit \$1); }
as_fn_success () { as_fn_return 0; }
as_fn_failure () { as_fn_return 1; }
as_fn_ret_success () { return 0; }
as_fn_ret_failure () { return 1; }

exitcode=0
as_fn_success || { exitcode=1; echo as_fn_success failed.; }
as_fn_failure && { exitcode=1; echo as_fn_failure succeeded.; }
as_fn_ret_success || { exitcode=1; echo as_fn_ret_success failed.; }
as_fn_ret_failure && { exitcode=1; echo as_fn_ret_failure succeeded.; }
if ( set x; as_fn_ret_success y && test x = \"\$1\" )
then :

else \$as_nop
  exitcode=1; echo positional parameters were not saved.
fi
test x\$exitcode = x0 || exit 1
blah=\$(echo \$(echo blah))
test x\"\$blah\" = xblah || exit 1
test -x / || exit 1"
  as_suggested="  as_lineno_1=";as_suggested=$as_suggested$LINENO;as_suggested=$as_suggested" as_lineno_1a=\$LINENO
  as_lineno_2=";as_suggested=$as_suggested$LINENO;as_suggested=$as_suggested" as_lineno_2a=\$LINENO
  eval 'test \"x\$as_lineno_1'\$as_run'\" != \"x\$as_lineno_2'\$as_run'\" &&
  test \"x\`expr \$as_lineno_1'\$as_run' + 1\`\" = \"x\$as_lineno_2'\$as_run'\"' || exit 1
test \$(( 1 + 1 )) = 2 || exit 1"
  if (eval "$as_required") 2>/dev/null
then :
  as_have_required=yes
else $as_nop
  as_have_required=no
fi
  if test x$as_have_required = xyes && (eval "$as_suggested") 2>/dev/null
then :

else $as_nop
  as_save_IFS=$IFS; IFS=$PATH_SEPARATOR
as_found=false
for as_dir in /bin$PATH_SEPARATOR/usr/bin$PATH_SEPARATOR$PATH
do
  IFS=$as_save_IFS
  case $as_dir in #(((
    '') as_dir=./ ;;
    */) ;;
    *) as_dir=$as_dir/ ;;
  esac
  as_found=:
  case $as_dir in #(
   /*)
     for as_base in sh bash ksh sh5; do
       # Try only shells that exist, to save several forks.
       as_shell=$as_dir$as_base
       if { test -f "$as_shell" || test -f "$as_shell.exe"; } &&
        as_run=a "$as_shell" -c "$as_bourne_compatible""$as_required" 2>/dev/null
then :
  CONFIG_SHELL=$as_shell as_have_required=yes
       if as_run=a "$as_shell" -c "$as_bourne_compatible""$as_suggested" 2>/dev/null
then :
  break 2
fi
fi
     done;;
       esac
  as_found=false
done
IFS=$as_save_IFS
if $as_found
then :

else $as_nop
  if { test -f "$SHELL" || test -f "$SHELL.exe"; } &&
        as_run=a "$SHELL" -c "$as_bourne_compatible""$as_required" 2>/dev/null
then :
  CONFIG_SHELL=$SHELL as_have_required=yes
fi
fi


      if test "x$CONFIG_SHELL" != x
then :
  export CONFIG_SHELL
             # We cannot yet assume a decent shell, so we have to provide a
# neutralization value for shells without unset; and this also
# works around shells that cannot unset nonexistent variables.
# Preserve -v and -x to the replacement shell.
BASH_ENV=/dev/null
ENV=/dev/null
(unset BASH_ENV) >/dev/null 2>&1 && unset BASH_ENV ENV
case $- in # ((((
  *v*x* | *x*v* ) as_opts=-vx ;;
  *v* ) as_opts=-v ;;
  *x* ) as_opts=-x ;;
  * ) as_opts= ;;
esac
exec $CONFIG_SHELL $as_opts "$as_myself" ${1+"$@"}
# Admittedly, this is quite paranoid, since all the known shells bail
# out after a failed `exec'.
printf "%s\n" "$0: could not re-execute with $CONFIG_SHELL" >&2
exit 255
fi

    if test x$as_have_required = xno
then :
  printf "%s\n" "$0: This script requires a shell more modern than all"
  printf "%s\n" "$0: the shells that I found on your system."
  if test ${ZSH_VERSION+y} ; then
    printf "%s\n" "$0: In particular, zsh $ZSH_VERSION has bugs and should"
    printf "%s\n" "$0: be upgraded to zsh 4.3.4 or later."
  else
    printf "%s\n" "$0: Please tell bug-autoconf@gnu.org about your system,
$0: including any error possibly output before this
$0: message. Then install a modern shell, or manually run
$0: the script under such a shell if you do have one."
  fi
  exit 1
fi
fi
fi
SHELL=${CONFIG_SHELL-/bin/sh}
export SHELL
# Unset more variables known to interfere with behavior of common tools.
CLICOLOR_FORCE= GREP_OPTIONS=
unset CLICOLOR_FORCE GREP_OPTIONS

## --------------------- ##
## M4sh Shell Functions. ##
## --------------------- ##
# as_fn_unset VAR
# ---------------
# Portably unset VAR.
as_fn_unset ()
{
  { eval $1=; unset $1;}
}
as_unset=as_fn_unset


# as_fn_set_status STATUS
# -----------------------
# Set $? to STATUS, without forking.
as_fn_set_status ()
{
  return $1
} # as_fn_set_status

# as_fn_exit STATUS
# -----------------
# Exit the shell with STATUS, even in a "trap 0" or "set -e" context.
as_fn_exit ()
{
  set +e
  as_fn_set_status $1
  exit $1
} # as_fn_exit
# as_fn_nop
# ---------
# Do nothing but, unlike ":", preserve the value of $?.
as_fn_nop ()
{
  return $?
}
as_nop=as_fn_nop

# as_fn_mkdir_p
# -------------
# Create "$as_dir" as a directory, including parents if necessary.
as_fn_mkdir_p ()
{

  case $as_dir in #(
  -*) as_dir=./$as_dir;;
  esac
  test -d "$as_dir" || eval $as_mkdir_p || {
    as_dirs=
    while :; do
      case $as_dir in #(
      *\'*) as_qdir=`printf "%s\n" "$as_dir" | sed "s/'/'\\\\\\\\''/g"`;; #'(
      *) as_qdir=$as_dir;;
      esac
      as_dirs="'$as_qdir' $as_dirs"
      as_dir=`$as_dirname -- "$as_dir" ||
$as_expr X"$as_dir" : 'X\(.*[^/]\)//*[^/][^/]*/*$' \| \
   X"$as_dir" : 'X\(//\)[^/]' \| \
   X"$as_dir" : 'X\(//\)$' \| \
   X"$as_dir" : 'X\(/\)' \| . 2>/dev/null ||
printf "%s\n" X"$as_dir" |
    sed '/^X\(.*[^/]\)\/\/*[^/][^/]*\/*$/{
      s//\1/
      q
    }
    /^X\(\/\/\)[^/].*/{
      s//\1/
      q
    }
    /^X\(\/\/\)$/{
      s//\1/
      q
    }
    /^X\(\/\).*/{
      s//\1/
      q
    }
    s/.*/./; q'`
      test -d "$as_dir" && break
    done
    test -z "$as_dirs" || eval "mkdir $as_dirs"
  } || test -d "$as_dir" || as_fn_error $? "cannot create directory $as_dir"


} # as_fn_mkdir_p

# as_fn_executable_p FILE
# -----------------------
# Test if FILE is an executable regular file.
as_fn_executable_p ()
{
  test -f "$1" && test -x "$1"
} # as_fn_executable_p
# as_fn_append VAR VALUE
# ----------------------
# Append the text in VALUE to the end of the definition contained in VAR. Take
# advantage of any shell optimizations that allow amortized linear growth over
# repeated appends, instead of the typical quadratic growth present in naive
# implementations.
if (eval "as_var=1; as_var+=2; test x\$as_var = x12") 2>/dev/null
then :
  eval 'as_fn_append ()
  {
    eval $1+=\$2
  }'
else $as_nop
  as_fn_append ()
  {
    eval $1=\$$1\$2
  }
fi # as_fn_append

# as_fn_arith ARG...
# ------------------
# Perform arithmetic evaluation on the ARGs, and store the result in the
# global $as_val. Take advantage of shells that can avoid forks. The arguments
# must be portable across $(()) and expr.
if (eval "test \$(( 1 + 1 )) = 2") 2>/dev/null
then :
  eval 'as_fn_arith ()
  {
    as_val=$(( $* ))
  }'
else $as_nop
  as_fn_arith ()
  {
    as_val=`expr "$@" || test $? -eq 1`
  }
fi # as_fn_arith


# as_fn_error STATUS ERROR [LINENO LOG_FD]
# ----------------------------------------
# Output "`basename $0`: error: ERROR" to stderr. If LINENO and LOG_FD are
# provided, also output the error to LOG_FD, referencing LINENO. Then exit the
# script with STATUS, using 1 if that was 0.
as_fn_error ()
{
  as_status=$1; test $as_status -eq 0 && as_status=1
  if test "$4"; then
    as_lineno=${as_lineno-"$3"} as_lineno_stack=as_lineno_stack=$as_lineno_stack
    printf "%s\n" "$as_me:${as_lineno-$LINENO}: error: $2" >&$4
  fi
  printf "%s\n" "$as_me: error: $2" >&2
  as_fn_exit $as_status
} # as_fn_error

if expr a : '\(a\)' >/dev/null 2>&1 &&
   test "X`expr 00001 : '.*\(...\)'`" = X001; then
  as_expr=expr
else
  as_expr=false
fi

if (basename -- /) >/dev/null 2>&1 && test "X`basename -- / 2>&1`" = "X/"; then
  as_basename=basename
else
  as_basename=false
fi

as_me=`$as_basename -- "$0" ||
$as_expr X/"$0" : '.*/\([^/][^/]*\)/*$' \| \
   X"$0" : 'X\(//\)$' \| \
   X"$0" : 'X\(/\)' \| . 2>/dev/null ||
printf "%s\n" X/"$0" |
    sed '/^.*\/\([^/][^/]*\)\/*$/{
      s//\1/
      q
    }
    /^X\/\(\/\/\)$/{
      s//\1/
      q
    }
    /^X\/\(\/\).*/{
      s//\1/
      q
    }
    s/.*/./; q'`

if (as_dir=`dirname -- /` && test "X$as_dir" = X/) >/dev/null 2>&1; then
  as_dirname=dirname
else
  as_dirname=false
fi

# Avoid depending upon Character Ranges.
as_cr_letters='abcdefghijklmnopqrstuvwxyz'
as_cr_LETTERS='ABCDEFGHIJKLMNOPQRSTUVWXYZ'
as_cr_Letters=$as_cr_letters$as_cr_LETTERS
as_cr_digits='0123456789'
as_cr_alnum=$as_cr_Letters$as_cr_digits


  as_lineno_1=$LINENO as_lineno_1a=$LINENO
  as_lineno_2=$LINENO as_lineno_2a=$LINENO
  eval 'test "x$as_lineno_1'$as_run'" != "x$as_lineno_2'$as_run'" &&
  test "x`expr $as_lineno_1'$as_run' + 1`" = "x$as_lineno_2'$as_run'"' || {
  # Blame Lee E. McMahon (1931-1989) for sed's syntax.  :-)
  sed -n '
    p
    /[$]LINENO/=
  ' <$as_myself |
    sed '
      s/[$]LINENO.*/&-/
      t lineno
      b
      :lineno
      N
      :loop
      s/[$]LINENO\([^'$as_cr_alnum'_].*\n\)\(.*\)/\2\1\2/
      t loop
      s/-\n.*//
    ' >$as_me.lineno &&
  chmod +x "$as_me.lineno" ||
    { printf "%s\n" "$as_me: error: cannot create $as_me.lineno; rerun with a POSIX shell" >&2; as_fn_exit 1; }

  # If we had to re-execute with $CONFIG_SHELL, we're ensured to have
  # already done that, so ensure we don't try to do so again and fall
  # in an infinite loop.  This has already happened in practice.
  _as_can_reexec=no; export _as_can_reexec
  # Don't try to exec as it changes $[0], causing all sort of problems
  # (the dirname of $[0] is not the place where we might find the
  # original and so on.  Autoconf is especially sensitive to this).
  . "./$as_me.lineno"
  # Exit status is that of the last command.
  exit
}


# Determine whether it's possible to make 'echo' print without a newline.
# These variables are no longer used directly by Autoconf, but are AC_SUBSTed
# for compatibility with existing Makefiles.
ECHO_C= ECHO_N= ECHO_T=
case `printf -n x` in #(((((
-n*)
  case `echo 'xy\c'` in
  *c*) ECHO_T='	';;	# ECHO_T is single tab character.
  xy)  ECHO_C='\c';;
  *)   echo `echo ksh88 bug on AIX 6.1` > /dev/null
       ECHO_T='	';;
  esac;;
*)
  ECHO_N='-n';;
esac

# For backward compatibility with old third-party macros, we provide
# the shell variables $as_echo and $as_echo_n.  New code should use
# AS_ECHO(["message"]) and AS_ECHO_N(["message"]), respectively.
as_echo='printf %s\n'
as_echo_n='printf %s'


rm -f conf$$ conf$$.exe conf$$.file
if test -d conf$$.dir; then
  rm -f conf$$.dir/conf$$.file
else
  rm -f conf$$.dir
  mkdir conf$$.dir 2>/dev/null
fi
if (echo >conf$$.file) 2>/dev/null; then
  if ln -s conf$$.file conf$$ 2>/dev/null; then
    as_ln_s='ln -s'
    # ... but there are two gotchas:
    # 1) On MSYS, both `ln -s file dir' and `ln file dir' fail.
    # 2) DJGPP < 2.04 has no symlinks; `ln -s' creates a wrapper executable.
    # In both cases, we have to default to `cp -pR'.
    ln -s conf$$.file conf$$.dir 2>/dev/null && test ! -f conf$$.exe ||
      as_ln_s='cp -pR'
  elif ln conf$$.file conf$$ 2>/dev/null; then
    as_ln_s=ln
  else
    as_ln_s='cp -pR'
  fi
else
  as_ln_s='cp -pR'
fi
rm -f conf$$ conf$$.exe conf$$.dir/conf$$.file conf$$.file
rmdir conf$$.dir 2>/dev/null

if mkdir -p . 2>/dev/null; then
  as_mkdir_p='mkdir -p "$as_dir"'
else
  test -d ./-p && rmdir ./-p
  as_mkdir_p=false
fi

as_test_x='test -x'
as_executable_p=as_fn_executable_p

# Sed expression to map a string onto a valid CPP name.
as_tr_cpp="eval sed 'y%*$as_cr_letters%P$as_cr_LETTERS%;s%[^_$as_cr_alnum]%_%g'"

# Sed expression to map a string onto a valid variable name.
as_tr_sh="eval sed 'y%*+%pp%;s%[^_$as_cr_alnum]%_%g'"





SHELL=${CONFIG_SHELL-/bin/sh}

# How were we run?
at_cli_args="$@"


# Not all shells have the 'times' builtin; the subshell is needed to make
# sure we discard the 'times: not found' message from the shell.
at_times_p=false
(times) >/dev/null 2>&1 && at_times_p=:

# CLI Arguments to pass to the debugging scripts.
at_debug_args=
# -e sets to true
at_errexit_p=false
# Shall we be verbose?  ':' means no, empty means yes.
at_verbose=:
at_quiet=
# Running several jobs in parallel, 0 means as many as test groups.
at_jobs=1
at_traceon=:
at_trace_echo=:
at_check_filter_trace=:

# Shall we keep the debug scripts?  Must be `:' when the suite is
# run by a debug script, so that the script doesn't remove itself.
at_debug_p=false
# Display help message?
at_help_p=false
# Display the version message?
at_version_p=false
# List test groups?
at_list_p=false
# --clean
at_clean=false
# Test groups to run
at_groups=
# Whether to rerun failed tests.
at_recheck=
# Whether a write failure occurred
at_write_fail=0

# The directory we run the suite in.  Default to . if no -C option.
at_dir=`pwd`
# An absolute reference to this testsuite script.
case $as_myself in
  [\\/]* | ?:[\\/]* ) at_myself=$as_myself ;;
  * ) at_myself=$at_dir/$as_myself ;;
esac
# Whether -C is in effect.
at_change_dir=false

# Whether to enable colored test results.
at_color=auto
# As many question marks as there are digits in the last test group number.
# Used to normalize the test group numbers so that `ls' lists them in
# numerical order.
at_format='?'
# Description of all the test groups.
at_help_all="1;multinode.at:3;ovn multinode basic test;;
"
# List of the all the test groups.
at_groups_all=`printf "%s\n" "$at_help_all" | sed 's/;.*//'`

# at_fn_validate_ranges NAME...
# -----------------------------
# Validate and normalize the test group number contained in each variable
# NAME. Leading zeroes are treated as decimal.
at_fn_validate_ranges ()
{
  for at_grp
  do
    eval at_value=\$$at_grp
    if test $at_value -lt 1 || test $at_value -gt 1; then
      printf "%s\n" "invalid test group: $at_value" >&2
      exit 1
    fi
    case $at_value in
      0*) # We want to treat leading 0 as decimal, like expr and test, but
    # AS_VAR_ARITH treats it as octal if it uses $(( )).
    # With XSI shells, ${at_value#${at_value%%[1-9]*}} avoids the
    # expr fork, but it is not worth the effort to determine if the
    # shell supports XSI when the user can just avoid leading 0.
    eval $at_grp='`expr $at_value + 0`' ;;
    esac
  done
}
# List of the tested programs.
at_tested='"ovs-vswitchd"
"ovs-vsctl"'


##
## Set up package specific options.
##

at_arg_rebuild=false
at_arg_given_rebuild=false


at_prev=
for at_option
do
  # If the previous option needs an argument, assign it.
  if test -n "$at_prev"; then
    at_option=$at_prev=$at_option
    at_prev=
  fi

  case $at_option in
  *=?*) at_optarg=`expr "X$at_option" : '[^=]*=\(.*\)'` ;;
  *)    at_optarg= ;;
  esac

  case $at_option in
    --help | -h )
  at_help_p=:
  ;;

    --list | -l )
  at_list_p=:
  ;;

    --version | -V )
  at_version_p=:
  ;;

    --clean | -c )
  at_clean=:
  ;;

    --color )
  at_color=always
  ;;
    --color=* )
  case $at_optarg in
  no | never | none) at_color=never ;;
  auto | tty | if-tty) at_color=auto ;;
  always | yes | force) at_color=always ;;
  *) at_optname=`echo " $at_option" | sed 's/^ //; s/=.*//'`
     as_fn_error $? "unrecognized argument to $at_optname: $at_optarg" ;;
  esac
  ;;

    --debug | -d )
  at_debug_p=:
  ;;

    --errexit | -e )
  at_debug_p=:
  at_errexit_p=:
  ;;

    --verbose | -v )
  at_verbose=; at_quiet=:
  ;;

    --trace | -x )
  at_traceon='set -x'
  at_trace_echo=echo
  at_check_filter_trace=at_fn_filter_trace
  ;;

    [0-9] | [0-9][0-9] | [0-9][0-9][0-9] | [0-9][0-9][0-9][0-9])
  at_fn_validate_ranges at_option
  as_fn_append at_groups "$at_option$as_nl"
  ;;

    # Ranges
    [0-9]- | [0-9][0-9]- | [0-9][0-9][0-9]- | [0-9][0-9][0-9][0-9]-)
  at_range_start=`echo $at_option |tr -d X-`
  at_fn_validate_ranges at_range_start
  at_range=`printf "%s\n" "$at_groups_all" | \
    sed -ne '/^'$at_range_start'$/,$p'`
  as_fn_append at_groups "$at_range$as_nl"
  ;;

    -[0-9] | -[0-9][0-9] | -[0-9][0-9][0-9] | -[0-9][0-9][0-9][0-9])
  at_range_end=`echo $at_option |tr -d X-`
  at_fn_validate_ranges at_range_end
  at_range=`printf "%s\n" "$at_groups_all" | \
    sed -ne '1,/^'$at_range_end'$/p'`
  as_fn_append at_groups "$at_range$as_nl"
  ;;

    [0-9]-[0-9] | [0-9]-[0-9][0-9] | [0-9]-[0-9][0-9][0-9] | \
    [0-9]-[0-9][0-9][0-9][0-9] | [0-9][0-9]-[0-9][0-9] | \
    [0-9][0-9]-[0-9][0-9][0-9] | [0-9][0-9]-[0-9][0-9][0-9][0-9] | \
    [0-9][0-9][0-9]-[0-9][0-9][0-9] | \
    [0-9][0-9][0-9]-[0-9][0-9][0-9][0-9] | \
    [0-9][0-9][0-9][0-9]-[0-9][0-9][0-9][0-9] )
  at_range_start=`expr $at_option : '\(.*\)-'`
  at_range_end=`expr $at_option : '.*-\(.*\)'`
  if test $at_range_start -gt $at_range_end; then
    at_tmp=$at_range_end
    at_range_end=$at_range_start
    at_range_start=$at_tmp
  fi
  at_fn_validate_ranges at_range_start at_range_end
  at_range=`printf "%s\n" "$at_groups_all" | \
    sed -ne '/^'$at_range_start'$/,/^'$at_range_end'$/p'`
  as_fn_append at_groups "$at_range$as_nl"
  ;;

    # Directory selection.
    --directory | -C )
  at_prev=--directory
  ;;
    --directory=* )
  at_change_dir=:
  at_dir=$at_optarg
  if test x- = "x$at_dir" ; then
    at_dir=./-
  fi
  ;;

    # Parallel execution.
    --jobs | -j )
  at_jobs=0
  ;;
    --jobs=* | -j[0-9]* )
  if test -n "$at_optarg"; then
    at_jobs=$at_optarg
  else
    at_jobs=`expr X$at_option : 'X-j\(.*\)'`
  fi
  case $at_jobs in *[!0-9]*)
    at_optname=`echo " $at_option" | sed 's/^ //; s/[0-9=].*//'`
    as_fn_error $? "non-numeric argument to $at_optname: $at_jobs" ;;
  esac
  ;;

    # Keywords.
    --keywords | -k )
  at_prev=--keywords
  ;;
    --keywords=* )
  at_groups_selected=$at_help_all
  at_save_IFS=$IFS
  IFS=,
  set X $at_optarg
  shift
  IFS=$at_save_IFS
  for at_keyword
  do
    at_invert=
    case $at_keyword in
    '!'*)
      at_invert="-v"
      at_keyword=`expr "X$at_keyword" : 'X!\(.*\)'`
      ;;
    esac
    # It is on purpose that we match the test group titles too.
    at_groups_selected=`printf "%s\n" "$at_groups_selected" |
        grep -i $at_invert "^[1-9][^;]*;.*[; ]$at_keyword[ ;]"`
  done
  # Smash the keywords.
  at_groups_selected=`printf "%s\n" "$at_groups_selected" | sed 's/;.*//'`
  as_fn_append at_groups "$at_groups_selected$as_nl"
  ;;
    --recheck)
  at_recheck=:
  ;;
    --rebuild )
  at_optarg=:
  at_arg_rebuild=:
  at_arg_given_rebuild=:
    ;;
    --no-rebuild )
  at_optarg=false
  at_arg_rebuild=false
  at_arg_given_rebuild=:
    ;;


    *=*)
  at_envvar=`expr "x$at_option" : 'x\([^=]*\)='`
  # Reject names that are not valid shell variable names.
  case $at_envvar in
    '' | [0-9]* | *[!_$as_cr_alnum]* )
      as_fn_error $? "invalid variable name: \`$at_envvar'" ;;
  esac
  at_value=`printf "%s\n" "$at_optarg" | sed "s/'/'\\\\\\\\''/g"`
  # Export now, but save eval for later and for debug scripts.
  export $at_envvar
  as_fn_append at_debug_args " $at_envvar='$at_value'"
  ;;

     *) printf "%s\n" "$as_me: invalid option: $at_option" >&2
  printf "%s\n" "Try \`$0 --help' for more information." >&2
  exit 1
  ;;
  esac
done

# Verify our last option didn't require an argument
if test -n "$at_prev"
then :
  as_fn_error $? "\`$at_prev' requires an argument"
fi

# The file containing the suite.
at_suite_log=$at_dir/$as_me.log

# Selected test groups.
if test -z "$at_groups$at_recheck"; then
  at_groups=$at_groups_all
else
  if test -n "$at_recheck" && test -r "$at_suite_log"; then
    at_oldfails=`sed -n '
      /^Failed tests:$/,/^Skipped tests:$/{
  s/^[ ]*\([1-9][0-9]*\):.*/\1/p
      }
      /^Unexpected passes:$/,/^## Detailed failed tests/{
  s/^[ ]*\([1-9][0-9]*\):.*/\1/p
      }
      /^## Detailed failed tests/q
      ' "$at_suite_log"`
    as_fn_append at_groups "$at_oldfails$as_nl"
  fi
  # Sort the tests, removing duplicates.
  at_groups=`printf "%s\n" "$at_groups" | sort -nu | sed '/^$/d'`
fi

if test x"$at_color" = xalways \
   || { test x"$at_color" = xauto && test -t 1; }; then
  at_red=`printf '\033[0;31m'`
  at_grn=`printf '\033[0;32m'`
  at_lgn=`printf '\033[1;32m'`
  at_blu=`printf '\033[1;34m'`
  at_std=`printf '\033[m'`
else
  at_red= at_grn= at_lgn= at_blu= at_std=
fi

# Help message.
if $at_help_p; then
  cat <<_ATEOF || at_write_fail=1
Usage: $0 [OPTION]... [VARIABLE=VALUE]... [TESTS]

Run all the tests, or the selected TESTS, given by numeric ranges, and
save a detailed log file.  Upon failure, create debugging scripts.

Do not change environment variables directly.  Instead, set them via
command line arguments.  Set \`AUTOTEST_PATH' to select the executables
to exercise.  Each relative directory is expanded as build and source
directories relative to the top level of this distribution.
E.g., from within the build directory /tmp/foo-1.0, invoking this:

  $ $0 AUTOTEST_PATH=bin

is equivalent to the following, assuming the source directory is /src/foo-1.0:

  PATH=/tmp/foo-1.0/bin:/src/foo-1.0/bin:\$PATH $0
_ATEOF
cat <<_ATEOF || at_write_fail=1

Operation modes:
  -h, --help     print the help message, then exit
  -V, --version  print version number, then exit
  -c, --clean    remove all the files this test suite might create and exit
  -l, --list     describes all the tests, or the selected TESTS
_ATEOF
cat <<_ATEOF || at_write_fail=1

Execution tuning:
  -C, --directory=DIR
                 change to directory DIR before starting
      --color[=never|auto|always]
                 disable colored test results, or enable even without terminal
  -j, --jobs[=N]
                 Allow N jobs at once; infinite jobs with no arg (default 1)
  -k, --keywords=KEYWORDS
                 select the tests matching all the comma-separated KEYWORDS
                 multiple \`-k' accumulate; prefixed \`!' negates a KEYWORD
      --recheck  select all tests that failed or passed unexpectedly last time
  -e, --errexit  abort as soon as a test fails; implies --debug
  -v, --verbose  force more detailed output
                 default for debugging scripts
  -d, --debug    inhibit clean up and top-level logging
                 default for debugging scripts
  -x, --trace    enable tests shell tracing
_ATEOF
cat <<_ATEOF || at_write_fail=1

Other options:
_ATEOF

cat <<_ATEOF || at_write_fail=1
Do not use cached versions of databases
_ATEOF
cat <<_ATEOF || at_write_fail=1

Report bugs to <bugs@openvswitch.org>.
_ATEOF
  exit $at_write_fail
fi

# List of tests.
if $at_list_p; then
  cat <<_ATEOF || at_write_fail=1
ovn 23.06.90 test suite test groups:

 NUM: FILE-NAME:LINE     TEST-GROUP-NAME
      KEYWORDS

_ATEOF
  # Pass an empty line as separator between selected groups and help.
  printf "%s\n" "$at_groups$as_nl$as_nl$at_help_all" |
    awk 'NF == 1 && FS != ";" {
     selected[$ 1] = 1
     next
   }
   /^$/ { FS = ";" }
   NF > 0 {
     if (selected[$ 1]) {
       printf " %3d: %-18s %s\n", $ 1, $ 2, $ 3
       if ($ 4) {
         lmax = 79
         indent = "     "
         line = indent
         len = length (line)
         n = split ($ 4, a, " ")
         for (i = 1; i <= n; i++) {
     l = length (a[i]) + 1
     if (i > 1 && len + l > lmax) {
       print line
       line = indent " " a[i]
       len = length (line)
     } else {
       line = line " " a[i]
       len += l
     }
         }
         if (n)
     print line
       }
     }
   }' || at_write_fail=1
  exit $at_write_fail
fi
if $at_version_p; then
  printf "%s\n" "$as_me (ovn 23.06.90)" &&
  cat <<\_ATEOF || at_write_fail=1

Copyright (C) 2021 Free Software Foundation, Inc.
This test suite is free software; the Free Software Foundation gives
unlimited permission to copy, distribute and modify it.

Copyright (c) 2022 Red Hat,

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at:

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
_ATEOF
  exit $at_write_fail
fi

# Should we print banners?  Yes if more than one test is run.
case $at_groups in #(
  *$as_nl* )
      at_print_banners=: ;; #(
  * ) at_print_banners=false ;;
esac
# Text for banner N, set to a single space once printed.
# Banner 1. multinode.at:1
# Category starts at test group 1.
at_banner_text_1="ovn multinode system tests using ovn-fake-multinode"

# Take any -C into account.
if $at_change_dir ; then
  test x != "x$at_dir" && cd "$at_dir" \
    || as_fn_error $? "unable to change directory"
  at_dir=`pwd`
fi

# Load the config files for any default variable assignments.
for at_file in atconfig atlocal
do
  test -r $at_file || continue
  . ./$at_file || as_fn_error $? "invalid content: $at_file"
done

# Autoconf <=2.59b set at_top_builddir instead of at_top_build_prefix:
: "${at_top_build_prefix=$at_top_builddir}"

# Perform any assignments requested during argument parsing.
eval "$at_debug_args"

# atconfig delivers names relative to the directory the test suite is
# in, but the groups themselves are run in testsuite-dir/group-dir.
if test -n "$at_top_srcdir"; then
  builddir=../..
  for at_dir_var in srcdir top_srcdir top_build_prefix
  do
    eval at_val=\$at_$at_dir_var
    case $at_val in
      [\\/$]* | ?:[\\/]* ) at_prefix= ;;
      *) at_prefix=../../ ;;
    esac
    eval "$at_dir_var=\$at_prefix\$at_val"
  done
fi

## -------------------- ##
## Directory structure. ##
## -------------------- ##

# This is the set of directories and files used by this script
# (non-literals are capitalized):
#
# TESTSUITE         - the testsuite
# TESTSUITE.log     - summarizes the complete testsuite run
# TESTSUITE.dir/    - created during a run, remains after -d or failed test
# + at-groups/      - during a run: status of all groups in run
# | + NNN/          - during a run: meta-data about test group NNN
# | | + check-line  - location (source file and line) of current AT_CHECK
# | | + status      - exit status of current AT_CHECK
# | | + stdout      - stdout of current AT_CHECK
# | | + stder1      - stderr, including trace
# | | + stderr      - stderr, with trace filtered out
# | | + test-source - portion of testsuite that defines group
# | | + times       - timestamps for computing duration
# | | + pass        - created if group passed
# | | + xpass       - created if group xpassed
# | | + fail        - created if group failed
# | | + xfail       - created if group xfailed
# | | + skip        - created if group skipped
# + at-stop         - during a run: end the run if this file exists
# + at-source-lines - during a run: cache of TESTSUITE line numbers for extraction
# + 0..NNN/         - created for each group NNN, remains after -d or failed test
# | + TESTSUITE.log - summarizes the group results
# | + ...           - files created during the group

# The directory the whole suite works in.
# Should be absolute to let the user `cd' at will.
at_suite_dir=$at_dir/$as_me.dir
# The file containing the suite ($at_dir might have changed since earlier).
at_suite_log=$at_dir/$as_me.log
# The directory containing helper files per test group.
at_helper_dir=$at_suite_dir/at-groups
# Stop file: if it exists, do not start new jobs.
at_stop_file=$at_suite_dir/at-stop
# The fifo used for the job dispatcher.
at_job_fifo=$at_suite_dir/at-job-fifo

if $at_clean; then
  test -d "$at_suite_dir" &&
    find "$at_suite_dir" -type d ! -perm -700 -exec chmod u+rwx \{\} \;
  rm -f -r "$at_suite_dir" "$at_suite_log"
  exit $?
fi

# Don't take risks: use only absolute directories in PATH.
#
# For stand-alone test suites (ie. atconfig was not found),
# AUTOTEST_PATH is relative to `.'.
#
# For embedded test suites, AUTOTEST_PATH is relative to the top level
# of the package.  Then expand it into build/src parts, since users
# may create executables in both places.
AUTOTEST_PATH=`printf "%s\n" "$AUTOTEST_PATH" | sed "s|:|$PATH_SEPARATOR|g"`
at_path=
as_save_IFS=$IFS; IFS=$PATH_SEPARATOR
for as_dir in $AUTOTEST_PATH $PATH
do
  IFS=$as_save_IFS
  case $as_dir in #(((
    '') as_dir=./ ;;
    */) ;;
    *) as_dir=$as_dir/ ;;
  esac
    test -n "$at_path" && as_fn_append at_path $PATH_SEPARATOR
case $as_dir in
  [\\/]* | ?:[\\/]* )
    as_fn_append at_path "$as_dir"
    ;;
  * )
    if test -z "$at_top_build_prefix"; then
      # Stand-alone test suite.
      as_fn_append at_path "$as_dir"
    else
      # Embedded test suite.
      as_fn_append at_path "$at_top_build_prefix$as_dir$PATH_SEPARATOR"
      as_fn_append at_path "$at_top_srcdir/$as_dir"
    fi
    ;;
esac
  done
IFS=$as_save_IFS


# Now build and simplify PATH.
#
# There might be directories that don't exist, but don't redirect
# builtins' (eg., cd) stderr directly: Ultrix's sh hates that.
at_new_path=
as_save_IFS=$IFS; IFS=$PATH_SEPARATOR
for as_dir in $at_path
do
  IFS=$as_save_IFS
  case $as_dir in #(((
    '') as_dir=./ ;;
    */) ;;
    *) as_dir=$as_dir/ ;;
  esac
    test -d "$as_dir" || continue
case $as_dir in
  [\\/]* | ?:[\\/]* ) ;;
  * ) as_dir=`(cd "$as_dir" && pwd) 2>/dev/null` ;;
esac
case $PATH_SEPARATOR$at_new_path$PATH_SEPARATOR in
  *$PATH_SEPARATOR$as_dir$PATH_SEPARATOR*) ;;
  $PATH_SEPARATOR$PATH_SEPARATOR) at_new_path=$as_dir ;;
  *) as_fn_append at_new_path "$PATH_SEPARATOR$as_dir" ;;
esac
  done
IFS=$as_save_IFS

PATH=$at_new_path
export PATH

# Setting up the FDs.



# 5 is the log file.  Not to be overwritten if `-d'.
if $at_debug_p; then
  at_suite_log=/dev/null
else
  : >"$at_suite_log"
fi
exec 5>>"$at_suite_log"

# Banners and logs.
printf "%s\n" "## ------------------------ ##
## ovn 23.06.90 test suite. ##
## ------------------------ ##"
{
  printf "%s\n" "## ------------------------ ##
## ovn 23.06.90 test suite. ##
## ------------------------ ##"
  echo

  printf "%s\n" "$as_me: command line was:"
  printf "%s\n" "  \$ $0 $at_cli_args"
  echo

  # If ChangeLog exists, list a few lines in case it might help determining
  # the exact version.
  if test -n "$at_top_srcdir" && test -f "$at_top_srcdir/ChangeLog"; then
    printf "%s\n" "## ---------- ##
## ChangeLog. ##
## ---------- ##"
    echo
    sed 's/^/| /;10q' "$at_top_srcdir/ChangeLog"
    echo
  fi

  {
cat <<_ASUNAME
## --------- ##
## Platform. ##
## --------- ##

hostname = `(hostname || uname -n) 2>/dev/null | sed 1q`
uname -m = `(uname -m) 2>/dev/null || echo unknown`
uname -r = `(uname -r) 2>/dev/null || echo unknown`
uname -s = `(uname -s) 2>/dev/null || echo unknown`
uname -v = `(uname -v) 2>/dev/null || echo unknown`

/usr/bin/uname -p = `(/usr/bin/uname -p) 2>/dev/null || echo unknown`
/bin/uname -X     = `(/bin/uname -X) 2>/dev/null     || echo unknown`

/bin/arch              = `(/bin/arch) 2>/dev/null              || echo unknown`
/usr/bin/arch -k       = `(/usr/bin/arch -k) 2>/dev/null       || echo unknown`
/usr/convex/getsysinfo = `(/usr/convex/getsysinfo) 2>/dev/null || echo unknown`
/usr/bin/hostinfo      = `(/usr/bin/hostinfo) 2>/dev/null      || echo unknown`
/bin/machine           = `(/bin/machine) 2>/dev/null           || echo unknown`
/usr/bin/oslevel       = `(/usr/bin/oslevel) 2>/dev/null       || echo unknown`
/bin/universe          = `(/bin/universe) 2>/dev/null          || echo unknown`

_ASUNAME

as_save_IFS=$IFS; IFS=$PATH_SEPARATOR
for as_dir in $PATH
do
  IFS=$as_save_IFS
  case $as_dir in #(((
    '') as_dir=./ ;;
    */) ;;
    *) as_dir=$as_dir/ ;;
  esac
    printf "%s\n" "PATH: $as_dir"
  done
IFS=$as_save_IFS

}
  echo

  # Contents of the config files.
  for at_file in atconfig atlocal
  do
    test -r $at_file || continue
    printf "%s\n" "$as_me: $at_file:"
    sed 's/^/| /' $at_file
    echo
  done
} >&5


## ------------------------- ##
## Autotest shell functions. ##
## ------------------------- ##

# at_fn_banner NUMBER
# -------------------
# Output banner NUMBER, provided the testsuite is running multiple groups and
# this particular banner has not yet been printed.
at_fn_banner ()
{
  $at_print_banners || return 0
  eval at_banner_text=\$at_banner_text_$1
  test "x$at_banner_text" = "x " && return 0
  eval "at_banner_text_$1=\" \""
  if test -z "$at_banner_text"; then
    $at_first || echo
  else
    printf "%s\n" "$as_nl$at_banner_text$as_nl"
  fi
} # at_fn_banner

# at_fn_check_prepare_notrace REASON LINE
# ---------------------------------------
# Perform AT_CHECK preparations for the command at LINE for an untraceable
# command; REASON is the reason for disabling tracing.
at_fn_check_prepare_notrace ()
{
  $at_trace_echo "Not enabling shell tracing (command contains $1)"
  printf "%s\n" "$2" >"$at_check_line_file"
  at_check_trace=: at_check_filter=:
  : >"$at_stdout"; : >"$at_stderr"
}

# at_fn_check_prepare_trace LINE
# ------------------------------
# Perform AT_CHECK preparations for the command at LINE for a traceable
# command.
at_fn_check_prepare_trace ()
{
  printf "%s\n" "$1" >"$at_check_line_file"
  at_check_trace=$at_traceon at_check_filter=$at_check_filter_trace
  : >"$at_stdout"; : >"$at_stderr"
}

# at_fn_check_prepare_dynamic COMMAND LINE
# ----------------------------------------
# Decide if COMMAND at LINE is traceable at runtime, and call the appropriate
# preparation function.
at_fn_check_prepare_dynamic ()
{
  case $1 in
    *$as_nl*)
      at_fn_check_prepare_notrace 'an embedded newline' "$2" ;;
    *)
      at_fn_check_prepare_trace "$2" ;;
  esac
}

# at_fn_filter_trace
# ------------------
# Remove the lines in the file "$at_stderr" generated by "set -x" and print
# them to stderr.
at_fn_filter_trace ()
{
  mv "$at_stderr" "$at_stder1"
  grep '^ *+' "$at_stder1" >&2
  grep -v '^ *+' "$at_stder1" >"$at_stderr"
}

# at_fn_log_failure FILE-LIST
# ---------------------------
# Copy the files in the list on stdout with a "> " prefix, and exit the shell
# with a failure exit code.
at_fn_log_failure ()
{
  for file
    do printf "%s\n" "$file:"; sed 's/^/> /' "$file"; done
  echo 1 > "$at_status_file"
  exit 1
}

# at_fn_check_skip EXIT-CODE LINE
# -------------------------------
# Check whether EXIT-CODE is a special exit code (77 or 99), and if so exit
# the test group subshell with that same exit code. Use LINE in any report
# about test failure.
at_fn_check_skip ()
{
  case $1 in
    99) echo 99 > "$at_status_file"; at_failed=:
  printf "%s\n" "$2: hard failure"; exit 99;;
    77) echo 77 > "$at_status_file"; exit 77;;
  esac
}

# at_fn_check_status EXPECTED EXIT-CODE LINE
# ------------------------------------------
# Check whether EXIT-CODE is the EXPECTED exit code, and if so do nothing.
# Otherwise, if it is 77 or 99, exit the test group subshell with that same
# exit code; if it is anything else print an error message referring to LINE,
# and fail the test.
at_fn_check_status ()
{
  case $2 in
    $1 ) ;;
    77) echo 77 > "$at_status_file"; exit 77;;
    99) echo 99 > "$at_status_file"; at_failed=:
  printf "%s\n" "$3: hard failure"; exit 99;;
    *) printf "%s\n" "$3: exit code was $2, expected $1"
      at_failed=:;;
  esac
}

# at_fn_diff_devnull FILE
# -----------------------
# Emit a diff between /dev/null and FILE. Uses "test -s" to avoid useless diff
# invocations.
at_fn_diff_devnull ()
{
  test -s "$1" || return 0
  $at_diff "$at_devnull" "$1"
}

# at_fn_test NUMBER
# -----------------
# Parse out test NUMBER from the tail of this file.
at_fn_test ()
{
  eval at_sed=\$at_sed$1
  sed "$at_sed" "$at_myself" > "$at_test_source"
}

# at_fn_create_debugging_script
# -----------------------------
# Create the debugging script $at_group_dir/run which will reproduce the
# current test group.
at_fn_create_debugging_script ()
{
  {
    echo "#! /bin/sh" &&
    echo 'test ${ZSH_VERSION+y} && alias -g '\''${1+"$@"}'\''='\''"$@"'\''' &&
    printf "%s\n" "cd '$at_dir'" &&
    printf "%s\n" "exec \${CONFIG_SHELL-$SHELL} \"$at_myself\" -v -d $at_debug_args $at_group \${1+\"\$@\"}" &&
    echo 'exit 1'
  } >"$at_group_dir/run" &&
  chmod +x "$at_group_dir/run"
}

## -------------------------------- ##
## End of autotest shell functions. ##
## -------------------------------- ##


# Set ovs_base to the base directory in which the test is running and
# initialize the OVS_*DIR environment variables to point to this
# directory.
ovs_init() {
    ovs_base=`pwd`
    trap ovs_on_exit 0
    : > cleanup
    ovs_setenv
}

# Catch testsuite error condition and cleanup test environment by tearing down
# all interfaces and processes spawned.
# User has an option to leave the test environment in error state so that system
# can be poked around to get more information. User can enable this option by setting
# environment variable OVS_PAUSE_TEST=1. User needs to press CTRL-D to resume the
# cleanup operation.
ovs_pause() {
    echo "====================================================="
    echo "Set following environment variable to use various ovs utilities"
    echo "export OVS_RUNDIR=$ovs_base"
    echo "Press ENTER to continue: "
    read
}

ovs_on_exit () {
    rv=$?
    if [ ! -z "${OVS_PAUSE_TEST}" ] && [ -z $at_verbose ] && [ $rv != 0 ]; then
        trap '' INT
        ovs_pause
    fi
    . "$ovs_base/cleanup"
}

# With no parameter or an empty parameter, sets the OVS_*DIR
# environment variables to point to $ovs_base, the base directory in
# which the test is running.
#
# With a parameter, sets them to $ovs_base/$1.
ovs_setenv() {
    sandbox=$1
    ovs_dir=$ovs_base${1:+/$1}
    OVS_RUNDIR=$ovs_dir; export OVS_RUNDIR
    OVN_RUNDIR=$ovs_dir; export OVN_RUNDIR
    OVS_LOGDIR=$ovs_dir; export OVS_LOGDIR
    OVS_DBDIR=$ovs_dir; export OVS_DBDIR
    OVS_SYSCONFDIR=$ovs_dir; export OVS_SYSCONFDIR
    OVN_SYSCONFDIR=$ovs_dir; export OVN_SYSCONFDIR
    OVS_PKGDATADIR=$ovs_dir; export OVS_PKGDATADIR
    OVN_PKGDATADIR=$ovs_dir; export OVN_PKGDATADIR
}

# Prints the integers from $1 to $2, increasing by $3 (default 1) on stdout.
seq () {
    if test $# = 1; then
        set 1 $1
    fi
    while test $1 -le $2; do
        echo $1
        set `expr $1 + ${3-1}` $2 $3
    done
}

if test "$IS_WIN32" = "yes"; then
    pwd () {
        command pwd -W "$@"
    }

    diff () {
        command diff --strip-trailing-cr "$@"
    }

    # tskill is more effective than taskkill but it isn't always installed.
    if (tskill //?) >/dev/null 2>&1; then :; else
        tskill () { taskkill //F //PID $1 >/dev/null; }
    fi

    kill () {
        signal=
        retval=0
        for arg; do
            case $arg in
            -*) signal=$arg ;;
            [1-9][0-9]*)
                # tasklist always returns 0.
                # If pid does exist, there will be a line with the pid.
                if tasklist //fi "PID eq $arg" | grep $arg >/dev/null; then
                    if test "X$signal" != "X-0"; then
                        tskill $arg
                    fi
                else
                    retval=1
                fi
                ;;
            esac
        done
        return $retval
    }
fi

# parent_pid PID
#
# Prints the PID of the parent of process PID.
parent_pid () {
    # Using "ps" is portable to any POSIX system, but busybox "ps" (used in
    # e.g. Alpine Linux) is noncompliant, so we use a Linux-specific approach
    # when it's available.  We check the format of the status file to avoid
    # the NetBSD file with the same name but different contents.
    if egrep '^PPid:[[:space:]]*[0-9]*$' /proc/$1/status > /dev/null 2>&1; then
        sed -n 's/^PPid:	\([0-9]*\)/\1/p' /proc/$1/status
    else
        ps -o ppid= -p $1
    fi
}

# kill_ovs_vswitchd [PID]
#
# Signal the ovs-vswitchd daemon to exit gracefully and wait for it to
# terminate or kill it if that takes too long.
#
# It is used to cleanup all sorts of tests and results. It can't assume
# any state, including the availability of PID file which can be provided.
kill_ovs_vswitchd () {
    # Use provided PID or save the current PID if available.
    TMPPID=$1
    if test -z "$TMPPID"; then
        TMPPID=$(cat $OVS_RUNDIR/ovs-vswitchd.pid 2>/dev/null)
    fi

    # Tell the daemon to terminate gracefully
    ovs-appctl --timeout=10 -t ovs-vswitchd exit --cleanup 2>/dev/null

    # Nothing else to be done if there is no PID
    test -z "$TMPPID" && return

    for i in 1 2 3 4 5 6 7 8 9; do
        # Check if the daemon is alive.
        kill -0 $TMPPID 2>/dev/null || return

        # Fallback to whole number since POSIX doesn't require
        # fractional times to work.
        sleep 0.1 || sleep 1
    done

    # Make sure it is terminated.
    kill $TMPPID
}

# Normalize the output of 'wc' to match POSIX.
# POSIX says 'wc' should print "%d %d %d", but GNU prints "%7d %7d %7d".
# POSIX says 'wc -l' should print "%d %s", but BSD prints "%8d".
#
# This fixes all of those (it will screw up filenames that contain
# multiple sequential spaces, but that doesn't really matter).
wc () {
   command wc "$@" | tr -s ' ' ' ' | sed 's/^ *//'
}

uuidfilt () {
    $PYTHON "$top_srcdir"/tests/uuidfilt.py "$@"
}

# run_as PROGRAM_NAME COMMAND [ARG...]
#
# Runs a command with argv[0] set to PROGRAM_NAME, if possible, in a
# subshell.  Most utilities print argc[0] as part of their messages,
# so this makes it easier to figure out which particular utility
# prints a message if a bunch of identical processes are running.
#
# Not all shells support "exec -a NAME", so test for it.
if (exec -a myname true 2>/dev/null); then
    run_as () {
        (exec -a "$@")
    }
else
    run_as () {
        shift
        (exec "$@")
    }
fi


ovs_cleanup() {
    if test "$(echo sanitizers.*)" != 'sanitizers.*'; then
        echo "Undefined Behavior Sanitizer or Address Sanitizer reported errors in:" sanitizers.*
        cat sanitizers.*
        printf "%s\n" "ovs-macros.at:233" >"$at_check_line_file"
at_fn_check_skip 99 "$at_srcdir/ovs-macros.at:233"
    fi
}

ovs_wait () {
    echo "$1: waiting $2..." >&5

    # First try the condition without waiting.
    if ovs_wait_cond; then echo "$1: wait succeeded immediately" >&5; return 0; fi

    # Try a quick sleep, so that the test completes very quickly
    # in the normal case.  POSIX doesn't require fractional times to
    # work, so this might not work.
    sleep 0.1
    if ovs_wait_cond; then echo "$1: wait succeeded quickly" >&5; return 0; fi

    # Then wait up to OVS_CTL_TIMEOUT seconds.
    local timer
    for timer in `seq 1 "$OVS_CTL_TIMEOUT"`; do
        sleep 1
        if ovs_wait_cond; then echo "$1: wait succeeded after $timer seconds" >&5; return 0; fi
    done

    echo "$1: wait failed after $timer seconds" >&5
    ovs_wait_failed
    printf "%s\n" "ovs-macros.at:258" >"$at_check_line_file"
at_fn_check_skip 99 "$at_srcdir/ovs-macros.at:258"
}

check_ovs_wait_until_args() {
   printf "%s\n" "ovs-macros.at:262" >"$at_check_line_file"
(test $1 -ge 3) \
  && at_fn_check_skip 99 "$at_srcdir/ovs-macros.at:262"
      printf "%s\n" "ovs-macros.at:264" >"$at_check_line_file"
(test $1 -eq 2 && test "$2" -eq "$2" 2>/dev/null) \
  && at_fn_check_skip 99 "$at_srcdir/ovs-macros.at:264"
}


   on_exit () {
    (echo "$1"; cat cleanup) > cleanup.tmp
    mv cleanup.tmp cleanup
}


ovsdb_client_wait() {
    ovsdb-client -vconsole:warn -vreconnect:err -vjsonrpc:err -vtimeval:off -vfile -vsyslog:off -vvlog:off --timeout=30 wait "$@"
}



# Strips 'n_packets=...' from ovs-ofctl output.
strip_n_packets () {
    sed 's/ n_packets=[0-9]*,//'
}

# Strips 'n_bytes=...' from ovs-ofctl output.
strip_n_bytes () {
    sed 's/ n_bytes=[0-9]*,//'
}

# Strips 'cookie=...' from ovs-ofctl output.
strip_cookie () {
    sed '
s/ cookie=0x[0-9a-fA-F]*,//
s/cookie=0x[0-9a-fA-F]*,//
'
}

# Strips 'nw_frag=yes|no' from ovs-ofctl (or similar) output.
strip_nw_frag () {
    sed '
s/nw_frag=yes,//
s/nw_frag=no,//
'
}

# Strips out uninteresting parts of ovs-ofctl output, as well as parts
# that vary from one run to another.
ofctl_strip () {
    sed '
s/ (xid=0x[0-9a-fA-F]*)//
s/ duration=[0-9.]*s,//
s/ cookie=0,//
s/ table=0,//
s/ n_packets=0,//
s/ n_bytes=0,//
s/ idle_age=[0-9]*,//
s/ hard_age=[0-9]*,//
s/dp_hash=0x[0-9a-f]*\//dp_hash=0x0\//
s/recirc_id=0x[0-9a-f]*,/recirc_id=0x0,/
s/[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]Z|//
s/dir\/[0-9]*\/br0.mgmt/dir\/XXXX\/br0.mgmt/
'
}

# Strips out uninteresting parts of ovs-ofctl output, including n_packets=..
# n_bytes=..
ofctl_strip_all () {
    ofctl_strip | strip_n_packets | strip_n_bytes | strip_cookie | sort
}

# Filter (multiline) vconn debug messages from ovs-vswitchd.log.
# Use with vconn_sub() and ofctl_strip()
print_vconn_debug () { awk -F\| < ovs-vswitchd.log '
BEGIN { prt=0 }
/\|vconn\|DBG\|/ { sub(/[ \t]*$/, ""); print $3 "|" $4 "|" $5; prt=1; next }
$4 != "" { prt=0; next }
prt==1 { sub(/[ \t]*$/, ""); print $0 }
'
}

vconn_sub() {
    sed '
s/tcp:127.0.0.1:[0-9][0-9]*:/unix:/
s/unix#[0-9]*:/unix:/
'
}


# PARSE_LISTENING_PORT LOGFILE VARIABLE
#
# Parses the TCP or SSL port on which a server is listening from
# LOGFILE, given that the server was told to listen on a kernel-chosen
# port, and assigns the port number to shell VARIABLE.  You should
# specify the listening remote as ptcp:0:127.0.0.1 or
# pssl:0:127.0.0.1, or the equivalent with [::1] instead of 127.0.0.1.
#
# Here's an example of how to use this with ovsdb-server:
#
#    ovsdb-server --log-file --remote=ptcp:0:127.0.0.1 ...
#    PARSE_LISTENING_PORT([ovsdb-server.log], [TCP_PORT])
#    # Now $TCP_PORT holds the listening port.


start_daemon () {
    set "$@" -vconsole:off --detach --no-chdir --pidfile --log-file
    echo "$@"
    "$@"
    pidfile="$OVS_RUNDIR"/$1.pid
    on_exit "test -e \"$pidfile\" && kill \`cat \"$pidfile\"\`"
}

# sim_add SANDBOX
#
# Starts a new simulated Open vSwitch instance named SANDBOX.  Files related to
# the instance, such as logs, databases, sockets, and pidfiles, are created in
# a subdirectory of the main test directory also named SANDBOX.  Afterward, the
# "as" command (see below) can be used to run Open vSwitch utilities in the
# context of the new sandbox.
#
# The new sandbox starts out without any bridges.  Use ovs-vsctl in the context
# of the new sandbox to create a bridge, e.g.:
#
#     sim_add hv0           # Create sandbox hv0.
#     as hv0                # Set hv0 as default sandbox.
#     ovs-vsctl add-br br0  # Add bridge br0 inside hv0.
#
# or:
#
#     sim_add hv0
#     as hv0 ovs-vsctl add-br br0
PKIDIR="$(cd $abs_top_builddir/tests && pwd)"
sims=
sim_add () {
   echo "adding simulator '$1'"

   sims="$sims $1"

   # Create sandbox.
   local d="$ovs_base"/$1
   mkdir "$d" || return 1
   ovs_setenv $1

   # Create database and start ovsdb-server.
   : > "$d"/.conf.db.~lock~
   as $1 ovsdb-tool create "$d"/conf.db "$ovs_srcdir"/vswitchd/vswitch.ovsschema || return 1
   as $1 start_daemon ovsdb-server --remote=punix:"$d"/db.sock || return 1

   # Initialize database.
   as $1 ovs-vsctl --no-wait -- init || return 1

   # Start ovs-vswitchd
   as $1 start_daemon ovs-vswitchd --enable-dummy=system -vvconn -vofproto_dpif -vunixctl
   as $1 ovs-appctl vlog/disable-rate-limit vconn
   if test X$HAVE_OPENSSL = Xyes; then
      if test -f $PKIDIR/testpki-$1-privkey.pem; then
         as $1 ovs-vsctl set-ssl \
            $PKIDIR/testpki-$1-privkey.pem \
            $PKIDIR/testpki-$1-cert.pem \
            $PKIDIR/testpki-cacert.pem \
            || return 1
      else
         echo "WARNING: No certificate created for sim '$1', check TESTPKI_CNS variable in tests/automake.mk"
      fi
   fi
}

# "as $1" sets the OVS_*DIR environment variables to point to $ovs_base/$1.
#
# "as $1 COMMAND..." sets those variables in a subshell and invokes COMMAND
# there.
as() {
    if test "X$2" != X; then
        (ovs_setenv $1; shift; "$@")
    else
        ovs_setenv $1
    fi
}

# Strips 'xid=0x1234' from ovs-ofctl output.
strip_xids () {
    sed 's/ (xid=0x[0-9a-fA-F]*)//'
}

# Changes all 'used:...' to say 'used:0.0', to make output easier to compare.
strip_used () {
    sed 's/used:[0-9]\.[0-9]*/used:0.0/'
}

# Removes all 'duration=...' to make output easier to compare.
strip_duration () {
    sed 's/duration=[0-9]*\.[0-9]*s,//'
}

# Strips 'ufid:...' from output, to make it easier to compare.
# (ufids are random.)
strip_ufid () {
    sed 's/ufid:[-0-9a-f]* //'
}

check_logs () {
    local logs
    for log in *.log; do
        case ${log} in # (
            '*.log'|testsuite.log) ;; # (
            *) logs="${logs} ${log}" ;;
        esac
    done

    # We most notably ignore 'Broken pipe' warnings.  These often and
    # intermittently appear in ovsdb-server.log, because *ctl commands
    # (e.g. ovs-vsctl, ovn-nbctl) exit right after committing a change to the
    # database.  However, in reaction, some daemon may immediately update the
    # database, and this later update may cause database sending update back to
    # *ctl command if *ctl has not exited yet.  If *ctl command exits before
    # the database calls send, the send fails with 'Broken pipe' or
    # 'not connected' depending on system.  Also removes all 'connection reset'
    # warning logs for similar reasons (EPIPE, ENOTCONN or ECONNRESET can be
    # returned on a send depending on whether the peer had unconsumed data
    # when it closed the socket).
    #
    # We also ignore "Dropped # log messages..." messages.  Otherwise, even if
    # we ignore the messages that were rate-limited, we can end up failing just
    # because of the announcement that rate-limiting happened (and in a racy,
    # timing-dependent way, too).
    sed -n "$1
/reset by peer/d
/Broken pipe/d
/is not connected/d
/timeval.*Unreasonably long [0-9]*ms poll interval/d
/timeval.*faults: [0-9]* minor, [0-9]* major/d
/timeval.*disk: [0-9]* reads, [0-9]* writes/d
/timeval.*context switches: [0-9]* voluntary, [0-9]* involuntary/d
/ovs_rcu.*blocked [0-9]* ms waiting for .* to quiesce/d
/Dropped [0-9]* log messages/d
/|WARN|/p
/|ERR|/p
/|EMER|/p" ${logs}
}

# add_of_br BRNUM [ARG...]
add_of_br () {
    local brnum=$1; shift
    local br=br$brnum
    local dpid=fedcba987654321$brnum
    local mac=aa:55:aa:55:00:0$brnum
    ovs-vsctl --timeout=20 \
        -- add-br $br \
        -- set bridge $br datapath-type=dummy \
                          fail-mode=secure \
                          other-config:datapath-id=$dpid \
                          other-config:hwaddr=$mac \
                          protocols="[OpenFlow10,OpenFlow11,OpenFlow12,\
                                       OpenFlow13,OpenFlow14,OpenFlow15]" \
        -- "$@"
}

# add_of_ports__ PORT_TYPE [--pcap] BRIDGE PNUM...
#
# Creates PORT_TYPE interfaces in BRIDGE named pPNUM, OpenFlow port number
# PNUM, and datapath port number PNUM (the latter is a consequence of
# the dummy implementation, which tries to assign datapath port
# numbers based on port names).
#
# If --pcap is supplied then packets received from the interface will
# be written to $port-rx.pcap and those sent to it to $port-tx.pcap.
add_of_ports__ () {
    local args
    local pcap=false
    local ptype=$1
    shift
    if test "$1" = --pcap; then
        pcap=:
    shift
    fi
    local br=$1; shift
    for pnum; do
        as_fn_append args " -- add-port $br p$pnum -- set Interface p$pnum type=$ptype ofport_request=$pnum"
    if $pcap; then
        as_fn_append args " -- set Interface p$pnum options:rxq_pcap=p$pnum-rx.pcap options:tx_pcap=p$pnum-tx.pcap"
    fi
    done
    echo ovs-vsctl $args
    ovs-vsctl $args
}

# add_of_ports [--pcap] BRIDGE PNUM...
#
add_of_ports () {
    add_of_ports__ dummy $@
}

# add_pmd_of_ports [--pcap] BRIDGE PNUM...
#
add_pmd_of_ports () {
    add_of_ports__ dummy-pmd $@
}



# ovn_init_db DATABASE [AZ]
#
# Creates and initializes the given DATABASE (one of "ovn-sb" or "ovn-nb"),
# starts its ovsdb-server instance, and sets the appropriate environment
# variable (OVN_SB_DB or OVN_NB_DB) so that ovn-sbctl or ovn-nbctl uses the
# database by default.
#
# Usually invoked from ovn_start.
ovn_init_db () {
    echo "${AZ:+$AZ: }creating $1 database"
    local as_d=$1
    if test -n "$2"; then
        as_d=$2/$as_d
    fi
    local d=$ovs_base/$as_d
    mkdir "$d" || return 1
    : > "$d"/.$1.db.~lock~
    as $as_d ovsdb-tool create "$d"/$1.db "$abs_top_srcdir"/$1.ovsschema

    local remote_in_db=
    if test X$HAVE_OPENSSL = Xyes -a X"$1" = X"ovn-sb"; then
        remote_in_db="--remote=db:OVN_Southbound,SB_Global,connections --private-key=$PKIDIR/testpki-test-privkey.pem --certificate=$PKIDIR/testpki-test-cert.pem --ca-cert=$PKIDIR/testpki-cacert.pem"
    fi

    as $as_d start_daemon ovsdb-server \
        -vjsonrpc \
        --remote=punix:"$d"/$1.sock \
        $remote_in_db \
        "$d"/$1.db

    local var=`echo $1_db | tr a-z- A-Z_`
    eval "$var=unix:\"\$d\"/\$1.sock"; export $var
}

# ovn_init_ic_db
#
# Creates and initializes ovn-ic-nb and ovn-ic-sb databases and starts their
# ovsdb-server instances, for OVN interconnection.
ovn_init_ic_db () {
    ovn_init_db ovn-ic-nb
    ovn_init_db ovn-ic-sb
}

# ovn_start_northd [--paused] (primary|backup) [AZ]
ovn_start_northd() {
    local northd_args=
    case $1 in
        --paused) northd_args=--dry-run; shift ;;
    esac
    local priority=$1
    local AZ=$2
    local msg_prefix=${AZ:+$AZ: }
    local d_prefix=${AZ:+$AZ/}

    local suffix=
    case $priority in
        backup) suffix=-backup ;;
    esac

    case ${NORTHD_TYPE:=ovn-northd} in
        ovn-northd) ;;
        ovn-northd-ddlog) northd_args="$northd_args --ddlog-record=${AZ:+$AZ/}northd$suffix/replay.dat -v" ;;
    esac

    if test X$NORTHD_USE_PARALLELIZATION = Xyes; then
        northd_args="$northd_args --n-threads=4"
    fi

    local name=${d_prefix}northd${suffix}
    echo "${prefix}starting $name"
    test -d "$ovs_base/$name" || mkdir "$ovs_base/$name"
    as $name start_daemon $NORTHD_TYPE $northd_args -vjsonrpc \
               --ovnnb-db=$OVN_NB_DB --ovnsb-db=$OVN_SB_DB
}

# ovn_start [--backup-northd=none|paused] [AZ]
#
# Creates and initializes ovn-sb and ovn-nb databases and starts their
# ovsdb-server instance, sets appropriate environment variables so that
# ovn-sbctl and ovn-nbctl use them by default, and starts ovn-northd running
# against them.
#
# Normally this starts an active northd and a backup northd.  The following
# options are accepted to adjust that:
#   --backup-northd=none    Don't start a backup northd.
#   --backup-northd=paused  Start the backup northd in the paused state.
ovn_start () {
    local backup_northd=:
    local backup_northd_options=
    case $1 in
        --backup-northd=none) backup_northd=false; shift ;;
        --backup-northd=paused) backup_northd_options=--paused; shift ;;
    esac
    local AZ=$1
    local msg_prefix=${AZ:+$AZ: }
    local d_prefix=${AZ:+$AZ/}

    if test -n "$AZ"; then
        mkdir "$ovs_base"/$AZ
    fi

    ovn_init_db ovn-sb $1; ovn-sbctl init
    ovn_init_db ovn-nb $1; ovn-nbctl init
    if test -n "$1"; then
        ovn-nbctl set NB_Global . name=$1
    fi

    ovn_start_northd primary $AZ
    if $backup_northd; then
        ovn_start_northd $backup_northd_options backup $AZ
    fi

    if test X$HAVE_OPENSSL = Xyes; then
        # Create the SB DB pssl+RBAC connection. Ideally we could pre-create
        # SB_Global and Connection with ovsdb-tool transact at DB creation
        # time, but unfortunately that does not work, northd-ddlog will replace
        # the SB_Global record on startup.
        ovn-sbctl \
            -- --id=@c create connection \
                target=\"pssl:0:127.0.0.1\" role=ovn-controller \
            -- add SB_Global . connections @c
        local d=$ovs_base
        if test -n "$AZ"; then
            d=$d/$AZ
        fi
        check_ovs_wait_until_args "1" ""
   ovs_wait_cond () {
    TCP_PORT=`sed -n 's/.*0:.*: listening on port \([0-9]*\)$/\1/p' "$d/ovn-sb/ovsdb-server.log"` && test X != X"$TCP_PORT"
}
ovs_wait_failed () {
    :

}
ovs_wait "ovn-macros.at:234" "until TCP_PORT=\`sed -n 's/.*0:.*: listening on port \\([0-9]*\\)\$/\\1/p' \"\$d/ovn-sb/ovsdb-server.log\"\` && test X != X\"\$TCP_PORT\""

        var="SSL_OVN_SB_DB"
        eval "$var=ssl:127.0.0.1:\$TCP_PORT"; export $var
    fi

    if test -n "$AZ"; then
        ovn-nbctl --wait=sb sync || exit $?

        echo "${msg_prefix}starting ovn-ic"
        mkdir "$ovs_base"/$d_prefix/ic
        as $d_prefix/ic start_daemon ovn-ic -v \
               --ovnnb-db=$OVN_NB_DB --ovnsb-db=$OVN_SB_DB \
               --ic-nb-db=unix:"$ovs_base"/ovn-ic-nb/ovn-ic-nb.sock \
               --ic-sb-db=unix:"$ovs_base"/ovn-ic-sb/ovn-ic-sb.sock
    fi
}

# Interconnection networks.
#
# When multiple sandboxed Open vSwitch instances exist, one will inevitably
# want to connect them together.  These commands allow for that.  Conceptually,
# an interconnection network is a switch for which these functions make it easy
# to plug into other switches in other sandboxed Open vSwitch instances.
# Interconnection networks are implemented as bridges in a switch named "main",
# so to use interconnection networks please avoid working with that switch
# directly.

# net_add NETWORK
#
# Creates a new interconnection network named NETWORK.
net_add () {
    test -d "$ovs_base"/main || sim_add main || return 1
    as main ovs-vsctl add-br "$1"
}

# net_attach NETWORK BRIDGE
#
# Adds a new port to BRIDGE in the default sandbox (as set with as()) and plugs
# it into the NETWORK interconnection network.  NETWORK must already have been
# created by a previous invocation of net_add.  The default sandbox must not be
# "main".
net_attach () {
    local net=$1 bridge=$2

    local port=${sandbox}_$bridge
    as main ovs-vsctl \
        -- add-port $net $port \
        -- set Interface $port options:pstream="punix:$ovs_base/main/$port.sock" options:rxq_pcap="$ovs_base/main/$port-rx.pcap" options:tx_pcap="$ovs_base/main/$port-tx.pcap" \
        || return 1

    ovs-vsctl \
        -- set Interface $bridge options:tx_pcap="$ovs_base/$sandbox/$bridge-tx.pcap" options:rxq_pcap="$ovs_base/$sandbox/$bridge-rx.pcap" \
        -- add-port $bridge ${bridge}_$net \
        -- set Interface ${bridge}_$net options:stream="unix:$ovs_base/main/$port.sock" options:rxq_pcap="$ovs_base/$sandbox/${bridge}_$net-rx.pcap" options:tx_pcap="$ovs_base/$sandbox/${bridge}_$net-tx.pcap" \
        || return 1
}

# ovn_az_attach AZ NETWORK BRIDGE IP [MASKLEN] [ENCAP]
ovn_az_attach() {
    local az=$1 net=$2 bridge=$3 ip=$4 masklen=${5-24} encap=${6-geneve,vxlan} systemid=${7-$sandbox} cli_args=${@:8}
    net_attach $net $bridge || return 1

    mac=`ovs-vsctl get Interface $bridge mac_in_use | sed s/\"//g`
    arp_table="$arp_table $sandbox,$bridge,$ip,$mac"
    if test -z $(echo $ip | sed '/:/d'); then
        ipversion="6"
    else
        ipversion="4"
    fi
    ovs-appctl netdev-dummy/ip${ipversion}addr $bridge $ip/$masklen >/dev/null || return 1
    ovs-appctl ovs/route/add $ip/$masklen $bridge >/dev/null || return 1

    local ovn_remote
    if test X"$az" = XNONE; then
        if test X$HAVE_OPENSSL = Xyes; then
            ovn_remote=$SSL_OVN_SB_DB
        else
            ovn_remote=unix:$ovs_base/ovn-sb/ovn-sb.sock
        fi
    else
        ovn_remote=unix:$ovs_base/$az/ovn-sb/ovn-sb.sock
    fi
    ovs-vsctl \
        -- set Open_vSwitch . external-ids:hostname=$sandbox \
        -- set Open_vSwitch . external-ids:system-id=$systemid \
        -- set Open_vSwitch . external-ids:ovn-remote=$ovn_remote \
        -- set Open_vSwitch . external-ids:ovn-encap-type=$encap \
        -- set Open_vSwitch . external-ids:ovn-encap-ip=$ip \
        -- --may-exist add-br br-int \
        -- set bridge br-int fail-mode=secure other-config:disable-in-band=true \
        || return 1

    # currently this is the optimal place to add the ovn-monitor-all=true option,
    # this can be implemented in a different way by redefining the sim-add function
    # to add the ovn-related external-ids when we add a new simulated node via sim-add.
    #
    if test X$OVN_MONITOR_ALL = Xyes; then
        ovs-vsctl set open . external_ids:ovn-monitor-all=true
    fi

    start_daemon ovn-controller --enable-dummy-vif-plug ${cli_args} || return 1
}

# ovn_attach NETWORK BRIDGE IP [MASKLEN] [ENCAP]
#
# First, this command attaches BRIDGE to interconnection network NETWORK, just
# like "net_attach NETWORK BRIDGE".  Second, it configures (simulated) IP
# address IP (with network mask length MASKLEN, which defaults to 24) on
# BRIDGE.  Finally, it configures the Open vSwitch database to work with OVN
# and starts ovn-controller.
ovn_attach() {
    ovn_az_attach NONE $@
}

# This function is similar to ovn_attach but makes sure it doesn't
# mess with another controller settings
start_virtual_controller() {
    local net=$1 bridge=$2 int_bridge=$3 ip=$4 masklen=${5-24} encap=${6-geneve,vxlan} systemid=${7-$sandbox} cli_args=${@:8}
    net_attach $net $bridge || return 1

    mac=`ovs-vsctl get Interface $bridge mac_in_use | sed s/\"//g`
    arp_table="$arp_table $sandbox,$bridge,$ip,$mac"
    ovs-appctl netdev-dummy/ip4addr $bridge $ip/$masklen >/dev/null || return 1
    ovs-appctl ovs/route/add $ip/$masklen $bridge >/dev/null || return 1

    local ovn_remote
    if test X$HAVE_OPENSSL = Xyes; then
        ovn_remote=$SSL_OVN_SB_DB
    else
        ovn_remote=unix:$ovs_base/ovn-sb/ovn-sb.sock
    fi
    ovs-vsctl \
        -- set Open_vSwitch . external-ids:ovn-remote-$systemid=$ovn_remote \
        -- set Open_vSwitch . external-ids:ovn-encap-type-$systemid=$encap \
        -- set Open_vSwitch . external-ids:ovn-encap-ip-$systemid=$ip \
        -- set Open_vSwitch . external-ids:ovn-bridge-$systemid=$int_bridge \
        -- --may-exist add-br $int_bridge \
        -- set bridge $int_bridge fail-mode=secure other-config:disable-in-band=true \
        || return 1

    echo IHAR ${cli_args}
    ovn-controller --enable-dummy-vif-plug ${cli_args} -vconsole:off --detach --no-chdir
}

# ovn_setenv AZ
ovn_setenv () {
    local d=$ovs_base/$1
    OVN_NB_DB=unix:"$d"/ovn-nb/ovn-nb.sock; export $var
    OVN_SB_DB=unix:"$d"/ovn-sb/ovn-sb.sock; export $var
}

# ovs_as AZ
ovn_as() {
    if test "X$2" != X; then
        (ovn_setenv $1; shift; "$@")
    else
        ovn_setenv $1
    fi
}

# OVN_POPULATE_ARP
#
# This pre-populates the ARP tables of all of the OVN instances that have been
# started with ovn_attach().  That means that packets sent from one hypervisor
# to another never get dropped or delayed by ARP resolution, which makes
# testing easier.
ovn_populate_arp__() {
    for e1 in $arp_table; do
        set `echo $e1 | sed 's/,/ /g'`; sb1=$1 br1=$2 ip=$3 mac=$4
        for e2 in $arp_table; do
            set `echo $e2 | sed 's/,/ /g'`; sb2=$1 br2=$2
            if test $sb1,$br1 != $sb2,$br2; then
                as $sb2 ovs-appctl tnl/neigh/set $br2 $ip $mac || return 1
            fi
        done
    done
}

# check COMMAND...
#
# Runs COMMAND and checks that it succeeds without any output.
check() {
    echo "$@"
    { set +x
printf "%s\n" "$at_srcdir/ovn-macros.at:419: \"\$@\""
at_fn_check_prepare_dynamic "\"$@\"" "ovn-macros.at:419"
( $at_check_trace; "$@"
) >>"$at_stdout" 2>>"$at_stderr" 5>&-
at_status=$? at_failed=false
$at_check_filter
at_fn_diff_devnull "$at_stderr" || at_failed=:
at_fn_diff_devnull "$at_stdout" || at_failed=:
at_fn_check_status 0 $at_status "$at_srcdir/ovn-macros.at:419"
$at_failed && at_fn_log_failure
$at_traceon; }

}

parse_db() {
    case $1 in
        (*:*) echo ${1%%:*} ;;
        (*) echo sb ;;
    esac
}

parse_table() {
    case $1 in
        (*:*) echo ${1##*:} ;;
        (*) echo $1 ;;
    esac
}

# count_rows TABLE [CONDITION...]
#
# Prints the number of rows in TABLE (that satisfy CONDITION).
# Uses the southbound db by default; set DB=nb for the northbound database.
count_rows() {
    local db=$(parse_db $1) table=$(parse_table $1); shift
    ovn-${db}ctl --format=table --no-headings find $table "$@" | wc -l
}

# check_row_count [DATABASE:]TABLE COUNT [CONDITION...]
#
# Checks that TABLE contains COUNT rows (that satisfy CONDITION).
# The default DATABASE is "sb".
check_row_count() {
    local db=$(parse_db $1) table=$(parse_table $1); shift
    local count=$1; shift
    local found=$(count_rows $db:$table "$@")
    echo
    echo "Checking for $count rows in $db $table${1+ with $*}... found $found"
    if test "$count" != "$found"; then
        ovn-${db}ctl list $table
        printf "%s\n" "ovn-macros.at:457" >"$at_check_line_file"
at_fn_check_skip 99 "$at_srcdir/ovn-macros.at:457"
    fi
}

# wait_row_count [DATABASE:]TABLE COUNT [CONDITION...]
#
# Waits until TABLE contains COUNT rows (that satisfy CONDITION).
# The default DATABASE is "sb".
wait_row_count() {
    local db=$(parse_db $1) table=$(parse_table $1); shift
    local count=$1; shift
    local a=$1 b=$2 c=$3 d=$4 e=$5
    echo "Waiting until $count rows in $db $table${1+ with $*}..."
    check_ovs_wait_until_args "2" "
      echo "$db table $table has the following rows. $(count_rows $db:$table $a $b $c $d $e) rows match instead of expected $count:"
      ovn-${db}ctl list $table"
   ovs_wait_cond () {
    test $count = $(count_rows $db:$table $a $b $c $d $e)
}
ovs_wait_failed () {
    :

      echo "$db table $table has the following rows. $(count_rows $db:$table $a $b $c $d $e) rows match instead of expected $count:"
      ovn-${db}ctl list $table
}
ovs_wait "ovn-macros.at:470" "until test \$count = \$(count_rows \$db:\$table \$a \$b \$c \$d \$e)"

}

# fetch_column [DATABASE:]TABLE COLUMN [CONDITION...]
#
# Fetches and prints all the values of COLUMN in the rows of TABLE
# (that satisfy CONDITION), sorting the results lexicographically.
# The default DATABASE is "sb".
fetch_column() {
    local db=$(parse_db $1) table=$(parse_table $1) column=${2-_uuid}; shift; shift
    # Using "echo" removes spaces and newlines.
    echo $(ovn-${db}ctl --bare --columns $column find $table "$@" | sort)
}

# check_column EXPECTED [DATABASE:]TABLE COLUMN [CONDITION...]
#
# Fetches all of the values of COLUMN in the rows of TABLE (that
# satisfy CONDITION), and compares them against EXPECTED (ignoring
# order).
#
# The default DATABASE is "sb".
check_column() {
    local expected=$1 db=$(parse_db $2) table=$(parse_table $2) column=${3-_uuid}; shift; shift; shift
    local found=$(ovn-${db}ctl --bare --columns $column find $table "$@")

    # Sort the expected and found values.
    local found=$(for d in $found; do echo $d; done | sort)
    local expected=$(for d in $expected; do echo $d; done | sort)

    echo
    echo "Checking values in $db $table${1+ with $*} against $expected... found $found"
    if test "$found" != "$expected"; then
        ovn-${db}ctl list $table
        printf "%s\n" "ovn-macros.at:505" >"$at_check_line_file"
at_fn_check_skip 99 "$at_srcdir/ovn-macros.at:505"
    fi
}

# wait_column EXPECTED [DATABASE:]TABLE [COLUMN [CONDITION...]]
#
# Wait until all of the values of COLUMN in the rows of TABLE (that
# satisfy CONDITION) equal EXPECTED (ignoring order).
#
# The default DATABASE is "sb".
#
# COLUMN defaults to _uuid if unspecified.
wait_column() {
    local expected=$(for d in $1; do echo $d; done | sort)
    local db=$(parse_db $2) table=$(parse_table $2) column=${3-_uuid}; shift; shift; shift
    local a=$1 b=$2 c=$3 d=$4 e=$5

    echo
    echo "Waiting until $column in $db $table${1+ with $*} is $expected..."
    check_ovs_wait_until_args "2" "
      echo "$column in $db table $table has value $found, from the following rows:"
      ovn-${db}ctl list $table"
   ovs_wait_cond () {

      found=$(ovn-${db}ctl --bare --columns $column find $table $a $b $c $d $e)
      found=$(for d in $found; do echo $d; done | sort)
      test "$expected" = "$found"

}
ovs_wait_failed () {
    :

      echo "$column in $db table $table has value $found, from the following rows:"
      ovn-${db}ctl list $table
}
ovs_wait "ovn-macros.at:524" "until
      found=\$(ovn-\${db}ctl --bare --columns \$column find \$table \$a \$b \$c \$d \$e)
      found=\$(for d in \$found; do echo \$d; done | sort)
      test \"\$expected\" = \"\$found\"
    "

}

# wait_for_ports_up [PORT...]
#
# With arguments, waits for specified Logical_Switch_Ports to come up.
# Without arguments, waits for all "plain" and router
# Logical_Switch_Ports to come up.
wait_for_ports_up() {
    if test $# = 0; then
        wait_row_count nb:Logical_Switch_Port 0 up!=true type='""'
        wait_row_count nb:Logical_Switch_Port 0 up!=true type=router
    else
        for port; do
            wait_row_count nb:Logical_Switch_Port 1 up=true name=$port
        done
    fi
}

# reset_pcap_file iface pcap_file
# Resets the pcap file associates with OVS interface.  should be used
# with dummy datapath.
reset_pcap_file() {
    local iface=$1
    local pcap_file=$2
    check rm -f dummy-*.pcap
    check ovs-vsctl -- set Interface $iface options:tx_pcap=dummy-tx.pcap \
options:rxq_pcap=dummy-rx.pcap
    check rm -f ${pcap_file}*.pcap
    check ovs-vsctl -- set Interface $iface options:tx_pcap=${pcap_file}-tx.pcap \
options:rxq_pcap=${pcap_file}-rx.pcap
}

# Receive a packet on a dummy netdev interface. If we expect packets to be
# recorded, then wait until the pcap file reflects the change.
netdev_dummy_receive() {
    local interface="$1"
    local packet="$2"
    local hv="$3"
    local pcap_file="$4"

    if test -n "pcap_file" ; then
        ts_old=$(stat -c %y "$pcap_file")
    fi
    if test -n "$hv" ; then
        as "$hv" ovs-appctl netdev-dummy/receive "$interface" "$packet"
    else
        ovs-appctl netdev-dummy/receive "$interface" "$packet"
    fi
    if test -n "$pcap_file" ; then
        ovs_wait_cond () {
    if ts_new=$(stat -c %y "$pcap_file")
           test "$ts_new" = "$ts_old"; then return 1; else return 0; fi
}
ovs_wait_failed () {
    :

}
ovs_wait "ovn-macros.at:580" "while ts_new=\$(stat -c %y \"\$pcap_file\")
           test \"\$ts_new\" = \"\$ts_old\""

    fi
}

# send_igmp_v3_report INPORT HV ETH_SRC IP_SRC IP_CSUM GROUP REC_TYPE
#                     IGMP_CSUM OUTFILE
#
# This shell function causes an IGMPv3 report to be received on INPORT of HV.
# The packet's content has Ethernet destination 01:00:5E:00:00:22 and source
# ETH_SRC (exactly 12 hex digits). Ethernet type is set to IP.
# GROUP is the IP multicast group to be joined/to leave (based on REC_TYPE).
# REC_TYPE == 04: join GROUP
# REC_TYPE == 03: leave GROUP
# The packet hexdump is also stored in OUTFILE.
#
send_igmp_v3_report() {
    local inport=$1 hv=$2 eth_src=$3 ip_src=$4 ip_chksum=$5 group=$6
    local rec_type=$7 igmp_chksum=$8 outfile=$9

    local eth_dst=01005e000016
    local ip_dst=$(ip_to_hex 224 0 0 22)
    local ip_ttl=01
    local ip_ra_opt=94040000

    local igmp_type=2200
    local num_rec=00000001
    local aux_dlen=00
    local num_src=0000

    local eth=${eth_dst}${eth_src}0800
    local ip=46c0002800004000${ip_ttl}02${ip_chksum}${ip_src}${ip_dst}${ip_ra_opt}
    local igmp=${igmp_type}${igmp_chksum}${num_rec}${rec_type}${aux_dlen}${num_src}${group}
    local packet=${eth}${ip}${igmp}

    echo ${packet} >> ${outfile}
    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# store_igmp_v3_query ETH_SRC IP_SRC IP_CSUM OUTFILE
#
# This shell function builds an IGMPv3 general query from ETH_SRC and IP_SRC
# and stores the hexdump of the packet in OUTFILE.
#
store_igmp_v3_query() {
    local eth_src=$1 ip_src=$2 ip_chksum=$3 outfile=$4

    local eth_dst=01005e000001
    local ip_dst=$(ip_to_hex 224 0 0 1)
    local ip_ttl=01
    local igmp_type=11
    local max_resp=0a
    local igmp_chksum=eeeb
    local addr=00000000

    local eth=${eth_dst}${eth_src}0800
    local ip=4500002000004000${ip_ttl}02${ip_chksum}${ip_src}${ip_dst}
    local igmp=${igmp_type}${max_resp}${igmp_chksum}${addr}000a0000
    local packet=${eth}${ip}${igmp}

    echo ${packet} >> ${outfile}
}

# send_igmp_v3_query INPORT HV ETH_SRC IP_SRC IP_CSUM OUTFILE
#
# This shell function builds and sends an IGMPv3 general query from
# ETH_SRC and IP_SRC and stores the hexdump of the packet in OUTFILE.
#
send_igmp_v3_query() {
    local inport=$1 hv=$2 eth_src=$3 ip_src=$4 ip_chksum=$5 outfile=$6

    local eth_dst=01005e000001
    local ip_dst=$(ip_to_hex 224 0 0 1)
    local ip_ttl=01
    local igmp_type=11
    local max_resp=0a
    local igmp_chksum=eeeb
    local addr=00000000

    local eth=${eth_dst}${eth_src}0800
    local ip=4500002000004000${ip_ttl}02${ip_chksum}${ip_src}${ip_dst}
    local igmp=${igmp_type}${max_resp}${igmp_chksum}${addr}000a0000
    local packet=${eth}${ip}${igmp}

    echo ${packet} >> ${outfile}
    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# send_ip_multicast_pkt INPORT HV ETH_SRC ETH_DST IP_SRC IP_DST IP_LEN TTL
#    IP_CHKSUM IP_PROTO DATA
#
# This shell function causes an IP multicast packet to be received on INPORT
# of HV.
# The hexdump of the packet is stored in OUTFILE.
#
send_ip_multicast_pkt() {
    local inport=$1 hv=$2 eth_src=$3 eth_dst=$4
    local ip_src=$5 ip_dst=$6 ip_len=$7 ip_ttl=$8 ip_chksum=$9 proto=${10}
    local data=${11}

    local eth=${eth_dst}${eth_src}0800
    local ip=450000${ip_len}95f14000${ip_ttl}${proto}${ip_chksum}${ip_src}${ip_dst}
    local packet=${eth}${ip}${data}

    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# store_ip_multicast_pkt ETH_SRC ETH_DST IP_SRC IP_DST IP_LEN TTL
#    IP_CHKSUM IP_PROTO DATA OUTFILE
#
# This shell function builds an IP multicast packet and stores the hexdump of
# the packet in OUTFILE.
#
store_ip_multicast_pkt() {
    local eth_src=$1 eth_dst=$2
    local ip_src=$3 ip_dst=$4 ip_len=$5 ip_ttl=$6 ip_chksum=$7 proto=$8
    local data=$9 outfile=${10}

    local eth=${eth_dst}${eth_src}0800
    local ip=450000${ip_len}95f14000${ip_ttl}${proto}${ip_chksum}${ip_src}${ip_dst}
    local packet=${eth}${ip}${data}

    echo ${packet} >> ${outfile}
}

# send_mld_v2_report INPORT HV ETH_SRC IP_SRC GROUP REC_TYPE
#                    MLD_CSUM OUTFILE
#
# This shell function causes an MLDv2 report to be received on INPORT of HV.
# The packet's content has Ethernet destination 33:33:00:00:00:16 and source
# ETH_SRC (exactly 12 hex digits). Ethernet type is set to IPv6.
# GROUP is the IPv6 multicast group to be joined/to leave (based on REC_TYPE).
# REC_TYPE == 04: join GROUP
# REC_TYPE == 03: leave GROUP
# The packet hexdump is also stored in OUTFILE.
#
send_mld_v2_report() {
    local inport=$1 hv=$2 eth_src=$3 ip_src=$4 group=$5
    local rec_type=$6 mld_chksum=$7 outfile=$8

    local eth_dst=333300000016
    local ip_dst=ff020000000000000000000000000016
    local ip_ttl=01
    local ip_ra_opt=3a00050200000100

    local mld_type=8f
    local mld_code=00
    local num_rec=0001
    local aux_dlen=00
    local num_src=0000

    local eth=${eth_dst}${eth_src}86dd
    local ip=60000000002400${ip_ttl}${ip_src}${ip_dst}${ip_ra_opt}
    local mld=${mld_type}${mld_code}${mld_chksum}0000${num_rec}${rec_type}${aux_dlen}${num_src}${group}
    local packet=${eth}${ip}${mld}

    echo ${packet} >> ${outfile}
    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# store_mld_query ETH_SRC IP_SRC OUTFILE
#
# This shell function builds an MLD general query from ETH_SRC and IP_SRC
# and stores the hexdump of the packet in OUTFILE.
#
store_mld_query() {
    local eth_src=$1 ip_src=$2 outfile=$3

    local eth_dst=333300000000
    local ip_dst=ff020000000000000000000000000001
    local ip_ttl=01
    local ip_ra_opt=3a00050200000000

    local mld_type=82
    local mld_code=00
    local max_resp=03e8
    local mld_chksum=7b3d
    local addr=00000000000000000000000000000000

    local eth=${eth_dst}${eth_src}86dd
    local ip=60000000002400${ip_ttl}${ip_src}${ip_dst}${ip_ra_opt}
    local mld=${mld_type}${mld_code}${mld_chksum}${max_resp}0000${addr}00010000
    local packet=${eth}${ip}${mld}

    echo ${packet} >> ${outfile}
}

# send_ip6_multicast_pkt INPORT HV ETH_SRC ETH_DST IP_SRC IP_DST IP_LEN TTL
#    IP_PROTO DATA
#
# This shell function causes an IP multicast packet to be received on INPORT
# of HV.
#
send_ip6_multicast_pkt() {
    local inport=$1 hv=$2 eth_src=$3 eth_dst=$4
    local ip_src=$5 ip_dst=$6 ip_len=$7 ip_ttl=$8 proto=$9
    local data=${10}

    local eth=${eth_dst}${eth_src}86dd
    local ip=60000000${ip_len}${proto}${ip_ttl}${ip_src}${ip_dst}
    local packet=${eth}${ip}${data}

    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# store_ip6_multicast_pkt ETH_SRC ETH_DST IP_SRC IP_DST IP_LEN TTL
#    IP_PROTO DATA OUTFILE
#
# This shell function builds an IP multicast packet and stores the hexdump of
# the packet in OUTFILE.
#
store_ip6_multicast_pkt() {
    local eth_src=$1 eth_dst=$2
    local ip_src=$3 ip_dst=$4 ip_len=$5 ip_ttl=$6 proto=$7
    local data=$8 outfile=$9

    local eth=${eth_dst}${eth_src}86dd
    local ip=60000000${ip_len}${proto}${ip_ttl}${ip_src}${ip_dst}
    local packet=${eth}${ip}${data}

    echo ${packet} >> ${outfile}
}

# Wrapper on top of ovn-trace, stripping some things and storing the trace
# output to a file called 'trace'.  For now it strips the rows starting
# with a '#'.  This should correspond to the flow key and might be displayed
# differently by different OVS library versions.
ovn_trace() {

    ovn-trace "$@" | tee trace | sed '/^# /d'
}

# Same as ovn_trace() except that it connects to an ovn-trace daemon.
ovn_trace_client() {
    target=$1; shift

    ovs-appctl -t $target trace "$@" | tee trace | sed '/^# /d'
}

# Receives a string with scapy python code that represents a packet.
# Returns a hex-string that contains bytes that reflect the packet symbolic
# description.
#
# Scapy docs: https://scapy.readthedocs.io/en/latest/usage.html
#
# Example of usage:
#
# packet=$(fmt_pkt "
#     Ether(dst='ff:ff:ff:ff:ff:ff', src='50:64:00:00:00:01') /
#     IPv6(src='abed::1', dst='ff02::1:ff00:2') /
#     ICMPv6ND_NS(tgt='abed::2')
# ")
#
# ovs-appctl netdev-dummy/receive $vif $packet
#
fmt_pkt() {
    echo "from scapy.all import *; \
          import binascii; \
          out = binascii.hexlify(raw($1)); \
          print(out.decode())" | $PYTHON3
}




m_as() {
    c=$1
    shift
    podman exec $c "$@"
}

m_central_as () {
    podman exec ovn-central "$@"
}

check_fake_multinode_setup() {
    check m_as ovn-central ovn-nbctl --wait=sb sync
    { set +x
printf "%s\n" "$at_srcdir/multinode-macros.at:32: m_as ovn-chassis-1 ovn-appctl -t ovn-controller version"
at_fn_check_prepare_trace "multinode-macros.at:32"
( $at_check_trace; m_as ovn-chassis-1 ovn-appctl -t ovn-controller version
) >>"$at_stdout" 2>>"$at_stderr" 5>&-
at_status=$? at_failed=false
$at_check_filter
at_fn_diff_devnull "$at_stderr" || at_failed=:
echo stdout:; cat "$at_stdout"
at_fn_check_status 0 $at_status "$at_srcdir/multinode-macros.at:32"
$at_failed && at_fn_log_failure
$at_traceon; }

    { set +x
printf "%s\n" "$at_srcdir/multinode-macros.at:33: m_as ovn-chassis-2 ovn-appctl -t ovn-controller version"
at_fn_check_prepare_trace "multinode-macros.at:33"
( $at_check_trace; m_as ovn-chassis-2 ovn-appctl -t ovn-controller version
) >>"$at_stdout" 2>>"$at_stderr" 5>&-
at_status=$? at_failed=false
$at_check_filter
at_fn_diff_devnull "$at_stderr" || at_failed=:
echo stdout:; cat "$at_stdout"
at_fn_check_status 0 $at_status "$at_srcdir/multinode-macros.at:33"
$at_failed && at_fn_log_failure
$at_traceon; }

    { set +x
printf "%s\n" "$at_srcdir/multinode-macros.at:34: m_as ovn-gw-1 ovn-appctl -t ovn-controller version"
at_fn_check_prepare_trace "multinode-macros.at:34"
( $at_check_trace; m_as ovn-gw-1 ovn-appctl -t ovn-controller version
) >>"$at_stdout" 2>>"$at_stderr" 5>&-
at_status=$? at_failed=false
$at_check_filter
at_fn_diff_devnull "$at_stderr" || at_failed=:
echo stdout:; cat "$at_stdout"
at_fn_check_status 0 $at_status "$at_srcdir/multinode-macros.at:34"
$at_failed && at_fn_log_failure
$at_traceon; }

    { set +x
printf "%s\n" "$at_srcdir/multinode-macros.at:35: m_as ovn-gw-1 ovn-appctl -t ovn-controller version"
at_fn_check_prepare_trace "multinode-macros.at:35"
( $at_check_trace; m_as ovn-gw-1 ovn-appctl -t ovn-controller version
) >>"$at_stdout" 2>>"$at_stderr" 5>&-
at_status=$? at_failed=false
$at_check_filter
at_fn_diff_devnull "$at_stderr" || at_failed=:
echo stdout:; cat "$at_stdout"
at_fn_check_status 0 $at_status "$at_srcdir/multinode-macros.at:35"
$at_failed && at_fn_log_failure
$at_traceon; }

}

cleanup_multinode_resources() {
    m_as ovn-central rm -f /etc/ovn/ovnnb_db.db
    m_as ovn-central /usr/share/ovn/scripts/ovn-ctl restart_northd
    check m_as ovn-central ovn-nbctl --wait=sb sync
    for c in ovn-chassis-1 ovn-chassis-2 ovn-gw-1
    do
        m_as $c ovs-vsctl del-br br-int
        m_as $c ip --all netns delete
    done
}

multinode_nbctl () {
    m_as ovn-central ovn-nbctl "$@"
}

# m_count_rows TABLE [CONDITION...]
#
# Prints the number of rows in TABLE (that satisfy CONDITION).
# Uses the southbound db by default; set DB=nb for the northbound database.
m_count_rows() {
    local db=$(parse_db $1) table=$(parse_table $1); shift
    m_central_as ovn-${db}ctl --format=table --no-headings find $table "$@" | wc -l
}

# m_check_row_count [DATABASE:]TABLE COUNT [CONDITION...]
#
# Checks that TABLE contains COUNT rows (that satisfy CONDITION).
# The default DATABASE is "sb".
m_check_row_count() {
    local db=$(parse_db $1) table=$(parse_table $1); shift
    local count=$1; shift
    local found=$(m_count_rows $c $db:$table "$@")
    echo
    echo "Checking for $count rows in $db $table${1+ with $*}... found $found"
    if test "$count" != "$found"; then
        m_central_as ovn-${db}ctl list $table
        printf "%s\n" "multinode-macros.at:74" >"$at_check_line_file"
at_fn_check_skip 99 "$at_srcdir/multinode-macros.at:74"
    fi
}

# m_wait_row_count [DATABASE:]TABLE COUNT [CONDITION...]
#
# Waits until TABLE contains COUNT rows (that satisfy CONDITION).
# The default DATABASE is "sb".
m_wait_row_count() {
    local db=$(parse_db $1) table=$(parse_table $1); shift
    local count=$1; shift
    local a=$1 b=$2 c=$3 d=$4 e=$5
    echo "Waiting until $count rows in $db $table${1+ with $*}..."
    check_ovs_wait_until_args "2" "
      echo "$db table $table has the following rows. $(m_count_rows $db:$table $a $b $c $d $e) rows match instead of expected $count:"
      m_central_as ovn-${db}ctl list $table"
   ovs_wait_cond () {
    test $count = $(m_count_rows $db:$table $a $b $c $d $e)
}
ovs_wait_failed () {
    :

      echo "$db table $table has the following rows. $(m_count_rows $db:$table $a $b $c $d $e) rows match instead of expected $count:"
      m_central_as ovn-${db}ctl list $table
}
ovs_wait "multinode-macros.at:87" "until test \$count = \$(m_count_rows \$db:\$table \$a \$b \$c \$d \$e)"

}

# m_wait_column EXPECTED [DATABASE:]TABLE [COLUMN [CONDITION...]]
#
# Wait until all of the values of COLUMN in the rows of TABLE (that
# satisfy CONDITION) equal EXPECTED (ignoring order).
#
# The default DATABASE is "sb".
#
# COLUMN defaults to _uuid if unspecified.
m_wait_column() {
    local expected=$(for d in $1; do echo $d; done | sort)
    local db=$(parse_db $2) table=$(parse_table $2) column=${3-_uuid}; shift; shift; shift
    local a=$1 b=$2 c=$3 d=$4 e=$5

    echo
    echo "Waiting until $column in $db $table${1+ with $*} is $expected..."
    check_ovs_wait_until_args "2" "
      echo "$column in $db table $table has value $found, from the following rows:"
      m_central_as ovn-${db}ctl list $table"
   ovs_wait_cond () {

      found=$(m_central_as ovn-${db}ctl --bare --columns $column find $table $a $b $c $d $e)
      found=$(for d in $found; do echo $d; done | sort)
      test "$expected" = "$found"

}
ovs_wait_failed () {
    :

      echo "$column in $db table $table has value $found, from the following rows:"
      m_central_as ovn-${db}ctl list $table
}
ovs_wait "multinode-macros.at:107" "until
      found=\$(m_central_as ovn-\${db}ctl --bare --columns \$column find \$table \$a \$b \$c \$d \$e)
      found=\$(for d in \$found; do echo \$d; done | sort)
      test \"\$expected\" = \"\$found\"
    "

}

# m_fetch_column [DATABASE:]TABLE COLUMN [CONDITION...]
#
# Fetches and prints all the values of COLUMN in the rows of TABLE
# (that satisfy CONDITION), sorting the results lexicographically.
# The default DATABASE is "sb".
m_fetch_column() {
    local db=$(parse_db $1) table=$(parse_table $1) column=${2-_uuid}; shift; shift
    # Using "echo" removes spaces and newlines.
    echo $(m_central_as ovn-${db}ctl --bare --columns $column find $table "$@" | sort)
}

# m_check_column EXPECTED [DATABASE:]TABLE COLUMN [CONDITION...]
#
# Fetches all of the values of COLUMN in the rows of TABLE (that
# satisfy CONDITION), and compares them against EXPECTED (ignoring
# order).
#
# The default DATABASE is "sb".
m_check_column() {
    local expected=$1 db=$(parse_db $2) table=$(parse_table $2) column=${3-_uuid}; shift; shift; shift
    local found=$(m_central_as ovn-${db}ctl --bare --columns $column find $table "$@")

    # Sort the expected and found values.
    local found=$(for d in $found; do echo $d; done | sort)
    local expected=$(for d in $expected; do echo $d; done | sort)

    echo
    echo "Checking values in $db $table${1+ with $*} against $expected... found $found"
    if test "$found" != "$expected"; then
        m_central_as ovn-${db}ctl list $table
        printf "%s\n" "multinode-macros.at:146" >"$at_check_line_file"
at_fn_check_skip 99 "$at_srcdir/multinode-macros.at:146"
    fi
}

# m_wait_for_ports_up [PORT...]
#
# With arguments, waits for specified Logical_Switch_Ports to come up.
# Without arguments, waits for all "plain" and router
# Logical_Switch_Ports to come up.
m_wait_for_ports_up() {
    if test $# = 0; then
        m_wait_row_count nb:Logical_Switch_Port 0 up!=true type='""'
        m_wait_row_count nb:Logical_Switch_Port 0 up!=true type=router
    else
        for port; do
            m_wait_row_count nb:Logical_Switch_Port 1 up=true name=$port
        done
    fi
}


   {
  printf "%s\n" "## ---------------- ##
## Tested programs. ##
## ---------------- ##"
  echo
} >&5

# Report what programs are being tested.
for at_program in : `eval echo $at_tested`
do
  case $at_program in #(
  :) :
    continue ;; #(
  [\\/]* | ?:[\\/]*) :
    at_program_=$at_program ;; #(
  *) :
    as_save_IFS=$IFS; IFS=$PATH_SEPARATOR
for as_dir in $PATH
do
  IFS=$as_save_IFS
  case $as_dir in #(((
    '') as_dir=./ ;;
    */) ;;
    *) as_dir=$as_dir/ ;;
  esac
    test -f "$as_dir$at_program" && break
  done
IFS=$as_save_IFS

    at_program_=$as_dir$at_program ;;
esac

  if test -f "$at_program_"; then
    {
      printf "%s\n" "$at_srcdir/multinode-testsuite.at:1: $at_program_ --version"
      "$at_program_" --version </dev/null
      echo
    } >&5 2>&1
  else
    as_fn_error $? "cannot find $at_program" "$LINENO" 5
  fi
done

{
  printf "%s\n" "## ------------------ ##
## Running the tests. ##
## ------------------ ##"
} >&5

at_start_date=`date`
at_start_time=`date +%s 2>/dev/null`
printf "%s\n" "$as_me: starting at: $at_start_date" >&5

# Create the master directory if it doesn't already exist.
as_dir="$at_suite_dir"; as_fn_mkdir_p ||
  as_fn_error $? "cannot create \`$at_suite_dir'" "$LINENO" 5

# Can we diff with `/dev/null'?  DU 5.0 refuses.
if diff /dev/null /dev/null >/dev/null 2>&1; then
  at_devnull=/dev/null
else
  at_devnull=$at_suite_dir/devnull
  >"$at_devnull"
fi

# Use `diff -u' when possible.
if at_diff=`diff -u "$at_devnull" "$at_devnull" 2>&1` && test -z "$at_diff"
then
  at_diff='diff -u'
else
  at_diff=diff
fi

# Get the last needed group.
for at_group in : $at_groups; do :; done

# Extract the start and end lines of each test group at the tail
# of this file
awk '
BEGIN { FS="" }
/^#AT_START_/ {
  start = NR
}
/^#AT_STOP_/ {
  test = substr ($ 0, 10)
  print "at_sed" test "=\"1," start "d;" (NR-1) "q\""
  if (test == "'"$at_group"'") exit
}' "$at_myself" > "$at_suite_dir/at-source-lines" &&
. "$at_suite_dir/at-source-lines" ||
  as_fn_error $? "cannot create test line number cache" "$LINENO" 5
rm -f "$at_suite_dir/at-source-lines"

# Set number of jobs for `-j'; avoid more jobs than test groups.
set X $at_groups; shift; at_max_jobs=$#
if test $at_max_jobs -eq 0; then
  at_jobs=1
fi
if test $at_jobs -ne 1 &&
   { test $at_jobs -eq 0 || test $at_jobs -gt $at_max_jobs; }; then
  at_jobs=$at_max_jobs
fi

# If parallel mode, don't output banners, don't split summary lines.
if test $at_jobs -ne 1; then
  at_print_banners=false
  at_quiet=:
fi

# Set up helper dirs.
rm -rf "$at_helper_dir" &&
mkdir "$at_helper_dir" &&
cd "$at_helper_dir" &&
{ test -z "$at_groups" || mkdir $at_groups; } ||
as_fn_error $? "testsuite directory setup failed" "$LINENO" 5

# Functions for running a test group.  We leave the actual
# test group execution outside of a shell function in order
# to avoid hitting zsh 4.x exit status bugs.

# at_fn_group_prepare
# -------------------
# Prepare for running a test group.
at_fn_group_prepare ()
{
  # The directory for additional per-group helper files.
  at_job_dir=$at_helper_dir/$at_group
  # The file containing the location of the last AT_CHECK.
  at_check_line_file=$at_job_dir/check-line
  # The file containing the exit status of the last command.
  at_status_file=$at_job_dir/status
  # The files containing the output of the tested commands.
  at_stdout=$at_job_dir/stdout
  at_stder1=$at_job_dir/stder1
  at_stderr=$at_job_dir/stderr
  # The file containing the code for a test group.
  at_test_source=$at_job_dir/test-source
  # The file containing dates.
  at_times_file=$at_job_dir/times

  # Be sure to come back to the top test directory.
  cd "$at_suite_dir"

  # Clearly separate the test groups when verbose.
  $at_first || $at_verbose echo

  at_group_normalized=$at_group

  eval 'while :; do
    case $at_group_normalized in #(
    '"$at_format"'*) break;;
    esac
    at_group_normalized=0$at_group_normalized
  done'


  # Create a fresh directory for the next test group, and enter.
  # If one already exists, the user may have invoked ./run from
  # within that directory; we remove the contents, but not the
  # directory itself, so that we aren't pulling the rug out from
  # under the shell's notion of the current directory.
  at_group_dir=$at_suite_dir/$at_group_normalized
  at_group_log=$at_group_dir/$as_me.log
  if test -d "$at_group_dir"
then
  find "$at_group_dir" -type d ! -perm -700 -exec chmod u+rwx {} \;
  rm -fr "$at_group_dir"/* "$at_group_dir"/.[!.] "$at_group_dir"/.??*
fi ||
    { printf "%s\n" "$as_me:${as_lineno-$LINENO}: WARNING: test directory for $at_group_normalized could not be cleaned" >&5
printf "%s\n" "$as_me: WARNING: test directory for $at_group_normalized could not be cleaned" >&2;}
  # Be tolerant if the above `rm' was not able to remove the directory.
  as_dir="$at_group_dir"; as_fn_mkdir_p

  echo 0 > "$at_status_file"

  # In verbose mode, append to the log file *and* show on
  # the standard output; in quiet mode only write to the log.
  if test -z "$at_verbose"; then
    at_tee_pipe='tee -a "$at_group_log"'
  else
    at_tee_pipe='cat >> "$at_group_log"'
  fi
}

# at_fn_group_banner ORDINAL LINE DESC PAD [BANNER]
# -------------------------------------------------
# Declare the test group ORDINAL, located at LINE with group description DESC,
# and residing under BANNER. Use PAD to align the status column.
at_fn_group_banner ()
{
  at_setup_line="$2"
  test -n "$5" && at_fn_banner $5
  at_desc="$3"
  case $1 in
    [0-9])      at_desc_line="  $1: ";;
    [0-9][0-9]) at_desc_line=" $1: " ;;
    *)          at_desc_line="$1: "  ;;
  esac
  as_fn_append at_desc_line "$3$4"
  $at_quiet printf %s "$at_desc_line"
  echo "#                             -*- compilation -*-" >> "$at_group_log"
}

# at_fn_group_postprocess
# -----------------------
# Perform cleanup after running a test group.
at_fn_group_postprocess ()
{
  # Be sure to come back to the suite directory, in particular
  # since below we might `rm' the group directory we are in currently.
  cd "$at_suite_dir"

  if test ! -f "$at_check_line_file"; then
    sed "s/^ */$as_me: WARNING: /" <<_ATEOF
      A failure happened in a test group before any test could be
      run. This means that test suite is improperly designed.  Please
      report this failure to <bugs@openvswitch.org>.
_ATEOF
    printf "%s\n" "$at_setup_line" >"$at_check_line_file"
    at_status=99
  fi
  $at_verbose printf %s "$at_group. $at_setup_line: "
  printf %s "$at_group. $at_setup_line: " >> "$at_group_log"
  case $at_xfail:$at_status in
    yes:0)
  at_msg="UNEXPECTED PASS"
  at_res=xpass
  at_errexit=$at_errexit_p
  at_color=$at_red
  ;;
    no:0)
  at_msg="ok"
  at_res=pass
  at_errexit=false
  at_color=$at_grn
  ;;
    *:77)
  at_msg='skipped ('`cat "$at_check_line_file"`')'
  at_res=skip
  at_errexit=false
  at_color=$at_blu
  ;;
    no:* | *:99)
  at_msg='FAILED ('`cat "$at_check_line_file"`')'
  at_res=fail
  at_errexit=$at_errexit_p
  at_color=$at_red
  ;;
    yes:*)
  at_msg='expected failure ('`cat "$at_check_line_file"`')'
  at_res=xfail
  at_errexit=false
  at_color=$at_lgn
  ;;
  esac
  echo "$at_res" > "$at_job_dir/$at_res"
  # In parallel mode, output the summary line only afterwards.
  if test $at_jobs -ne 1 && test -n "$at_verbose"; then
    printf "%s\n" "$at_desc_line $at_color$at_msg$at_std"
  else
    # Make sure there is a separator even with long titles.
    printf "%s\n" " $at_color$at_msg$at_std"
  fi
  at_log_msg="$at_group. $at_desc ($at_setup_line): $at_msg"
  case $at_status in
    0|77)
      # $at_times_file is only available if the group succeeded.
      # We're not including the group log, so the success message
      # is written in the global log separately.  But we also
      # write to the group log in case they're using -d.
      if test -f "$at_times_file"; then
  at_log_msg="$at_log_msg     ("`sed 1d "$at_times_file"`')'
  rm -f "$at_times_file"
      fi
      printf "%s\n" "$at_log_msg" >> "$at_group_log"
      printf "%s\n" "$at_log_msg" >&5

      # Cleanup the group directory, unless the user wants the files
      # or the success was unexpected.
      if $at_debug_p || test $at_res = xpass; then
  at_fn_create_debugging_script
  if test $at_res = xpass && $at_errexit; then
    echo stop > "$at_stop_file"
  fi
      else
  if test -d "$at_group_dir"; then
    find "$at_group_dir" -type d ! -perm -700 -exec chmod u+rwx \{\} \;
    rm -fr "$at_group_dir"
  fi
  rm -f "$at_test_source"
      fi
      ;;
    *)
      # Upon failure, include the log into the testsuite's global
      # log.  The failure message is written in the group log.  It
      # is later included in the global log.
      printf "%s\n" "$at_log_msg" >> "$at_group_log"

      # Upon failure, keep the group directory for autopsy, and create
      # the debugging script.  With -e, do not start any further tests.
      at_fn_create_debugging_script
      if $at_errexit; then
  echo stop > "$at_stop_file"
      fi
      ;;
  esac
}


## ------------ ##
## Driver loop. ##
## ------------ ##


if (set -m && set +m && set +b) >/dev/null 2>&1; then
  set +b
  at_job_control_on='set -m' at_job_control_off='set +m' at_job_group=-
else
  at_job_control_on=: at_job_control_off=: at_job_group=
fi

for at_signal in 1 2 15; do
  trap 'set +x; set +e
  $at_job_control_off
  at_signal='"$at_signal"'
  echo stop > "$at_stop_file"
  trap "" $at_signal
  at_pgids=
  for at_pgid in `jobs -p 2>/dev/null`; do
    at_pgids="$at_pgids $at_job_group$at_pgid"
  done
  test -z "$at_pgids" || kill -$at_signal $at_pgids 2>/dev/null
  wait
  if test "$at_jobs" -eq 1 || test -z "$at_verbose"; then
    echo >&2
  fi
  at_signame=`kill -l $at_signal 2>&1 || echo $at_signal`
  set x $at_signame
  test 0 -gt 2 && at_signame=$at_signal
  { printf "%s\n" "$as_me:${as_lineno-$LINENO}: WARNING: caught signal $at_signame, bailing out" >&5
printf "%s\n" "$as_me: WARNING: caught signal $at_signame, bailing out" >&2;}
  as_fn_arith 128 + $at_signal && exit_status=$as_val
  as_fn_exit $exit_status' $at_signal
done

rm -f "$at_stop_file"
at_first=:

if test $at_jobs -ne 1 &&
     rm -f "$at_job_fifo" &&
     test -n "$at_job_group" &&
     ( mkfifo "$at_job_fifo" && trap 'exit 1' PIPE STOP TSTP ) 2>/dev/null
then
  # FIFO job dispatcher.

  trap 'at_pids=
  for at_pid in `jobs -p`; do
    at_pids="$at_pids $at_job_group$at_pid"
  done
  if test -n "$at_pids"; then
    at_sig=TSTP
    test ${TMOUT+y} && at_sig=STOP
    kill -$at_sig $at_pids 2>/dev/null
  fi
  kill -STOP $$
  test -z "$at_pids" || kill -CONT $at_pids 2>/dev/null' TSTP

  echo
  # Turn jobs into a list of numbers, starting from 1.
  at_joblist=`printf "%s\n" "$at_groups" | sed -n 1,${at_jobs}p`

  set X $at_joblist
  shift
  for at_group in $at_groups; do
    $at_job_control_on 2>/dev/null
    (
      # Start one test group.
      $at_job_control_off
      if $at_first; then
  exec 7>"$at_job_fifo"
      else
  exec 6<&-
      fi
      trap 'set +x; set +e
      trap "" PIPE
      echo stop > "$at_stop_file"
      echo >&7
      as_fn_exit 141' PIPE
      at_fn_group_prepare
      if cd "$at_group_dir" &&
   at_fn_test $at_group &&
   . "$at_test_source"
      then :; else
  { printf "%s\n" "$as_me:${as_lineno-$LINENO}: WARNING: unable to parse test group: $at_group" >&5
printf "%s\n" "$as_me: WARNING: unable to parse test group: $at_group" >&2;}
  at_failed=:
      fi
      at_fn_group_postprocess
      echo >&7
    ) &
    $at_job_control_off
    if $at_first; then
      at_first=false
      exec 6<"$at_job_fifo" 7>"$at_job_fifo"
    fi
    shift # Consume one token.
    if test $# -gt 0; then :; else
      read at_token <&6 || break
      set x $*
    fi
    test -f "$at_stop_file" && break
  done
  exec 7>&-
  # Read back the remaining ($at_jobs - 1) tokens.
  set X $at_joblist
  shift
  if test $# -gt 0; then
    shift
    for at_job
    do
      read at_token
    done <&6
  fi
  exec 6<&-
  wait
else
  # Run serially, avoid forks and other potential surprises.
  for at_group in $at_groups; do
    at_fn_group_prepare
    if cd "$at_group_dir" &&
       at_fn_test $at_group &&
       . "$at_test_source"; then :; else
      { printf "%s\n" "$as_me:${as_lineno-$LINENO}: WARNING: unable to parse test group: $at_group" >&5
printf "%s\n" "$as_me: WARNING: unable to parse test group: $at_group" >&2;}
      at_failed=:
    fi
    at_fn_group_postprocess
    test -f "$at_stop_file" && break
    at_first=false
  done
fi

# Wrap up the test suite with summary statistics.
cd "$at_helper_dir"

# Use ?..???? when the list must remain sorted, the faster * otherwise.
at_pass_list=`for f in */pass; do echo $f; done | sed '/\*/d; s,/pass,,'`
at_skip_list=`for f in */skip; do echo $f; done | sed '/\*/d; s,/skip,,'`
at_xfail_list=`for f in */xfail; do echo $f; done | sed '/\*/d; s,/xfail,,'`
at_xpass_list=`for f in ?/xpass ??/xpass ???/xpass ????/xpass; do
     echo $f; done | sed '/?/d; s,/xpass,,'`
at_fail_list=`for f in ?/fail ??/fail ???/fail ????/fail; do
    echo $f; done | sed '/?/d; s,/fail,,'`

set X $at_pass_list $at_xpass_list $at_xfail_list $at_fail_list $at_skip_list
shift; at_group_count=$#
set X $at_xpass_list; shift; at_xpass_count=$#; at_xpass_list=$*
set X $at_xfail_list; shift; at_xfail_count=$#
set X $at_fail_list; shift; at_fail_count=$#; at_fail_list=$*
set X $at_skip_list; shift; at_skip_count=$#

as_fn_arith $at_group_count - $at_skip_count && at_run_count=$as_val
as_fn_arith $at_xpass_count + $at_fail_count && at_unexpected_count=$as_val
as_fn_arith $at_xfail_count + $at_fail_count && at_total_fail_count=$as_val

# Back to the top directory.
cd "$at_dir"
rm -rf "$at_helper_dir"

# Compute the duration of the suite.
at_stop_date=`date`
at_stop_time=`date +%s 2>/dev/null`
printf "%s\n" "$as_me: ending at: $at_stop_date" >&5
case $at_start_time,$at_stop_time in
  [0-9]*,[0-9]*)
    as_fn_arith $at_stop_time - $at_start_time && at_duration_s=$as_val
    as_fn_arith $at_duration_s / 60 && at_duration_m=$as_val
    as_fn_arith $at_duration_m / 60 && at_duration_h=$as_val
    as_fn_arith $at_duration_s % 60 && at_duration_s=$as_val
    as_fn_arith $at_duration_m % 60 && at_duration_m=$as_val
    at_duration="${at_duration_h}h ${at_duration_m}m ${at_duration_s}s"
    printf "%s\n" "$as_me: test suite duration: $at_duration" >&5
    ;;
esac

echo
printf "%s\n" "## ------------- ##
## Test results. ##
## ------------- ##"
echo
{
  echo
  printf "%s\n" "## ------------- ##
## Test results. ##
## ------------- ##"
  echo
} >&5

if test $at_run_count = 1; then
  at_result="1 test"
  at_were=was
else
  at_result="$at_run_count tests"
  at_were=were
fi
if $at_errexit_p && test $at_unexpected_count != 0; then
  if test $at_xpass_count = 1; then
    at_result="$at_result $at_were run, one passed"
  else
    at_result="$at_result $at_were run, one failed"
  fi
  at_result="$at_result unexpectedly and inhibited subsequent tests."
  at_color=$at_red
else
  # Don't you just love exponential explosion of the number of cases?
  at_color=$at_red
  case $at_xpass_count:$at_fail_count:$at_xfail_count in
    # So far, so good.
    0:0:0) at_result="$at_result $at_were successful." at_color=$at_grn ;;
    0:0:*) at_result="$at_result behaved as expected." at_color=$at_lgn ;;

    # Some unexpected failures
    0:*:0) at_result="$at_result $at_were run,
$at_fail_count failed unexpectedly." ;;

    # Some failures, both expected and unexpected
    0:*:1) at_result="$at_result $at_were run,
$at_total_fail_count failed ($at_xfail_count expected failure)." ;;
    0:*:*) at_result="$at_result $at_were run,
$at_total_fail_count failed ($at_xfail_count expected failures)." ;;

    # No unexpected failures, but some xpasses
    *:0:*) at_result="$at_result $at_were run,
$at_xpass_count passed unexpectedly." ;;

    # No expected failures, but failures and xpasses
    *:1:0) at_result="$at_result $at_were run,
$at_unexpected_count did not behave as expected ($at_fail_count unexpected failure)." ;;
    *:*:0) at_result="$at_result $at_were run,
$at_unexpected_count did not behave as expected ($at_fail_count unexpected failures)." ;;

    # All of them.
    *:*:1) at_result="$at_result $at_were run,
$at_xpass_count passed unexpectedly,
$at_total_fail_count failed ($at_xfail_count expected failure)." ;;
    *:*:*) at_result="$at_result $at_were run,
$at_xpass_count passed unexpectedly,
$at_total_fail_count failed ($at_xfail_count expected failures)." ;;
  esac

  if test $at_skip_count = 0 && test $at_run_count -gt 1; then
    at_result="All $at_result"
  fi
fi

# Now put skips in the mix.
case $at_skip_count in
  0) ;;
  1) at_result="$at_result
1 test was skipped." ;;
  *) at_result="$at_result
$at_skip_count tests were skipped." ;;
esac

if test $at_unexpected_count = 0; then
  echo "$at_color$at_result$at_std"
  echo "$at_result" >&5
else
  echo "${at_color}ERROR: $at_result$at_std" >&2
  echo "ERROR: $at_result" >&5
  {
    echo
    printf "%s\n" "## ------------------------ ##
## Summary of the failures. ##
## ------------------------ ##"

    # Summary of failed and skipped tests.
    if test $at_fail_count != 0; then
      echo "Failed tests:"
      $SHELL "$at_myself" $at_fail_list --list
      echo
    fi
    if test $at_skip_count != 0; then
      echo "Skipped tests:"
      $SHELL "$at_myself" $at_skip_list --list
      echo
    fi
    if test $at_xpass_count != 0; then
      echo "Unexpected passes:"
      $SHELL "$at_myself" $at_xpass_list --list
      echo
    fi
    if test $at_fail_count != 0; then
      printf "%s\n" "## ---------------------- ##
## Detailed failed tests. ##
## ---------------------- ##"
      echo
      for at_group in $at_fail_list
      do
  at_group_normalized=$at_group

  eval 'while :; do
    case $at_group_normalized in #(
    '"$at_format"'*) break;;
    esac
    at_group_normalized=0$at_group_normalized
  done'

  cat "$at_suite_dir/$at_group_normalized/$as_me.log"
  echo
      done
      echo
    fi
    if test -n "$at_top_srcdir"; then
      sed 'h;s/./-/g;s/^.../## /;s/...$/ ##/;p;x;p;x' <<_ASBOX
## ${at_top_build_prefix}config.log ##
_ASBOX
      sed 's/^/| /' ${at_top_build_prefix}config.log
      echo
    fi
  } >&5

  sed 'h;s/./-/g;s/^.../## /;s/...$/ ##/;p;x;p;x' <<_ASBOX
## $as_me.log was created. ##
_ASBOX

  echo
  if $at_debug_p; then
    at_msg='per-test log files'
  else
    at_msg="\`${at_testdir+${at_testdir}/}$as_me.log'"
  fi
  at_msg1a=${at_xpass_list:+', '}
  at_msg1=$at_fail_list${at_fail_list:+" failed$at_msg1a"}
  at_msg2=$at_xpass_list${at_xpass_list:+" passed unexpectedly"}

  printf "%s\n" "Please send $at_msg and all information you think might help:

   To: <bugs@openvswitch.org>
   Subject: [ovn 23.06.90] $as_me: $at_msg1$at_msg2

You may investigate any problem if you feel able to do so, in which
case the test suite provides a good starting point.  Its output may
be found below \`${at_testdir+${at_testdir}/}$as_me.dir'.
"
  exit 1
fi

exit 0

## ------------- ##
## Actual tests. ##
## ------------- ##
#AT_START_1
at_fn_group_banner 1 'multinode.at:3' \
  "ovn multinode basic test" "                       " 1
at_xfail=no
(
  printf "%s\n" "1. $at_setup_line: testing $at_desc ..."
  $at_traceon

ovs_init


# Check that ovn-fake-multinode setup is up and running
check_fake_multinode_setup

# Delete the multinode NB and OVS resources before starting the test.
cleanup_multinode_resources

# Test East-West switching
check multinode_nbctl ls-add sw0
check multinode_nbctl lsp-add sw0 sw0-port1
check multinode_nbctl lsp-set-addresses sw0-port1 "50:54:00:00:00:03 10.0.0.3 1000::3"
check multinode_nbctl lsp-add sw0 sw0-port2
check multinode_nbctl lsp-set-addresses sw0-port2 "50:54:00:00:00:04 10.0.0.4 1000::4"

m_as ovn-chassis-1 /data/create_fake_vm.sh sw0-port1 sw0p1 50:54:00:00:00:03 10.0.0.3 24 10.0.0.1 1000::3/64 1000::a
m_as ovn-chassis-2 /data/create_fake_vm.sh sw0-port2 sw0p2 50:54:00:00:00:04 10.0.0.4 24 10.0.0.1 1000::4/64 1000::a

m_wait_for_ports_up

 { set +x
printf "%s\n" "$at_srcdir/multinode.at:23: podman exec ovn-chassis-1 ip netns exec sw0p1 ping -q -c 3 -i 0.3 -w 2 10.0.0.4 | grep \"transmitted\" | sed 's/time.*ms\$/time 0ms/'"
at_fn_check_prepare_notrace 'a shell pipeline' "multinode.at:23"
( $at_check_trace; podman exec ovn-chassis-1 ip netns exec sw0p1 ping -q -c 3 -i 0.3 -w 2 10.0.0.4 | grep "transmitted" | sed 's/time.*ms$/time 0ms/'
) >>"$at_stdout" 2>>"$at_stderr" 5>&-
at_status=$? at_failed=false
$at_check_filter
at_fn_diff_devnull "$at_stderr" || at_failed=:
echo >>"$at_stdout"; printf "%s\n" "3 packets transmitted, 3 received, 0% packet loss, time 0ms
" | \
  $at_diff - "$at_stdout" || at_failed=:
at_fn_check_status \
0 $at_status "$at_srcdir/multinode.at:23"
$at_failed && at_fn_log_failure
$at_traceon; }



# Add ACLs to drop all traffic
check multinode_nbctl pg-add pg0 sw0-port1 sw0-port2
check multinode_nbctl acl-add pg0 to-lport 1001 "outport == @pg0 && ip4" drop
check multinode_nbctl --wait=sb sync

 { set +x
printf "%s\n" "$at_srcdir/multinode.at:33: podman exec ovn-chassis-1 ip netns exec sw0p1 ping -q -c 3 -i 0.3 -w 2 10.0.0.4"
at_fn_check_prepare_trace "multinode.at:33"
( $at_check_trace; podman exec ovn-chassis-1 ip netns exec sw0p1 ping -q -c 3 -i 0.3 -w 2 10.0.0.4
) >>"$at_stdout" 2>>"$at_stderr" 5>&-
at_status=$? at_failed=false
$at_check_filter
at_fn_diff_devnull "$at_stderr" || at_failed=:
echo stdout:; cat "$at_stdout"
at_fn_check_status \
1 $at_status "$at_srcdir/multinode.at:33"
$at_failed && at_fn_log_failure
$at_traceon; }



# Add ACLs to allow icmp traffic
check multinode_nbctl acl-add pg0 to-lport 1002 "outport == @pg0 && ip4 && icmp" allow-related
check multinode_nbctl --wait=sb sync

 { set +x
printf "%s\n" "$at_srcdir/multinode.at:40: podman exec ovn-chassis-1 ip netns exec sw0p1 ping -q -c 3 -i 0.3 -w 2 10.0.0.4 | grep \"transmitted\" | sed 's/time.*ms\$/time 0ms/'"
at_fn_check_prepare_notrace 'a shell pipeline' "multinode.at:40"
( $at_check_trace; podman exec ovn-chassis-1 ip netns exec sw0p1 ping -q -c 3 -i 0.3 -w 2 10.0.0.4 | grep "transmitted" | sed 's/time.*ms$/time 0ms/'
) >>"$at_stdout" 2>>"$at_stderr" 5>&-
at_status=$? at_failed=false
$at_check_filter
at_fn_diff_devnull "$at_stderr" || at_failed=:
echo >>"$at_stdout"; printf "%s\n" "3 packets transmitted, 3 received, 0% packet loss, time 0ms
" | \
  $at_diff - "$at_stdout" || at_failed=:
at_fn_check_status \
0 $at_status "$at_srcdir/multinode.at:40"
$at_failed && at_fn_log_failure
$at_traceon; }




# Create the second logical switch with one port
check multinode_nbctl ls-add sw1
check multinode_nbctl lsp-add sw1 sw1-port1
check multinode_nbctl lsp-set-addresses sw1-port1 "40:54:00:00:00:03 20.0.0.3 2000::3"

# Create a logical router and attach both logical switches
check multinode_nbctl lr-add lr0
check multinode_nbctl lrp-add lr0 lr0-sw0 00:00:00:00:ff:01 10.0.0.1/24 1000::a/64
check multinode_nbctl lsp-add sw0 sw0-lr0
check multinode_nbctl lsp-set-type sw0-lr0 router
check multinode_nbctl lsp-set-addresses sw0-lr0 router
check multinode_nbctl lsp-set-options sw0-lr0 router-port=lr0-sw0

check multinode_nbctl lrp-add lr0 lr0-sw1 00:00:00:00:ff:02 20.0.0.1/24 2000::a/64
check multinode_nbctl lsp-add sw1 sw1-lr0
check multinode_nbctl lsp-set-type sw1-lr0 router
check multinode_nbctl lsp-set-addresses sw1-lr0 router
check multinode_nbctl lsp-set-options sw1-lr0 router-port=lr0-sw1

m_as ovn-chassis-2 /data/create_fake_vm.sh sw1-port1 sw1p1 40:54:00:00:00:03 20.0.0.3 24 20.0.0.1 2000::4/64 1000::a

m_wait_for_ports_up sw1-port1

 { set +x
printf "%s\n" "$at_srcdir/multinode.at:69: podman exec ovn-chassis-1 ip netns exec sw0p1 ping -q -c 3 -i 0.3 -w 2 20.0.0.3 | grep \"transmitted\" | sed 's/time.*ms\$/time 0ms/'"
at_fn_check_prepare_notrace 'a shell pipeline' "multinode.at:69"
( $at_check_trace; podman exec ovn-chassis-1 ip netns exec sw0p1 ping -q -c 3 -i 0.3 -w 2 20.0.0.3 | grep "transmitted" | sed 's/time.*ms$/time 0ms/'
) >>"$at_stdout" 2>>"$at_stderr" 5>&-
at_status=$? at_failed=false
$at_check_filter
at_fn_diff_devnull "$at_stderr" || at_failed=:
echo >>"$at_stdout"; printf "%s\n" "3 packets transmitted, 3 received, 0% packet loss, time 0ms
" | \
  $at_diff - "$at_stdout" || at_failed=:
at_fn_check_status \
0 $at_status "$at_srcdir/multinode.at:69"
$at_failed && at_fn_log_failure
$at_traceon; }



ovs_cleanup
  set +x
  $at_times_p && times >"$at_times_file"
) 5>&1 2>&1 7>&- | eval $at_tee_pipe
read at_status <"$at_status_file"
#AT_STOP_1
