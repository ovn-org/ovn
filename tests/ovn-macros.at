# OVN_CLEANUP_VSWITCH(sim)
#
# Gracefully terminate vswitch daemons in the
# specified sandbox.
m4_define([OVN_CLEANUP_VSWITCH],[
    echo
    echo "$1: clean up vswitch"
    as $1
    OVS_APP_EXIT_AND_WAIT([ovs-vswitchd])
    OVS_APP_EXIT_AND_WAIT([ovsdb-server])
])

# OVN_CLEANUP_SBOX(sbox)
#
# Gracefully terminate OVN daemons in the specified
# sandbox instance. The sandbox name "vtep" is treated
# as a special case, and is assumed to have ovn-controller-vtep
# and ovs-vtep daemons running instead of ovn-controller.
m4_define([OVN_CLEANUP_SBOX],[
    echo
    echo "$1: clean up sandbox"
    as $1
    if test "$1" = "vtep"; then
        OVS_APP_EXIT_AND_WAIT([ovn-controller-vtep])
        OVS_APP_EXIT_AND_WAIT([ovs-vtep])
    else
        OVS_APP_EXIT_AND_WAIT([ovn-controller])
    fi
    OVN_CLEANUP_VSWITCH([$1])
])

# OVN_CLEANUP(sim [, sim ...])
#
# Gracefully terminate all OVN daemons, including those in the
# specified sandbox instances.
m4_define([OVN_CLEANUP],[
    m4_foreach([sbox], [$@], [
        OVN_CLEANUP_SBOX([sbox])
    ])

    echo
    echo "clean up OVN"
    as ovn-sb
    OVS_APP_EXIT_AND_WAIT([ovsdb-server])

    as ovn-nb
    OVS_APP_EXIT_AND_WAIT([ovsdb-server])

    as northd
    OVS_APP_EXIT_AND_WAIT([[$NORTHD_TYPE]])

    if test -d northd-backup; then
        as northd-backup
        OVS_APP_EXIT_AND_WAIT([[$NORTHD_TYPE]])
    fi

    OVN_CLEANUP_VSWITCH([main])
])

# OVN_CLEANUP_AZ(az)
#
# Gracefully terminate all OVN daemons, including those in the
# specified sandbox instances.
m4_define([OVN_CLEANUP_AZ],[
    echo
    echo "$1: clean up availability zone"
    as $1/ovn-sb
    OVS_APP_EXIT_AND_WAIT([ovsdb-server])

    as $1/ovn-nb
    OVS_APP_EXIT_AND_WAIT([ovsdb-server])

    as $1/northd
    OVS_APP_EXIT_AND_WAIT([[$NORTHD_TYPE]])

    if test -d $1/northd-backup; then
        as $1/northd-backup
        OVS_APP_EXIT_AND_WAIT([[$NORTHD_TYPE]])
    fi

    as $1/ic
    OVS_APP_EXIT_AND_WAIT([ovn-ic])
])

# OVN_CLEANUP_IC([az ...])
#
# Gracefully terminate all interconnection DBs, and daemons in the
# specified AZs, if any.
m4_define([OVN_CLEANUP_IC],[
    m4_foreach([az], [$@], [
        OVN_CLEANUP_AZ([az])
    ])

    echo
    echo "clean up interconnection"
    as ovn-ic-sb
    OVS_APP_EXIT_AND_WAIT([ovsdb-server])

    as ovn-ic-nb
    OVS_APP_EXIT_AND_WAIT([ovsdb-server])

    if test -d "$ovs_base"/main; then
        OVN_CLEANUP_VSWITCH([main])
    fi
])

m4_divert_push([PREPARE_TESTS])

# ovn_init_db DATABASE [AZ]
#
# Creates and initializes the given DATABASE (one of "ovn-sb" or "ovn-nb"),
# starts its ovsdb-server instance, and sets the appropriate environment
# variable (OVN_SB_DB or OVN_NB_DB) so that ovn-sbctl or ovn-nbctl uses the
# database by default.
#
# Usually invoked from ovn_start.
ovn_init_db () {
    echo "${AZ:+$AZ: }creating $1 database"
    local as_d=$1
    if test -n "$2"; then
        as_d=$2/$as_d
    fi
    local d=$ovs_base/$as_d
    mkdir "$d" || return 1
    : > "$d"/.$1.db.~lock~
    as $as_d ovsdb-tool create "$d"/$1.db "$abs_top_srcdir"/$1.ovsschema

    local remote_in_db=
    if test X$HAVE_OPENSSL = Xyes -a X"$1" = X"ovn-sb"; then
        remote_in_db="--remote=db:OVN_Southbound,SB_Global,connections --private-key=$PKIDIR/testpki-test-privkey.pem --certificate=$PKIDIR/testpki-test-cert.pem --ca-cert=$PKIDIR/testpki-cacert.pem"
    fi

    as $as_d start_daemon ovsdb-server \
        -vjsonrpc \
        --remote=punix:"$d"/$1.sock \
        $remote_in_db \
        "$d"/$1.db

    local var=`echo $1_db | tr a-z- A-Z_`
    AS_VAR_SET([$var], [unix:"$d"/$1.sock]); export $var
}

# ovn_init_ic_db
#
# Creates and initializes ovn-ic-nb and ovn-ic-sb databases and starts their
# ovsdb-server instances, for OVN interconnection.
ovn_init_ic_db () {
    ovn_init_db ovn-ic-nb
    ovn_init_db ovn-ic-sb
}

# ovn_start_northd [--paused] (primary|backup) [AZ]
ovn_start_northd() {
    local northd_args=
    case $1 in
        --paused) northd_args=--dry-run; shift ;;
    esac
    local priority=$1
    local AZ=$2
    local msg_prefix=${AZ:+$AZ: }
    local d_prefix=${AZ:+$AZ/}

    local suffix=
    case $priority in
        backup) suffix=-backup ;;
    esac

    case ${NORTHD_TYPE:=ovn-northd} in
        ovn-northd) ;;
        ovn-northd-ddlog) northd_args="$northd_args --ddlog-record=${AZ:+$AZ/}northd$suffix/replay.dat -v" ;;
    esac

    if test X$NORTHD_USE_PARALLELIZATION = Xyes; then
        northd_args="$northd_args --n-threads=4"
    fi

    local name=${d_prefix}northd${suffix}
    echo "${prefix}starting $name"
    test -d "$ovs_base/$name" || mkdir "$ovs_base/$name"
    as $name start_daemon $NORTHD_TYPE $northd_args -vjsonrpc \
               --ovnnb-db=$OVN_NB_DB --ovnsb-db=$OVN_SB_DB
}

# ovn_start [--backup-northd=none|paused] [AZ]
#
# Creates and initializes ovn-sb and ovn-nb databases and starts their
# ovsdb-server instance, sets appropriate environment variables so that
# ovn-sbctl and ovn-nbctl use them by default, and starts ovn-northd running
# against them.
#
# Normally this starts only an active northd and no backup northd.  The following
# options are accepted to adjust that:
#   --backup-northd         Start a backup northd.
#   --backup-northd=paused  Start the backup northd in the paused state.
#   --use-tcp-to-sb         Use tcp to connect to sb.
ovn_start () {
    local backup_northd=false
    local backup_northd_options=
    case $1 in
        --backup-northd) backup_northd=true; shift ;;
        --backup-northd=paused) backup_northd=true; backup_northd_options=--paused; shift ;;
        --use-tcp-to-sb) use_tcp=true; shift ;;
    esac
    local AZ=$1
    local msg_prefix=${AZ:+$AZ: }
    local d_prefix=${AZ:+$AZ/}

    if test -n "$AZ"; then
        mkdir "$ovs_base"/$AZ
    fi

    ovn_init_db ovn-sb $1; ovn-sbctl init
    ovn_init_db ovn-nb $1; ovn-nbctl init
    if test -n "$1"; then
        ovn-nbctl set NB_Global . name=$1
    fi

    ovn_start_northd primary $AZ
    if $backup_northd; then
        ovn_start_northd $backup_northd_options backup $AZ
    fi

    if test $use_tcp; then
        # Create the SB DB ptcp connection.
        ovn-sbctl \
            -- --id=@c create connection \
                target=\"ptcp:0:127.0.0.1\" \
            -- add SB_Global . connections @c
    elif test X$HAVE_OPENSSL = Xyes; then
        # Create the SB DB pssl+RBAC connection.
        ovn-sbctl \
            -- --id=@c create connection \
                target=\"pssl:0:127.0.0.1\" role=ovn-controller \
            -- add SB_Global . connections @c
        local d=$ovs_base
        if test -n "$AZ"; then
            d=$d/$AZ
        fi
        PARSE_LISTENING_PORT([$d/ovn-sb/ovsdb-server.log], [TCP_PORT])
        var="SSL_OVN_SB_DB"
        AS_VAR_SET([$var], [ssl:127.0.0.1:$TCP_PORT]); export $var
    fi

    if test -n "$AZ"; then
        ovn-nbctl --wait=sb sync || exit $?

        echo "${msg_prefix}starting ovn-ic"
        mkdir "$ovs_base"/$d_prefix/ic
        as $d_prefix/ic start_daemon ovn-ic -v \
               --ovnnb-db=$OVN_NB_DB --ovnsb-db=$OVN_SB_DB \
               --ic-nb-db=unix:"$ovs_base"/ovn-ic-nb/ovn-ic-nb.sock \
               --ic-sb-db=unix:"$ovs_base"/ovn-ic-sb/ovn-ic-sb.sock
    fi
}

# Interconnection networks.
#
# When multiple sandboxed Open vSwitch instances exist, one will inevitably
# want to connect them together.  These commands allow for that.  Conceptually,
# an interconnection network is a switch for which these functions make it easy
# to plug into other switches in other sandboxed Open vSwitch instances.
# Interconnection networks are implemented as bridges in a switch named "main",
# so to use interconnection networks please avoid working with that switch
# directly.

# net_add NETWORK
#
# Creates a new interconnection network named NETWORK.
net_add () {
    test -d "$ovs_base"/main || sim_add main || return 1
    as main ovs-vsctl add-br "$1"
}

# net_attach NETWORK BRIDGE
#
# Adds a new port to BRIDGE in the default sandbox (as set with as()) and plugs
# it into the NETWORK interconnection network.  NETWORK must already have been
# created by a previous invocation of net_add.  The default sandbox must not be
# "main".
net_attach () {
    local net=$1 bridge=$2

    local port=${sandbox}_$bridge
    as main ovs-vsctl \
        -- add-port $net $port \
        -- set Interface $port options:pstream="punix:$ovs_base/main/$port.sock" options:rxq_pcap="$ovs_base/main/$port-rx.pcap" options:tx_pcap="$ovs_base/main/$port-tx.pcap" \
        || return 1

    ovs-vsctl \
        -- set Interface $bridge options:tx_pcap="$ovs_base/$sandbox/$bridge-tx.pcap" options:rxq_pcap="$ovs_base/$sandbox/$bridge-rx.pcap" \
        -- add-port $bridge ${bridge}_$net \
        -- set Interface ${bridge}_$net options:stream="unix:$ovs_base/main/$port.sock" options:rxq_pcap="$ovs_base/$sandbox/${bridge}_$net-rx.pcap" options:tx_pcap="$ovs_base/$sandbox/${bridge}_$net-tx.pcap" \
        || return 1
}

ovn_wait_for_encaps() {
    local systemid=$1

    if [[ -f "${OVN_SYSCONFDIR}/system-id-override" ]]; then
        systemid=$(cat ${OVN_SYSCONFDIR}/system-id-override)
    fi

    local encap=$(ovs-vsctl get Open_vSwitch . external_ids:ovn-encap-type-$systemid)
    if [[ -z "$encap" ]]; then
        encap=$(ovs-vsctl get Open_vSwitch . external_ids:ovn-encap-type)
    fi
    encap=$(tr -d '"' <<< $encap)

    local ip=$(ovs-vsctl get Open_vSwitch . external_ids:ovn-encap-ip-$systemid)
    if [[ -z "$ip" ]]; then
        ip=$(ovs-vsctl get Open_vSwitch . external_ids:ovn-encap-ip)
    fi
    ip=$(tr -d '"' <<< $ip)

    IFS="," read -r -a encap_types <<< "$encap"
    for e in "${encap_types[[@]]}"; do
        wait_column "$ip" sb:Encap ip chassis_name="$systemid" type="$e"
    done
}

# ovn_az_attach AZ NETWORK BRIDGE IP [MASKLEN] [ENCAP]
ovn_az_attach() {
    local az=$1 net=$2 bridge=$3 ip=$4 masklen=${5-24} encap=${6-geneve,vxlan}
    local systemid=${7-$sandbox} systemid_override=$8
    net_attach $net $bridge || return 1

    local expected_encap_id=$systemid
    local cli_args=""
    if [[ -n "$systemid_override" ]]; then
        cli_args="-n $systemid_override"
        expected_encap_id=$systemid_override
    fi

    mac=`ovs-vsctl get Interface $bridge mac_in_use | sed s/\"//g`
    arp_table="$arp_table $sandbox,$bridge,$ip,$mac"
    if test -z $(echo $ip | sed '/:/d'); then
        ipversion="6"
    else
        ipversion="4"
    fi
    ovs-appctl netdev-dummy/ip${ipversion}addr $bridge $ip/$masklen >/dev/null || return 1
    ovs-appctl ovs/route/add $ip/$masklen $bridge >/dev/null || return 1

    local ovn_remote
    if test X"$az" = XNONE; then
        if test X$HAVE_OPENSSL = Xyes; then
            ovn_remote=$SSL_OVN_SB_DB
        else
            ovn_remote=unix:$ovs_base/ovn-sb/ovn-sb.sock
        fi
    else
        ovn_remote=unix:$ovs_base/$az/ovn-sb/ovn-sb.sock
    fi
    ovs-vsctl \
        -- set Open_vSwitch . external-ids:hostname=$sandbox \
        -- set Open_vSwitch . external-ids:system-id=$systemid \
        -- set Open_vSwitch . external-ids:ovn-remote=$ovn_remote \
        -- set Open_vSwitch . external-ids:ovn-encap-type=$encap \
        -- set Open_vSwitch . external-ids:ovn-encap-ip=$ip \
        -- --may-exist add-br br-int \
        -- set bridge br-int fail-mode=secure other-config:disable-in-band=true \
        || return 1

    # currently this is the optimal place to add the ovn-monitor-all=true option,
    # this can be implemented in a different way by redefining the sim-add function
    # to add the ovn-related external-ids when we add a new simulated node via sim-add.
    #
    if test X$OVN_MONITOR_ALL = Xyes; then
        ovs-vsctl set open . external_ids:ovn-monitor-all=true
    fi

    start_daemon ovn-controller --enable-dummy-vif-plug ${cli_args} || return 1
    if test X"$az" = XNONE; then
        ovn_wait_for_encaps $expected_encap_id
    else
        ovn_as $az ovn_wait_for_encaps $expected_encap_id
    fi
}

# ovn_attach NETWORK BRIDGE IP [MASKLEN] [ENCAP]
#
# First, this command attaches BRIDGE to interconnection network NETWORK, just
# like "net_attach NETWORK BRIDGE".  Second, it configures (simulated) IP
# address IP (with network mask length MASKLEN, which defaults to 24) on
# BRIDGE.  Finally, it configures the Open vSwitch database to work with OVN
# and starts ovn-controller.
ovn_attach() {
    ovn_az_attach NONE $@
}

# This function is similar to ovn_attach but makes sure it doesn't
# mess with another controller settings
start_virtual_controller() {
    local net=$1 bridge=$2 int_bridge=$3 ip=$4 masklen=${5-24} encap=${6-geneve,vxlan} systemid=${7-$sandbox} cli_args=${@:8}
    net_attach $net $bridge || return 1

    mac=`ovs-vsctl get Interface $bridge mac_in_use | sed s/\"//g`
    arp_table="$arp_table $sandbox,$bridge,$ip,$mac"
    ovs-appctl netdev-dummy/ip4addr $bridge $ip/$masklen >/dev/null || return 1
    ovs-appctl ovs/route/add $ip/$masklen $bridge >/dev/null || return 1

    local ovn_remote
    if test X$HAVE_OPENSSL = Xyes; then
        ovn_remote=$SSL_OVN_SB_DB
    else
        ovn_remote=unix:$ovs_base/ovn-sb/ovn-sb.sock
    fi
    ovs-vsctl \
        -- set Open_vSwitch . external-ids:ovn-remote-$systemid=$ovn_remote \
        -- set Open_vSwitch . external-ids:ovn-encap-type-$systemid=$encap \
        -- set Open_vSwitch . external-ids:ovn-encap-ip-$systemid=$ip \
        -- set Open_vSwitch . external-ids:ovn-bridge-$systemid=$int_bridge \
        -- --may-exist add-br $int_bridge \
        -- set bridge $int_bridge fail-mode=secure other-config:disable-in-band=true \
        || return 1

    ovn-controller --enable-dummy-vif-plug ${cli_args} -vconsole:off --detach --no-chdir
    ovn_wait_for_encaps $systemid
}

# ovn_setenv AZ
ovn_setenv () {
    local d=$ovs_base/$1
    AS_VAR_SET([OVN_NB_DB], [unix:"$d"/ovn-nb/ovn-nb.sock]); export $var
    AS_VAR_SET([OVN_SB_DB], [unix:"$d"/ovn-sb/ovn-sb.sock]); export $var
}

# ovs_as AZ
ovn_as() {
    if test "X$2" != X; then
        (ovn_setenv $1; shift; "$@")
    else
        ovn_setenv $1
    fi
}

# OVN_POPULATE_ARP
#
# This pre-populates the ARP tables of all of the OVN instances that have been
# started with ovn_attach().  That means that packets sent from one hypervisor
# to another never get dropped or delayed by ARP resolution, which makes
# testing easier.
ovn_populate_arp__() {
    for e1 in $arp_table; do
        set `echo $e1 | sed 's/,/ /g'`; sb1=$1 br1=$2 ip=$3 mac=$4
        for e2 in $arp_table; do
            set `echo $e2 | sed 's/,/ /g'`; sb2=$1 br2=$2
            if test $sb1,$br1 != $sb2,$br2; then
                as $sb2 ovs-appctl tnl/neigh/set $br2 $ip $mac || return 1
            fi
        done
    done
}
m4_divert_pop([PREPARE_TESTS])

OVS_START_SHELL_HELPERS
# check COMMAND...
#
# Runs COMMAND and checks that it succeeds without any output.
check() {
    echo "$@"
    AT_CHECK(["$@"])
}

parse_db() {
    case $1 in
        (*:*) echo ${1%%:*} ;;
        (*) echo sb ;;
    esac
}

parse_table() {
    case $1 in
        (*:*) echo ${1##*:} ;;
        (*) echo $1 ;;
    esac
}

# count_rows TABLE [CONDITION...]
#
# Prints the number of rows in TABLE (that satisfy CONDITION).
# Uses the southbound db by default; set DB=nb for the northbound database.
count_rows() {
    local db=$(parse_db $1) table=$(parse_table $1); shift
    ovn-${db}ctl --format=table --no-headings find $table "$@" | wc -l
}

# check_row_count [DATABASE:]TABLE COUNT [CONDITION...]
#
# Checks that TABLE contains COUNT rows (that satisfy CONDITION).
# The default DATABASE is "sb".
check_row_count() {
    local db=$(parse_db $1) table=$(parse_table $1); shift
    local count=$1; shift
    local found=$(count_rows $db:$table "$@")
    echo
    echo "Checking for $count rows in $db $table${1+ with $*}... found $found"
    if test "$count" != "$found"; then
        ovn-${db}ctl list $table
        AT_FAIL_IF([:])
    fi
}

# wait_row_count [DATABASE:]TABLE COUNT [CONDITION...]
#
# Waits until TABLE contains COUNT rows (that satisfy CONDITION).
# The default DATABASE is "sb".
wait_row_count() {
    local db=$(parse_db $1) table=$(parse_table $1); shift
    local count=$1; shift
    local a=$1 b=$2 c=$3 d=$4 e=$5
    echo "Waiting until $count rows in $db $table${1+ with $*}..."
    OVS_WAIT_UNTIL([test $count = $(count_rows $db:$table $a $b $c $d $e)],[
      echo "$db table $table has the following rows. $(count_rows $db:$table $a $b $c $d $e) rows match instead of expected $count:"
      ovn-${db}ctl list $table])
}

# fetch_column [DATABASE:]TABLE COLUMN [CONDITION...]
#
# Fetches and prints all the values of COLUMN in the rows of TABLE
# (that satisfy CONDITION), sorting the results lexicographically.
# The default DATABASE is "sb".
fetch_column() {
    local db=$(parse_db $1) table=$(parse_table $1) column=${2-_uuid}; shift; shift
    # Using "echo" removes spaces and newlines.
    echo $(ovn-${db}ctl --bare --columns $column find $table "$@" | sort)
}

# check_column EXPECTED [DATABASE:]TABLE COLUMN [CONDITION...]
#
# Fetches all of the values of COLUMN in the rows of TABLE (that
# satisfy CONDITION), and compares them against EXPECTED (ignoring
# order).
#
# The default DATABASE is "sb".
check_column() {
    local expected=$1 db=$(parse_db $2) table=$(parse_table $2) column=${3-_uuid}; shift; shift; shift
    local found=$(ovn-${db}ctl --bare --columns $column find $table "$@")

    # Sort the expected and found values.
    local found=$(for d in $found; do echo $d; done | sort)
    local expected=$(for d in $expected; do echo $d; done | sort)

    echo
    echo "Checking values in $db $table${1+ with $*} against $expected... found $found"
    if test "$found" != "$expected"; then
        ovn-${db}ctl list $table
        AT_FAIL_IF([:])
    fi
}

# wait_column EXPECTED [DATABASE:]TABLE [COLUMN [CONDITION...]]
#
# Wait until all of the values of COLUMN in the rows of TABLE (that
# satisfy CONDITION) equal EXPECTED (ignoring order).
#
# The default DATABASE is "sb".
#
# COLUMN defaults to _uuid if unspecified.
wait_column() {
    local expected=$(for d in $1; do echo $d; done | sort)
    local db=$(parse_db $2) table=$(parse_table $2) column=${3-_uuid}; shift; shift; shift
    local a=$1 b=$2 c=$3 d=$4 e=$5

    echo
    echo "Waiting until $column in $db $table${1+ with $*} is $expected..."
    OVS_WAIT_UNTIL([
      found=$(ovn-${db}ctl --bare --columns $column find $table $a $b $c $d $e)
      found=$(for d in $found; do echo $d; done | sort)
      test "$expected" = "$found"
    ], [
      echo "$column in $db table $table has value $found, from the following rows:"
      ovn-${db}ctl list $table])
}

# wait_for_ports_up [PORT...]
#
# With arguments, waits for specified Logical_Switch_Ports to come up.
# Without arguments, waits for all "plain" and router
# Logical_Switch_Ports to come up.
wait_for_ports_up() {
    if test $# = 0; then
        wait_row_count nb:Logical_Switch_Port 0 up!=true type='""'
        wait_row_count nb:Logical_Switch_Port 0 up!=true type=router
    else
        for port; do
            wait_row_count nb:Logical_Switch_Port 1 up=true name=$port
        done
    fi
}

# reset_pcap_file iface pcap_file
# Resets the pcap file associates with OVS interface.  should be used
# with dummy datapath.
reset_pcap_file() {
    local iface=$1
    local pcap_file=$2
    check rm -f dummy-*.pcap
    check ovs-vsctl -- set Interface $iface options:tx_pcap=dummy-tx.pcap \
options:rxq_pcap=dummy-rx.pcap
    check rm -f ${pcap_file}*.pcap
    check ovs-vsctl -- set Interface $iface options:tx_pcap=${pcap_file}-tx.pcap \
options:rxq_pcap=${pcap_file}-rx.pcap
}

# Receive a packet on a dummy netdev interface. If we expect packets to be
# recorded, then wait until the pcap file reflects the change.
netdev_dummy_receive() {
    local interface="$1"
    local packet="$2"
    local hv="$3"
    local pcap_file="$4"

    if test -n "pcap_file" ; then
        ts_old=$(stat -c %y "$pcap_file")
    fi
    if test -n "$hv" ; then
        as "$hv" ovs-appctl netdev-dummy/receive "$interface" "$packet"
    else
        ovs-appctl netdev-dummy/receive "$interface" "$packet"
    fi
    if test -n "$pcap_file" ; then
        OVS_WAIT_WHILE(
          [ts_new=$(stat -c %y "$pcap_file")
           test "$ts_new" = "$ts_old"])
    fi
}

# send_igmp_v3_report INPORT HV ETH_SRC IP_SRC IP_CSUM GROUP REC_TYPE
#                     IGMP_CSUM OUTFILE
#
# This shell function causes an IGMPv3 report to be received on INPORT of HV.
# The packet's content has Ethernet destination 01:00:5E:00:00:22 and source
# ETH_SRC (exactly 12 hex digits). Ethernet type is set to IP.
# GROUP is the IP multicast group to be joined/to leave (based on REC_TYPE).
# REC_TYPE == 04: join GROUP
# REC_TYPE == 03: leave GROUP
# The packet hexdump is also stored in OUTFILE.
#
send_igmp_v3_report() {
    local inport=$1 hv=$2 eth_src=$3 ip_src=$4 ip_chksum=$5 group=$6
    local rec_type=$7 igmp_chksum=$8 outfile=$9

    local eth_dst=01005e000016
    local ip_dst=$(ip_to_hex 224 0 0 22)
    local ip_ttl=01
    local ip_ra_opt=94040000

    local igmp_type=2200
    local num_rec=00000001
    local aux_dlen=00
    local num_src=0000

    local eth=${eth_dst}${eth_src}0800
    local ip=46c0002800004000${ip_ttl}02${ip_chksum}${ip_src}${ip_dst}${ip_ra_opt}
    local igmp=${igmp_type}${igmp_chksum}${num_rec}${rec_type}${aux_dlen}${num_src}${group}
    local packet=${eth}${ip}${igmp}

    echo ${packet} >> ${outfile}
    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# store_igmp_v3_query ETH_SRC IP_SRC IP_CSUM OUTFILE
#
# This shell function builds an IGMPv3 general query from ETH_SRC and IP_SRC
# and stores the hexdump of the packet in OUTFILE.
#
store_igmp_v3_query() {
    local eth_src=$1 ip_src=$2 ip_chksum=$3 outfile=$4

    local eth_dst=01005e000001
    local ip_dst=$(ip_to_hex 224 0 0 1)
    local ip_ttl=01
    local igmp_type=11
    local max_resp=0a
    local igmp_chksum=eeeb
    local addr=00000000

    local eth=${eth_dst}${eth_src}0800
    local ip=4500002000004000${ip_ttl}02${ip_chksum}${ip_src}${ip_dst}
    local igmp=${igmp_type}${max_resp}${igmp_chksum}${addr}000a0000
    local packet=${eth}${ip}${igmp}

    echo ${packet} >> ${outfile}
}

# send_igmp_v3_query INPORT HV ETH_SRC IP_SRC IP_CSUM OUTFILE
#
# This shell function builds and sends an IGMPv3 general query from
# ETH_SRC and IP_SRC and stores the hexdump of the packet in OUTFILE.
#
send_igmp_v3_query() {
    local inport=$1 hv=$2 eth_src=$3 ip_src=$4 ip_chksum=$5 outfile=$6

    local eth_dst=01005e000001
    local ip_dst=$(ip_to_hex 224 0 0 1)
    local ip_ttl=01
    local igmp_type=11
    local max_resp=0a
    local igmp_chksum=eeeb
    local addr=00000000

    local eth=${eth_dst}${eth_src}0800
    local ip=4500002000004000${ip_ttl}02${ip_chksum}${ip_src}${ip_dst}
    local igmp=${igmp_type}${max_resp}${igmp_chksum}${addr}000a0000
    local packet=${eth}${ip}${igmp}

    echo ${packet} >> ${outfile}
    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# send_ip_multicast_pkt INPORT HV ETH_SRC ETH_DST IP_SRC IP_DST IP_LEN TTL
#    IP_CHKSUM IP_PROTO DATA
#
# This shell function causes an IP multicast packet to be received on INPORT
# of HV.
# The hexdump of the packet is stored in OUTFILE.
#
send_ip_multicast_pkt() {
    local inport=$1 hv=$2 eth_src=$3 eth_dst=$4
    local ip_src=$5 ip_dst=$6 ip_len=$7 ip_ttl=$8 ip_chksum=$9 proto=${10}
    local data=${11}

    local eth=${eth_dst}${eth_src}0800
    local ip=450000${ip_len}95f14000${ip_ttl}${proto}${ip_chksum}${ip_src}${ip_dst}
    local packet=${eth}${ip}${data}

    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# store_ip_multicast_pkt ETH_SRC ETH_DST IP_SRC IP_DST IP_LEN TTL
#    IP_CHKSUM IP_PROTO DATA OUTFILE
#
# This shell function builds an IP multicast packet and stores the hexdump of
# the packet in OUTFILE.
#
store_ip_multicast_pkt() {
    local eth_src=$1 eth_dst=$2
    local ip_src=$3 ip_dst=$4 ip_len=$5 ip_ttl=$6 ip_chksum=$7 proto=$8
    local data=$9 outfile=${10}

    local eth=${eth_dst}${eth_src}0800
    local ip=450000${ip_len}95f14000${ip_ttl}${proto}${ip_chksum}${ip_src}${ip_dst}
    local packet=${eth}${ip}${data}

    echo ${packet} >> ${outfile}
}

# send_mld_v2_report INPORT HV ETH_SRC IP_SRC GROUP REC_TYPE
#                    MLD_CSUM OUTFILE
#
# This shell function causes an MLDv2 report to be received on INPORT of HV.
# The packet's content has Ethernet destination 33:33:00:00:00:16 and source
# ETH_SRC (exactly 12 hex digits). Ethernet type is set to IPv6.
# GROUP is the IPv6 multicast group to be joined/to leave (based on REC_TYPE).
# REC_TYPE == 04: join GROUP
# REC_TYPE == 03: leave GROUP
# The packet hexdump is also stored in OUTFILE.
#
send_mld_v2_report() {
    local inport=$1 hv=$2 eth_src=$3 ip_src=$4 group=$5
    local rec_type=$6 mld_chksum=$7 outfile=$8

    local eth_dst=333300000016
    local ip_dst=ff020000000000000000000000000016
    local ip_ttl=01
    local ip_ra_opt=3a00050200000100

    local mld_type=8f
    local mld_code=00
    local num_rec=0001
    local aux_dlen=00
    local num_src=0000

    local eth=${eth_dst}${eth_src}86dd
    local ip=60000000002400${ip_ttl}${ip_src}${ip_dst}${ip_ra_opt}
    local mld=${mld_type}${mld_code}${mld_chksum}0000${num_rec}${rec_type}${aux_dlen}${num_src}${group}
    local packet=${eth}${ip}${mld}

    echo ${packet} >> ${outfile}
    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# store_mld_query ETH_SRC IP_SRC OUTFILE
#
# This shell function builds an MLD general query from ETH_SRC and IP_SRC
# and stores the hexdump of the packet in OUTFILE.
#
store_mld_query() {
    local eth_src=$1 ip_src=$2 outfile=$3

    local eth_dst=333300000000
    local ip_dst=ff020000000000000000000000000001
    local ip_ttl=01
    local ip_ra_opt=3a00050200000000

    local mld_type=82
    local mld_code=00
    local max_resp=03e8
    local mld_chksum=7b3d
    local addr=00000000000000000000000000000000

    local eth=${eth_dst}${eth_src}86dd
    local ip=60000000002400${ip_ttl}${ip_src}${ip_dst}${ip_ra_opt}
    local mld=${mld_type}${mld_code}${mld_chksum}${max_resp}0000${addr}00010000
    local packet=${eth}${ip}${mld}

    echo ${packet} >> ${outfile}
}

# send_ip6_multicast_pkt INPORT HV ETH_SRC ETH_DST IP_SRC IP_DST IP_LEN TTL
#    IP_PROTO DATA
#
# This shell function causes an IP multicast packet to be received on INPORT
# of HV.
#
send_ip6_multicast_pkt() {
    local inport=$1 hv=$2 eth_src=$3 eth_dst=$4
    local ip_src=$5 ip_dst=$6 ip_len=$7 ip_ttl=$8 proto=$9
    local data=${10}

    local eth=${eth_dst}${eth_src}86dd
    local ip=60000000${ip_len}${proto}${ip_ttl}${ip_src}${ip_dst}
    local packet=${eth}${ip}${data}

    check as $hv ovs-appctl netdev-dummy/receive ${inport} ${packet}
}

# store_ip6_multicast_pkt ETH_SRC ETH_DST IP_SRC IP_DST IP_LEN TTL
#    IP_PROTO DATA OUTFILE
#
# This shell function builds an IP multicast packet and stores the hexdump of
# the packet in OUTFILE.
#
store_ip6_multicast_pkt() {
    local eth_src=$1 eth_dst=$2
    local ip_src=$3 ip_dst=$4 ip_len=$5 ip_ttl=$6 proto=$7
    local data=$8 outfile=$9

    local eth=${eth_dst}${eth_src}86dd
    local ip=60000000${ip_len}${proto}${ip_ttl}${ip_src}${ip_dst}
    local packet=${eth}${ip}${data}

    echo ${packet} >> ${outfile}
}

# Wrapper on top of ovn-trace, stripping some things and storing the trace
# output to a file called 'trace'.  For now it strips the rows starting
# with a '#'.  This should correspond to the flow key and might be displayed
# differently by different OVS library versions.
ovn_trace() {
    AT_CAPTURE_FILE([trace])
    ovn-trace "$@" | tee trace | sed '/^# /d'
}

# Same as ovn_trace() except that it connects to an ovn-trace daemon.
ovn_trace_client() {
    target=$1; shift
    AT_CAPTURE_FILE([trace])
    ovs-appctl -t $target trace "$@" | tee trace | sed '/^# /d'
}

# Receives a string with scapy python code that represents a packet.
# Returns a hex-string that contains bytes that reflect the packet symbolic
# description.
#
# Scapy docs: https://scapy.readthedocs.io/en/latest/usage.html
#
# Example of usage:
#
# packet=$(fmt_pkt "
#     Ether(dst='ff:ff:ff:ff:ff:ff', src='50:64:00:00:00:01') /
#     IPv6(src='abed::1', dst='ff02::1:ff00:2') /
#     ICMPv6ND_NS(tgt='abed::2')
# ")
#
# ovs-appctl netdev-dummy/receive $vif $packet
#
fmt_pkt() {
    ctlfile=$ovs_base/scapy.ctl
    if [[ ! -S $ctlfile ]]; then
        start_scapy_server
    fi
    while [[ ! -S $ctlfile ]]; do sleep 0.1; done
    ovs-appctl -t $ctlfile payload "$1"
}

start_scapy_server() {
    pidfile=$ovs_base/scapy.pid
    ctlfile=$ovs_base/scapy.ctl
    logfile=$ovs_base/scapy.log
    lockfile=$ovs_base/scapy.lock

    flock -n $lockfile "$top_srcdir"/tests/scapy-server.py \
        --pidfile=$pidfile --unixctl=$ctlfile --log-file=$logfile --detach \
    && on_exit "test -e \"$pidfile\" && ovs-appctl -t $ctlfile exit"
}

sleep_sb() {
  echo SB going to sleep
  AT_CHECK([kill -STOP $(cat ovn-sb/ovsdb-server.pid)])
  on_exit "kill -CONT $(cat ovn-sb/ovsdb-server.pid)"
}
wake_up_sb() {
  echo SB waking up
  AT_CHECK([kill -CONT $(cat ovn-sb/ovsdb-server.pid)])
}
sleep_controller() {
  hv=$1
  echo Controller $hv going to sleep
  as $hv
  check ovn-appctl debug/pause
  OVS_WAIT_UNTIL([test x$(ovn-appctl -t ovn-controller debug/status) = "xpaused"])
}
wake_up_controller() {
  hv=$1
  as $hv
  echo Controller $hv waking up
  ovn-appctl debug/resume
  OVS_WAIT_UNTIL([test x$(ovn-appctl -t ovn-controller debug/status) = "xrunning"])
}
sleep_ovs() {
  hv=$1
  echo ovs $hv going to sleep
  AT_CHECK([kill -STOP $(cat $hv/ovs-vswitchd.pid)])
  on_exit "kill -CONT $(cat $hv/ovs-vswitchd.pid)"
}

wake_up_ovs() {
  hv=$1
  echo ovs $hv going to wake-up
  AT_CHECK([kill -CONT $(cat $hv/ovs-vswitchd.pid)])
}

sleep_ovsdb() {
  echo OVSDB $1 going to sleep
  AT_CHECK([kill -STOP $(cat $1/ovsdb-server.pid)])
  on_exit "kill -CONT $(cat $1/ovsdb-server.pid)"
}
wake_up_ovsdb() {
  echo OVSDB $1 waking up
  AT_CHECK([kill -CONT $(cat $1/ovsdb-server.pid)])
}

stop_ovsdb_controller_updates() {
  TCP_PORT=$1
  echo Stopping updates from ovn-controller to ovsdb using port $TCP_PORT
  on_exit 'nft list tables | grep ovn-test && nft delete table ip ovn-test'
  nft add table ip ovn-test
  nft 'add chain ip ovn-test INPUT { type filter hook input priority 0; policy accept; }'
  nft add rule ip ovn-test INPUT tcp dport $TCP_PORT counter drop
}

restart_ovsdb_controller_updates() {
  TCP_PORT=$1
  echo Restarting updates from ovn-controller to ovsdb
  nft list ruleset | grep $TCP_PORT
  nft delete table ip ovn-test
}

trim_zeros() {
    sed 's/\(00\)\{1,\}$//'
}

OVS_END_SHELL_HELPERS

m4_define([OVN_POPULATE_ARP], [AT_CHECK(ovn_populate_arp__, [0], [ignore])])

# Defines versions of the test with all combinations of northd,
# parallelization on/off and conditional monitoring on/off.
m4_define([OVN_FOR_EACH_NORTHD],
  [m4_foreach([NORTHD_TYPE], [ovn-northd],
     [m4_foreach([NORTHD_USE_PARALLELIZATION], [yes, no],
       [m4_foreach([OVN_MONITOR_ALL], [yes, no], [$1
])])])])

# Defines versions of the test with all combinations of northd and
# parallelization on/off.  To be used when the ovn-controller configuration
# is not relevant.
m4_define([OVN_FOR_EACH_NORTHD_NO_HV],
  [m4_foreach([NORTHD_TYPE], [ovn-northd],
     [m4_foreach([NORTHD_USE_PARALLELIZATION], [yes, no], [$1
])])])


# OVN_NBCTL(NBCTL_COMMAND) adds NBCTL_COMMAND to list of commands to be run by RUN_OVN_NBCTL().
m4_define([OVN_NBCTL], [
    command="${command} -- $1"
])

# RUN_OVN_NBCTL() executes list of commands built by the OVN_NBCTL() macro.
m4_define([RUN_OVN_NBCTL], [
    check ovn-nbctl ${command}
    unset command
])

m4_define([OVN_CHECK_SCAPY_EDNS_CLIENT_SUBNET_SUPPORT],
[
    AT_SKIP_IF([test $HAVE_SCAPY = no])
    AT_SKIP_IF([! echo "from scapy.layers.dns import EDNS0ClientSubnet" | python 2>&1 > /dev/null])
])
