/*
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at:
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import OVN_Northbound as nb
import OVN_Southbound as sb
import ovsdb
import allocate
import ovn
import lswitch
import lrouter
import multicast
import helpers
import ipam
import vec

index Logical_Flow_Index() on sb::Out_Logical_Flow()

/* Meter_Band table */
for (mb in nb::Meter_Band) {
    sb::Out_Meter_Band(._uuid = mb._uuid,
                      .action = mb.action,
                      .rate = mb.rate,
                      .burst_size = mb.burst_size)
}

/* Meter table */
for (meter in nb::Meter) {
    sb::Out_Meter(._uuid = meter._uuid,
                 .name = meter.name,
                 .unit = meter.unit,
                 .bands = meter.bands)
}
sb::Out_Meter(._uuid = hash128(name),
              .name = name,
              .unit = meter.unit,
              .bands = meter.bands) :-
    ACLWithFairMeter(acl, meter),
    var name = acl_log_meter_name(meter.name, acl._uuid).

/* Proxy table for Out_Datapath_Binding: contains all Datapath_Binding fields,
 * except tunnel id, which is allocated separately (see TunKeyAllocation). */
relation OutProxy_Datapath_Binding (
    _uuid: uuid,
    load_balancers: Set<uuid>,
    external_ids: Map<string,string>
)

/* Datapath_Binding table */
OutProxy_Datapath_Binding(uuid, load_balancers, external_ids) :-
    nb::Logical_Switch(._uuid = uuid, .name = name, .external_ids = ids,
                       .load_balancer = load_balancers,
                       .other_config = other_config),
    var uuid_str = uuid2str(uuid),
    var external_ids = {
        var eids = ["logical-switch" -> uuid_str, "name" -> name];
        match (ids.get("neutron:network_name")) {
            None -> (),
            Some{nnn} -> eids.insert("name2", nnn)
        };
        match (other_config.get("interconn-ts")) {
            None -> (),
            Some{value} -> eids.insert("interconn-ts", value)
        };
        eids
    }.

OutProxy_Datapath_Binding(uuid, set_empty(), external_ids) :-
    lr in nb::Logical_Router(._uuid = uuid, .name = name, .external_ids = ids,
                             .options = options),
    lr.is_enabled(),
    var uuid_str = uuid2str(uuid),
    var external_ids = {
        var eids = ["logical-router" -> uuid_str, "name" -> name];
        match (ids.get("neutron:router_name")) {
            None -> (),
            Some{nnn} -> eids.insert("name2", nnn)
        };
        match (options.get("snat-ct-zone").and_then(parse_dec_u64)) {
            None -> (),
            Some{zone} -> eids.insert("snat-ct-zone", "${zone}")
        };
        var learn_from_arp_request = options.get_bool_def("always_learn_from_arp_request", true);
        if (not learn_from_arp_request) {
            eids.insert("always_learn_from_arp_request", "false")
        };
        eids
    }.

sb::Out_Datapath_Binding(uuid, tunkey, load_balancers, external_ids) :-
    OutProxy_Datapath_Binding(uuid, load_balancers, external_ids),
    TunKeyAllocation(uuid, tunkey).


/* Proxy table for Out_Datapath_Binding: contains all Datapath_Binding fields,
 * except tunnel id, which is allocated separately (see PortTunKeyAllocation). */
relation OutProxy_Port_Binding (
    _uuid: uuid,
    logical_port: string,
    __type: string,
    gateway_chassis: Set<uuid>,
    ha_chassis_group: Option<uuid>,
    options: Map<string,string>,
    datapath: uuid,
    parent_port: Option<string>,
    tag: Option<integer>,
    mac: Set<string>,
    nat_addresses: Set<string>,
    external_ids: Map<string,string>
)

/* Case 1: Create a Port_Binding per logical switch port that is not of type "router" */
OutProxy_Port_Binding(._uuid              = lsp._uuid,
                      .logical_port       = lsp.name,
                      .__type             = lsp.__type,
                      .gateway_chassis    = set_empty(),
                      .ha_chassis_group   = sp.hac_group_uuid,
                      .options            = lsp.options,
                      .datapath           = sw.ls._uuid,
                      .parent_port        = lsp.parent_name,
                      .tag                = tag,
                      .mac                = lsp.addresses,
                      .nat_addresses      = set_empty(),
                      .external_ids       = eids) :-
    sp in &SwitchPort(.lsp = lsp, .sw = &sw),
    SwitchPortNewDynamicTag(lsp._uuid, opt_tag),
    var tag = match (opt_tag) {
        None -> lsp.tag,
        Some{t} -> Some{t}
    },
    lsp.__type != "router",
    var eids = {
        var eids = lsp.external_ids;
        match (lsp.external_ids.get("neutron:port_name")) {
            None -> (),
            Some{name} -> eids.insert("name", name)
        };
        eids
    }.


/* Case 2: Create a Port_Binding per logical switch port of type "router" */
OutProxy_Port_Binding(._uuid              = lsp._uuid,
                      .logical_port       = lsp.name,
                      .__type             = __type,
                      .gateway_chassis    = set_empty(),
                      .ha_chassis_group   = None,
                      .options            = options,
                      .datapath           = sw.ls._uuid,
                      .parent_port        = lsp.parent_name,
                      .tag                = None,
                      .mac                = lsp.addresses,
                      .nat_addresses      = nat_addresses,
                      .external_ids       = eids) :-
    &SwitchPort(.lsp = lsp, .sw = &sw, .peer = peer),
    var eids = {
        var eids = lsp.external_ids;
        match (lsp.external_ids.get("neutron:port_name")) {
            None -> (),
            Some{name} -> eids.insert("name", name)
        };
        eids
    },
    Some{var router_port} = lsp.options.get("router-port"),
    var opt_chassis = peer.and_then(|p| p.router.lr.options.get("chassis")),
    var l3dgw_port = peer.and_then(|p| p.router.l3dgw_port),    
    (var __type, var options) = {
        var options = ["peer" -> router_port];
        match (opt_chassis) {
            None -> {
                ("patch", options)
            },
            Some{chassis} -> {
                options.insert("l3gateway-chassis", chassis);
                ("l3gateway", options)
            }
        }
    },
    var base_nat_addresses = {
        match (lsp.options.get("nat-addresses")) {
            None -> { set_empty() },
            Some{"router"} -> match ((l3dgw_port, opt_chassis, peer)) {
                                 (None, None, _) -> set_empty(),
                                 (_, _, None) -> set_empty(),
                                 (_, _, Some{rport}) -> get_nat_addresses(deref(rport))
                              },
            Some{nat_addresses} -> {
                /* Only accept manual specification of ethernet address
                 * followed by IPv4 addresses on type "l3gateway" ports. */
                if (opt_chassis.is_some()) {
                    match (extract_lsp_addresses(nat_addresses)) {
                        None -> {
                            warn("Error extracting nat-addresses.");
                            set_empty()
                        },
                        Some{_} -> { set_singleton(nat_addresses) }
                    }
                } else { set_empty() }
            }
        }
    },
    /* Add the router mac and IPv4 addresses to
     * Port_Binding.nat_addresses so that GARP is sent for these
     * IPs by the ovn-controller on which the distributed gateway
     * router port resides if:
     *
     * 1. The peer has 'reside-on-redirect-chassis' set and the
     *    the logical router datapath has distributed router port.
     *
     * 2. The peer is distributed gateway router port.
     *
     * 3. The peer's router is a gateway router and the port has a localnet
     *    port.
     *
     * Note: Port_Binding.nat_addresses column is also used for
     * sending the GARPs for the router port IPs.
     * */
    var garp_nat_addresses = match (peer) {
        Some{rport} -> match (
            (rport.lrp.options.get_bool_def("reside-on-redirect-chassis", false)
             and l3dgw_port.is_some()) or
            Some{rport.lrp} == l3dgw_port or
            (rport.router.lr.options.contains_key("chassis") and
             not sw.localnet_ports.is_empty())) {
            false -> set_empty(),
            true -> set_singleton(get_garp_nat_addresses(deref(rport)))
        },
        None -> set_empty()
    },
    var nat_addresses = set_union(base_nat_addresses, garp_nat_addresses).

/* Case 3: Port_Binding per logical router port */
OutProxy_Port_Binding(._uuid              = lrp._uuid,
                      .logical_port       = lrp.name,
                      .__type             = __type,
                      .gateway_chassis    = set_empty(),
                      .ha_chassis_group   = None,
                      .options            = options,
                      .datapath           = router.lr._uuid,
                      .parent_port        = None,
                      .tag                = None, // always empty for router ports
                      .mac                = set_singleton("${lrp.mac} ${lrp.networks.join(\" \")}"),
                      .nat_addresses      = set_empty(),
                      .external_ids       = lrp.external_ids) :-
    rp in &RouterPort(.lrp = lrp, .router = &router, .peer = peer),
    RouterPortRAOptionsComplete(lrp._uuid, options0),
    (var __type, var options1) = match (router.lr.options.get("chassis")) {
        /* TODO: derived ports */
        None -> ("patch", map_empty()),
        Some{lrchassis} -> ("l3gateway", ["l3gateway-chassis" -> lrchassis])
    },
    var options2 = match (router_peer_name(peer)) {
        None -> map_empty(),
        Some{peer_name} -> ["peer" -> peer_name]
    },
    var options3 = match ((peer, rp.networks.ipv6_addrs.is_empty())) {
        (PeerSwitch{_, _}, false) -> {
            var enabled = lrp.is_enabled();
            var pd = lrp.options.get_bool_def("prefix_delegation", false);
            var p = lrp.options.get_bool_def("prefix", false);
            ["ipv6_prefix_delegation" -> "${pd and enabled}",
             "ipv6_prefix" -> "${p and enabled}"]
        },
        _ -> map_empty()
    },
    PreserveIPv6RAPDList(lrp._uuid, ipv6_ra_pd_list),
    var options4 = match (ipv6_ra_pd_list) {
        None -> map_empty(),
        Some{value} -> ["ipv6_ra_pd_list" -> value]
    },
    var options = options0.union(options1).union(options2).union(options3).union(options4),
    var eids = {
        var eids = lrp.external_ids;
        match (lrp.external_ids.get("neutron:port_name")) {
            None -> (),
            Some{name} -> eids.insert("name", name)
        };
        eids
    }.
/*
*/
function get_router_load_balancer_ips(router: Router) :
    (Set<string>, Set<string>) =
{
    var all_ips_v4 = set_empty();
    var all_ips_v6 = set_empty();
    for (lb in router.lbs) {
        for (kv in deref(lb).vips) {
            (var vip, _) = kv;
            /* node->key contains IP:port or just IP. */
            match (ip_address_and_port_from_lb_key(vip)) {
                None -> (),
                Some{(IPv4{ipv4}, _)} -> all_ips_v4.insert("${ipv4}"),
                Some{(IPv6{ipv6}, _)} -> all_ips_v6.insert("${ipv6}")
            }
        }
    };
    (all_ips_v4, all_ips_v6)
}

/* Returns an array of strings, each consisting of a MAC address followed
 * by one or more IP addresses, and if the port is a distributed gateway
 * port, followed by 'is_chassis_resident("LPORT_NAME")', where the
 * LPORT_NAME is the name of the L3 redirect port or the name of the
 * logical_port specified in a NAT rule.  These strings include the
 * external IP addresses of all NAT rules defined on that router, and all
 * of the IP addresses used in load balancer VIPs defined on that router.
 */
function get_nat_addresses(rport: RouterPort): Set<string> =
{
    var addresses = set_empty();
    var router = deref(rport.router);
    var has_redirect = router.l3dgw_port.is_some();
    match (eth_addr_from_string(rport.lrp.mac)) {
        None -> addresses,
        Some{mac} -> {
            var c_addresses = "${mac}";
            var central_ip_address = false;

            /* Get NAT IP addresses. */
            for (nat in router.nats) {
                /* Determine whether this NAT rule satisfies the conditions for
                 * distributed NAT processing. */
                if (has_redirect and nat.nat.__type == "dnat_and_snat" and
                    nat.nat.logical_port.is_some() and nat.external_mac.is_some()) {
                    /* Distributed NAT rule. */
                    var logical_port = option_unwrap_or_default(nat.nat.logical_port);
                    var external_mac = option_unwrap_or_default(nat.external_mac);
                    addresses.insert("${external_mac} ${nat.external_ip} "
                                     "is_chassis_resident(${json_string_escape(logical_port)})")
                } else {
                    /* Centralized NAT rule, either on gateway router or distributed
                     * router.
                     * Check if external_ip is same as router ip. If so, then there
                     * is no need to add this to the nat_addresses. The router IPs
                     * will be added separately. */
                    var is_router_ip = false;
                    match (nat.external_ip) {
                        IPv4{ei} -> {
                            for (ipv4 in rport.networks.ipv4_addrs) {
                                if (ei == ipv4.addr) {
                                    is_router_ip = true;
                                    break
                                }
                            }
                        },
                        IPv6{ei} -> {
                            for (ipv6 in rport.networks.ipv6_addrs) {
                                if (ei == ipv6.addr) {
                                    is_router_ip = true;
                                    break
                                }
                            }
                        }
                    };
                    if (not is_router_ip) {
                        c_addresses = c_addresses ++ " ${nat.external_ip}";
                        central_ip_address = true
                    }
                }
            };

            /* A set to hold all load-balancer vips. */
            (var all_ips_v4, var all_ips_v6) = get_router_load_balancer_ips(router);

            for (ip_address in set_union(all_ips_v4, all_ips_v6)) {
                c_addresses = c_addresses ++ " ${ip_address}";
                central_ip_address = true
            };

            if (central_ip_address) {
                /* Gratuitous ARP for centralized NAT rules on distributed gateway
                 * ports should be restricted to the gateway chassis. */
                if (has_redirect) {
                    c_addresses = c_addresses ++ " is_chassis_resident(${router.redirect_port_name})"
                } else ();

                addresses.insert(c_addresses)
            } else ();
            addresses
        }
    }
}

function get_garp_nat_addresses(rport: RouterPort): string = {
    var garp_info = ["${rport.networks.ea}"];
    for (ipv4_addr in rport.networks.ipv4_addrs) {
        garp_info.push("${ipv4_addr.addr}")
    };
    if (rport.router.redirect_port_name != "") {
        garp_info.push("is_chassis_resident(${rport.router.redirect_port_name})")
    };
    garp_info.join(" ")
}

/* Extra options computed for router ports by the logical flow generation code */
relation RouterPortRAOptions(lrp: uuid, options: Map<string, string>)

relation RouterPortRAOptionsComplete(lrp: uuid, options: Map<string, string>)

RouterPortRAOptionsComplete(lrp, options) :-
    RouterPortRAOptions(lrp, options).
RouterPortRAOptionsComplete(lrp, map_empty()) :-
    nb::Logical_Router_Port(._uuid = lrp),
    not RouterPortRAOptions(lrp, _).


/*
 * Create derived port for Logical_Router_Ports with non-empty 'gateway_chassis' column.
 */

/* Create derived ports */
OutProxy_Port_Binding(// lrp._uuid is already in use; generate a new UUID by
                      // hashing it.
                      ._uuid              = hash128(lrp._uuid),
                      .logical_port       = chassis_redirect_name(lrp.name),
                      .__type             = "chassisredirect",
                      .gateway_chassis    = set_empty(),
                      .ha_chassis_group   = Some{hacg_uuid},
                      .options            = options,
                      .datapath           = lr_uuid,
                      .parent_port        = None,
                      .tag                = None,  //always empty for router ports
                      .mac                = set_singleton("${lrp.mac} ${lrp.networks.join(\" \")}"),
                      .nat_addresses      = set_empty(),
                      .external_ids       = lrp.external_ids) :-
    DistributedGatewayPort(lrp, lr_uuid),
    LogicalRouterHAChassisGroup(lr_uuid, hacg_uuid),
    var redirect_type = match (lrp.options.get("redirect-type")) {
        Some{var value} -> ["redirect-type" -> value],
        _ -> map_empty()
    },
    var options = redirect_type.insert_imm("distributed-port", lrp.name).

/*
 * We want to preserve 'up' (set by ovn-controller) for Port_Binding rows.
 * We need to set set 'up' in new rows to Some{false}; if we don't set
 * it at all, ovn-controller will never update it.
 */
relation PortBindingUp0(pb_uuid: uuid, up: bool)
PortBindingUp0(pb_uuid, up) :- sb::Port_Binding(._uuid = pb_uuid, .up = Some{up}).

relation PortBindingUp(pb_uuid: uuid, up: bool)
PortBindingUp(pb_uuid, up) :- PortBindingUp0(pb_uuid, up).
PortBindingUp(pb_uuid, false) :-
    OutProxy_Port_Binding(._uuid = pb_uuid),
    not PortBindingUp0(pb_uuid, _).

/* Add allocated qdisc_queue_id and tunnel key to Port_Binding.
 */
sb::Out_Port_Binding(._uuid              = pbinding._uuid,
                    .logical_port       = pbinding.logical_port,
                    .__type             = pbinding.__type,
                    .gateway_chassis    = pbinding.gateway_chassis,
                    .ha_chassis_group   = pbinding.ha_chassis_group,
                    .options            = options0,
                    .datapath           = pbinding.datapath,
                    .tunnel_key         = tunkey,
                    .parent_port        = pbinding.parent_port,
                    .tag                = pbinding.tag,
                    .mac                = pbinding.mac,
                    .nat_addresses      = pbinding.nat_addresses,
                    .external_ids       = pbinding.external_ids,
                    .up                 = Some{up}) :-
    pbinding in OutProxy_Port_Binding(),
    PortTunKeyAllocation(pbinding._uuid, tunkey),
    QueueIDAllocation(pbinding._uuid, qid),
    PortBindingUp(pbinding._uuid, up),
    var options0 = match (qid) {
        None -> pbinding.options,
        Some{id} -> pbinding.options.insert_imm("qdisc_queue_id", "${id}")
    }.

/* Referenced chassis.
 *
 * These tables track the sb::Chassis that a packet that traverses logical
 * router 'lr_uuid' can end up at (or start from).  This is used for
 * sb::Out_HA_Chassis_Group's ref_chassis column.
 *
 * RefChassisSet0 has a row for each logical router that actually references a
 * chassis.  RefChassisSet has a row for every logical router. */
relation RefChassis(lr_uuid: uuid, chassis_uuid: uuid)
RefChassis(lr_uuid, chassis_uuid) :-
    ReachableLogicalRouter(lr_uuid, lr2_uuid),
    FirstHopLogicalRouter(lr2_uuid, ls_uuid),
    LogicalSwitchPort(lsp_uuid, ls_uuid),
    nb::Logical_Switch_Port(._uuid = lsp_uuid, .name = lsp_name),
    sb::Port_Binding(.logical_port = lsp_name, .chassis = chassis_uuids),
    Some{var chassis_uuid} = chassis_uuids.
relation RefChassisSet0(lr_uuid: uuid, chassis_uuids: Set<uuid>)
RefChassisSet0(lr_uuid, chassis_uuids) :-
    RefChassis(lr_uuid, chassis_uuid),
    var chassis_uuids = chassis_uuid.group_by(lr_uuid).to_set().
relation RefChassisSet(lr_uuid: uuid, chassis_uuids: Set<uuid>)
RefChassisSet(lr_uuid, chassis_uuids) :-
    RefChassisSet0(lr_uuid, chassis_uuids).
RefChassisSet(lr_uuid, set_empty()) :-
    nb::Logical_Router(._uuid = lr_uuid),
    not RefChassisSet0(lr_uuid, _).

/* Referenced chassis for an HA chassis group.
 *
 * Multiple logical routers can reference an HA chassis group so we merge the
 * referenced chassis across all of them.
 */
relation HAChassisGroupRefChassisSet(hacg_uuid: uuid,
                                     chassis_uuids: Set<uuid>)
HAChassisGroupRefChassisSet(hacg_uuid, chassis_uuids) :-
    LogicalRouterHAChassisGroup(lr_uuid, hacg_uuid),
    RefChassisSet(lr_uuid, chassis_uuids),
    var chassis_uuids = chassis_uuids.group_by(hacg_uuid).union().

/* HA_Chassis_Group and HA_Chassis. */
sb::Out_HA_Chassis_Group(hacg_uuid, hacg_name, ha_chassis, ref_chassis, eids) :-
    HAChassis(hacg_uuid, hac_uuid, chassis_name, _, _),
    var chassis_uuid = ha_chassis_uuid(chassis_name, hac_uuid),
    var ha_chassis = chassis_uuid.group_by(hacg_uuid).to_set(),
    HAChassisGroup(hacg_uuid, hacg_name, eids),
    HAChassisGroupRefChassisSet(hacg_uuid, ref_chassis).

sb::Out_HA_Chassis(ha_chassis_uuid(chassis_name, hac_uuid), chassis, priority, eids) :-
    HAChassis(_, hac_uuid, chassis_name, priority, eids),
    chassis_rec in sb::Chassis(.name = chassis_name),
    var chassis = Some{chassis_rec._uuid}.
sb::Out_HA_Chassis(ha_chassis_uuid(chassis_name, hac_uuid), None, priority, eids) :-
    HAChassis(_, hac_uuid, chassis_name, priority, eids),
    not chassis_rec in sb::Chassis(.name = chassis_name).

relation HAChassisToChassis(name: string, chassis: Option<uuid>)
HAChassisToChassis(name, Some{chassis}) :-
    sb::Chassis(._uuid = chassis, .name = name).
HAChassisToChassis(name, None) :-
    nb::HA_Chassis(.chassis_name = name),
    not sb::Chassis(.name = name).
sb::Out_HA_Chassis(ha_chassis_uuid(ha_chassis.chassis_name, hac_uuid), chassis, priority, eids) :-
    sp in &SwitchPort(),
    sp.lsp.__type == "external",
    Some{var ha_chassis_group_uuid} = sp.lsp.ha_chassis_group,
    ha_chassis_group in nb::HA_Chassis_Group(._uuid = ha_chassis_group_uuid),
    var hac_uuid = FlatMap(ha_chassis_group.ha_chassis),
    ha_chassis in nb::HA_Chassis(._uuid = hac_uuid, .priority = priority, .external_ids = eids),
    HAChassisToChassis(ha_chassis.chassis_name, chassis).
sb::Out_HA_Chassis_Group(_uuid, name, ha_chassis, set_empty() /* XXX? */, eids) :-
    sp in &SwitchPort(),
    sp.lsp.__type == "external",
    var ls_uuid = sp.sw.ls._uuid,
    Some{var ha_chassis_group_uuid} = sp.lsp.ha_chassis_group,
    ha_chassis_group in nb::HA_Chassis_Group(._uuid = ha_chassis_group_uuid, .name = name,
                                            .external_ids = eids),
    var hac_uuid = FlatMap(ha_chassis_group.ha_chassis),
    ha_chassis in nb::HA_Chassis(._uuid = hac_uuid),
    var ha_chassis_uuid_name = ha_chassis_uuid(ha_chassis.chassis_name, hac_uuid),
    var ha_chassis = ha_chassis_uuid_name.group_by((ls_uuid, name, eids)).to_set(),
    var _uuid = ha_chassis_group_uuid(ls_uuid).

/*
 * SB_Global: copy nb_cfg and options from NB.
 * If NB_Global does not exist yet, just keep the current value of SB_Global,
 * if any.
 */
for (nb_global in nb::NB_Global) {
    sb::Out_SB_Global(._uuid          = nb_global._uuid,
                     .nb_cfg         = nb_global.nb_cfg,
                     .options        = nb_global.options,
                     .ipsec          = nb_global.ipsec)
}

sb::Out_SB_Global(._uuid          = sb_global._uuid,
                 .nb_cfg         = sb_global.nb_cfg,
                 .options        = sb_global.options,
                 .ipsec          = sb_global.ipsec) :-
    sb_global in sb::SB_Global(),
    not nb::NB_Global().

/* sb::Chassis_Private joined with is_remote from sb::Chassis,
 * including a record even for a null Chassis ref. */
relation ChassisPrivate(
    cp: sb::Chassis_Private,
    is_remote: bool)
ChassisPrivate(cp, c.other_config.get_bool_def("is-remote", false)) :-
    cp in sb::Chassis_Private(.chassis = Some{uuid}),
    c in sb::Chassis(._uuid = uuid).
ChassisPrivate(cp, false),
Warning["Chassis not exist for Chassis_Private record, name: ${cp.name}"] :-
    cp in sb::Chassis_Private(.chassis = Some{uuid}),
    not sb::Chassis(._uuid = uuid).
ChassisPrivate(cp, false),
Warning["Chassis not exist for Chassis_Private record, name: ${cp.name}"] :-
    cp in sb::Chassis_Private(.chassis = None).

/* Track minimum hv_cfg across all the (non-remote) chassis. */
relation HvCfg0(hv_cfg: integer)
HvCfg0(hv_cfg) :-
    ChassisPrivate(.cp = sb::Chassis_Private{.nb_cfg = chassis_cfg}, .is_remote = false),
    var hv_cfg = chassis_cfg.group_by(()).min().
relation HvCfg(hv_cfg: integer)
HvCfg(hv_cfg) :- HvCfg0(hv_cfg).
HvCfg(hv_cfg) :-
    nb::NB_Global(.nb_cfg = hv_cfg),
    not HvCfg0().

/* Track maximum nb_cfg_timestamp among all the (non-remote) chassis
 * that have the minimum nb_cfg. */
relation HvCfgTimestamp0(hv_cfg_timestamp: integer)
HvCfgTimestamp0(hv_cfg_timestamp) :-
    HvCfg(hv_cfg),
    ChassisPrivate(.cp = sb::Chassis_Private{.nb_cfg = hv_cfg,
                                             .nb_cfg_timestamp = chassis_cfg_timestamp},
                   .is_remote = false),
    var hv_cfg_timestamp = chassis_cfg_timestamp.group_by(()).max().
relation HvCfgTimestamp(hv_cfg_timestamp: integer)
HvCfgTimestamp(hv_cfg_timestamp) :- HvCfgTimestamp0(hv_cfg_timestamp).
HvCfgTimestamp(hv_cfg_timestamp) :-
    nb::NB_Global(.hv_cfg_timestamp = hv_cfg_timestamp),
    not HvCfgTimestamp0().

/*
 * NB_Global:
 * - set `sb_cfg` to the value of `SB_Global.nb_cfg`.
 * - set `hv_cfg` to the smallest value of `nb_cfg` across all `Chassis`
 * - FIXME: we use ipsec as unique key to make sure that we don't create multiple `NB_Global`
 *   instance.  There is a potential race condition if this field is modified at the same
 *   time northd is updating `sb_cfg` or `hv_cfg`.
 */
input relation NbCfgTimestamp[integer]
nb::Out_NB_Global(._uuid         = _uuid,
                 .sb_cfg        = sb_cfg,
                 .hv_cfg        = hv_cfg,
                 .nb_cfg_timestamp = nb_cfg_timestamp,
                 .hv_cfg_timestamp = hv_cfg_timestamp,
                 .ipsec         = ipsec,
                 .options       = options) :-
    NbCfgTimestamp[nb_cfg_timestamp],
    HvCfgTimestamp(hv_cfg_timestamp),
    nbg in nb::NB_Global(._uuid = _uuid, .ipsec = ipsec),
    sb::SB_Global(.nb_cfg = sb_cfg),
    HvCfg(hv_cfg),
    HvCfgTimestamp(hv_cfg_timestamp),
    MacPrefix(mac_prefix),
    SvcMonitorMac(svc_monitor_mac),
    OvnMaxDpKeyLocal[max_tunid],
    var options0 = put_mac_prefix(nbg.options, mac_prefix),
    var options1 = put_svc_monitor_mac(options0, svc_monitor_mac),
    var options2 = options1.insert_imm("max_tunid", "${max_tunid}"),
    var options = options2.insert_imm("northd_internal_version", ovn_internal_version()).


/* SB_Global does not exist yet -- just keep the old value of NB_Global */
nb::Out_NB_Global(._uuid         = nbg._uuid,
                 .sb_cfg        = nbg.sb_cfg,
                 .hv_cfg        = nbg.hv_cfg,
                 .ipsec         = nbg.ipsec,
                 .options       = nbg.options,
                 .nb_cfg_timestamp = nb_cfg_timestamp,
                 .hv_cfg_timestamp = hv_cfg_timestamp) :-
    NbCfgTimestamp[nb_cfg_timestamp],
    HvCfgTimestamp(hv_cfg_timestamp),
    nbg in nb::NB_Global(),
    not sb::SB_Global().

output relation SbCfg[integer]
SbCfg[sb_cfg] :- nb::Out_NB_Global(.sb_cfg = sb_cfg).

output relation Northd_Probe_Interval[s64]
Northd_Probe_Interval[interval] :-
    nb in nb::NB_Global(),
    var interval = nb.options.get("northd_probe_interval").and_then(parse_dec_i64).unwrap_or(-1).

relation CheckLspIsUp[bool]
CheckLspIsUp[check_lsp_is_up] :-
    nb in nb::NB_Global(),
    var check_lsp_is_up = not nb.options.get_bool_def("ignore_lsp_down", false).
CheckLspIsUp[true] :-
    Unit(),
    not nb in nb::NB_Global().

/*
 * Address_Set: copy from NB + additional records generated from NB Port_Group (two records for each
 * Port_Group for IPv4 and IPv6 addresses).
 *
 * There can be name collisions between the two types of Address_Set records.  User-defined records
 * take precedence.
 */
sb::Out_Address_Set(._uuid     = nb_as._uuid,
                    .name      = nb_as.name,
                    .addresses = nb_as.addresses) :-
    AddressSetRef[nb_as].

sb::Out_Address_Set(._uuid = hash128("svc_monitor_mac"),
                   .name = "svc_monitor_mac",
                   .addresses = set_singleton("${svc_monitor_mac}")) :-
    SvcMonitorMac(svc_monitor_mac).

sb::Out_Address_Set(hash128(as_name), as_name, pg_ip4addrs.union()) :-
    nb::Port_Group(.ports = pg_ports, .name = pg_name),
    var as_name = pg_name ++ "_ip4",
    // avoid name collisions with user-defined Address_Sets
    not nb::Address_Set(.name = as_name),
    var port_uuid = FlatMap(pg_ports),
    PortStaticAddresses(.lsport = port_uuid, .ip4addrs = stat),
    SwitchPortNewDynamicAddress(&SwitchPort{.lsp = nb::Logical_Switch_Port{._uuid = port_uuid}},
                                dyn_addr),
    var dynamic = match (dyn_addr) {
        None -> set_empty(),
        Some{lpaddress} -> match (lpaddress.ipv4_addrs.nth(0)) {
            None -> set_empty(),
            Some{addr} -> set_singleton("${addr.addr}")
        }
    },
    //PortDynamicAddresses(.lsport = port_uuid, .ip4addrs = dynamic),
    var port_ip4addrs = stat.union(dynamic),
    var pg_ip4addrs = port_ip4addrs.group_by(as_name).to_vec().

sb::Out_Address_Set(hash128(as_name), as_name, set_empty()) :-
    nb::Port_Group(.ports = set_empty(), .name = pg_name),
    var as_name = pg_name ++ "_ip4",
    // avoid name collisions with user-defined Address_Sets
    not nb::Address_Set(.name = as_name).

sb::Out_Address_Set(hash128(as_name), as_name, pg_ip6addrs.union()) :-
    nb::Port_Group(.ports = pg_ports, .name = pg_name),
    var as_name = pg_name ++ "_ip6",
    // avoid name collisions with user-defined Address_Sets
    not nb::Address_Set(.name = as_name),
    var port_uuid = FlatMap(pg_ports),
    PortStaticAddresses(.lsport = port_uuid, .ip6addrs = stat),
    SwitchPortNewDynamicAddress(&SwitchPort{.lsp = nb::Logical_Switch_Port{._uuid = port_uuid}},
                                dyn_addr),
    var dynamic = match (dyn_addr) {
        None -> set_empty(),
        Some{lpaddress} -> match (lpaddress.ipv6_addrs.nth(0)) {
            None -> set_empty(),
            Some{addr} -> set_singleton("${addr.addr}")
        }
    },
    //PortDynamicAddresses(.lsport = port_uuid, .ip6addrs = dynamic),
    var port_ip6addrs = stat.union(dynamic),
    var pg_ip6addrs = port_ip6addrs.group_by(as_name).to_vec().

sb::Out_Address_Set(hash128(as_name), as_name, set_empty()) :-
    nb::Port_Group(.ports = set_empty(), .name = pg_name),
    var as_name = pg_name ++ "_ip6",
    // avoid name collisions with user-defined Address_Sets
    not nb::Address_Set(.name = as_name).

/*
 * Port_Group
 *
 * Create one SB Port_Group record for every datapath that has ports
 * referenced by the NB Port_Group.ports field. In order to maintain the
 * SB Port_Group.name uniqueness constraint, ovn-northd populates the field
 * with the value: <SB.Logical_Datapath.tunnel_key>_<NB.Port_Group.name>.
 */
sb::Out_Port_Group(._uuid = hash128(sb_name), .name = sb_name, .ports = port_names) :-
    nb::Port_Group(._uuid = _uuid, .name = nb_name, .ports = pg_ports),
    var port_uuid = FlatMap(pg_ports),
    &SwitchPort(.lsp = lsp@nb::Logical_Switch_Port{._uuid = port_uuid,
                                                   .name = port_name},
                .sw = &Switch{.ls = nb::Logical_Switch{._uuid = ls_uuid}}),
    TunKeyAllocation(.datapath = ls_uuid, .tunkey = tunkey),
    var sb_name = "${tunkey}_${nb_name}",
    var port_names = port_name.group_by((_uuid, sb_name)).to_set().

/*
 * Multicast_Group:
 * - three static rows per logical switch: one for flooding, one for packets
 *   with unknown destinations, one for flooding IP multicast known traffic to
 *   mrouters.
 * - dynamically created rows based on IGMP groups learned by controllers.
 */

function mC_FLOOD():         (string, integer) =
    ("_MC_flood", 32768)

function mC_UNKNOWN():       (string, integer) =
    ("_MC_unknown", 32769)

function mC_MROUTER_FLOOD(): (string, integer) =
    ("_MC_mrouter_flood", 32770)

function mC_MROUTER_STATIC(): (string, integer) =
    ("_MC_mrouter_static", 32771)

function mC_STATIC(): (string, integer) =
    ("_MC_static", 32772)

function mC_FLOOD_L2(): (string, integer) =
    ("_MC_flood_l2", 32773)

function mC_IP_MCAST_MIN():  (string, integer) =
    ("_MC_ip_mcast_min", 32774)

function mC_IP_MCAST_MAX():  (string, integer) =
    ("_MC_ip_mcast_max", 65535)


// TODO: check that Multicast_Group.ports should not include derived ports

/* Proxy table for Out_Multicast_Group: contains all Multicast_Group fields,
 * except `_uuid`, which will be computed by hashing the remaining fields,
 * and tunnel key, which case it is allocated separately (see
 * MulticastGroupTunKeyAllocation). */
relation OutProxy_Multicast_Group (
    datapath: uuid,
    name: string,
    ports: Set<uuid>
)

/* Only create flood group if the switch has enabled ports */
sb::Out_Multicast_Group (._uuid      = hash128((datapath,name)),
                        .datapath   = datapath,
                        .name       = name,
                        .tunnel_key = tunnel_key,
                        .ports      = port_ids) :-
    &SwitchPort(.lsp = lsp, .sw = &Switch{.ls = ls}),
    lsp.is_enabled(),
    var datapath = ls._uuid,
    var port_ids = lsp._uuid.group_by((datapath)).to_set(),
    (var name, var tunnel_key) = mC_FLOOD().

/* Create a multicast group to flood to all switch ports except router ports.
 */
sb::Out_Multicast_Group (._uuid      = hash128((datapath,name)),
                        .datapath   = datapath,
                        .name       = name,
                        .tunnel_key = tunnel_key,
                        .ports      = port_ids) :-
    &SwitchPort(.lsp = lsp, .sw = &Switch{.ls = ls}),
    lsp.is_enabled(),
    lsp.__type != "router",
    var datapath = ls._uuid,
    var port_ids = lsp._uuid.group_by((datapath)).to_set(),
    (var name, var tunnel_key) = mC_FLOOD_L2().

/* Only create unknown group if the switch has ports with "unknown" address */
sb::Out_Multicast_Group (._uuid      = hash128((ls,name)),
                        .datapath   = ls,
                        .name       = name,
                        .tunnel_key = tunnel_key,
                        .ports      = ports) :-
    LogicalSwitchPortWithUnknownAddress(ls, lsp),
    var ports = lsp.group_by(ls).to_set(),
    (var name, var tunnel_key) = mC_UNKNOWN().

/* Create a multicast group to flood multicast traffic to routers with
 * multicast relay enabled.
 */
sb::Out_Multicast_Group (._uuid    = hash128((sw.ls._uuid,name)),
                        .datapath = sw.ls._uuid,
                        .name = name,
                        .tunnel_key = tunnel_key,
                        .ports = port_ids) :-
    SwitchMcastFloodRelayPorts(&sw, port_ids),
    not port_ids.is_empty(),
    (var name, var tunnel_key) = mC_MROUTER_FLOOD().

/* Create a multicast group to flood traffic (no reports) to ports with
 * multicast flood enabled.
 */
sb::Out_Multicast_Group (._uuid    = hash128((sw.ls._uuid,name)),
                        .datapath = sw.ls._uuid,
                        .name = name,
                        .tunnel_key = tunnel_key,
                        .ports = port_ids) :-
    SwitchMcastFloodPorts(&sw, port_ids),
    not port_ids.is_empty(),
    (var name, var tunnel_key) = mC_STATIC().

/* Create a multicast group to flood reports to ports with
 * multicast flood_reports enabled.
 */
sb::Out_Multicast_Group (._uuid    = hash128((sw.ls._uuid,name)),
                        .datapath = sw.ls._uuid,
                        .name = name,
                        .tunnel_key = tunnel_key,
                        .ports = port_ids) :-
    SwitchMcastFloodReportPorts(&sw, port_ids),
    not port_ids.is_empty(),
    (var name, var tunnel_key) = mC_MROUTER_STATIC().

/* Create a multicast group to flood traffic and reports to router ports with
 * multicast flood enabled.
 */
sb::Out_Multicast_Group (._uuid    = hash128((rtr.lr._uuid,name)),
                        .datapath = rtr.lr._uuid,
                        .name = name,
                        .tunnel_key = tunnel_key,
                        .ports = port_ids) :-
    RouterMcastFloodPorts(&rtr, port_ids),
    not port_ids.is_empty(),
    (var name, var tunnel_key) = mC_STATIC().

/* Create a multicast group for each IGMP group learned by a Switch.
 * 'tunnel_key' == 0 triggers an ID allocation later.
 */
OutProxy_Multicast_Group (.datapath   = switch.ls._uuid,
                          .name       = address,
                          .ports      = port_ids) :-
    IgmpSwitchMulticastGroup(address, &switch, port_ids).

/* Create a multicast group for each IGMP group learned by a Router.
 * 'tunnel_key' == 0 triggers an ID allocation later.
 */
OutProxy_Multicast_Group (.datapath   = router.lr._uuid,
                          .name       = address,
                          .ports      = port_ids) :-
    IgmpRouterMulticastGroup(address, &router, port_ids).

/* Allocate a 'tunnel_key' for dynamic multicast groups. */
sb::Out_Multicast_Group(._uuid    = hash128((mcgroup.datapath,mcgroup.name)),
                       .datapath = mcgroup.datapath,
                       .name = mcgroup.name,
                       .tunnel_key = tunnel_key,
                       .ports = mcgroup.ports) :-
    mcgroup in OutProxy_Multicast_Group(),
    MulticastGroupTunKeyAllocation(mcgroup.datapath, mcgroup.name, tunnel_key).

/*
 * MAC binding: records inserted by hypervisors; northd removes records for deleted logical ports and datapaths.
 */
sb::Out_MAC_Binding (._uuid        = mb._uuid,
                    .logical_port = mb.logical_port,
                    .ip           = mb.ip,
                    .mac          = mb.mac,
                    .datapath     = mb.datapath) :-
    sb::MAC_Binding[mb],
    sb::Out_Port_Binding(.logical_port = mb.logical_port),
    sb::Out_Datapath_Binding(._uuid = mb.datapath).

/*
 * DHCP options: fixed table
 */
sb::Out_DHCP_Options (
    ._uuid  = 128'h7d9d898a_179b_4898_8382_b73bec391f23,
    .name   = "offerip",
    .code   = 0,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hea5e7d14_fd97_491c_8004_a120bdbc4306,
    .name   = "netmask",
    .code   = 1,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hdab5e39b_6702_4245_9573_6c142aa3724c,
    .name   = "router",
    .code   = 3,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h340b4bc5_c5c3_43d1_ae77_564da69c8fcc,
    .name   = "dns_server",
    .code   = 6,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hcd1ab302_cbb2_4eab_9ec5_ec1c8541bd82,
    .name   = "log_server",
    .code   = 7,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h1c7ea6a0_fe6b_48c1_a920_302583c1ff08,
    .name   = "lpr_server",
    .code   = 9,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hae35e575_226a_4ab5_a1c4_166f426dd999,
    .name   = "domain_name",
    .code   = 15,
    .__type = "str"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'had0ec3e0_8be9_4c77_bceb_f8954a34c7ba,
    .name   = "swap_server",
    .code   = 16,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h884c2e02_6e99_4d12_aef7_8454ebf8a3b7,
    .name   = "policy_filter",
    .code   = 21,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h57cc2c61_fd2a_41c6_b6b1_6ce9a8901f86,
    .name   = "router_solicitation",
    .code   = 32,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h48249097_03f0_46c1_a32a_2dd57cd4d0f8,
    .name   = "nis_server",
    .code   = 41,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h333fe07e_bdd1_4371_aa4f_a412bc60f3a2,
    .name   = "ntp_server",
    .code   = 42,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h6207109c_49d0_4348_8238_dd92afb69bf0,
    .name   = "server_id",
    .code   = 54,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h2090b783_26d3_4c1d_830c_54c1b6c5d846,
    .name   = "tftp_server",
    .code   = 66,
    .__type = "host_id"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'ha18ff399_caea_406e_af7e_321c6f74e581,
    .name   = "classless_static_route",
    .code   = 121,
    .__type = "static_routes"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hb81ad7b4_62f0_40c7_a9a3_f96677628767,
    .name   = "ms_classless_static_route",
    .code   = 249,
    .__type = "static_routes"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h0c2e144e_4b5f_4e21_8978_0e20bac9a6ea,
    .name   = "ip_forward_enable",
    .code   = 19,
    .__type = "bool"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h6feb1926_9469_4b40_bfbf_478b9888cd3a,
    .name   = "router_discovery",
    .code   = 31,
    .__type = "bool"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hcb776249_e8b1_4502_b33b_fa294d44077d,
    .name   = "ethernet_encap",
    .code   = 36,
    .__type = "bool"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'ha2df9eaa_aea9_497f_b339_0c8ec3e39a07,
    .name   = "default_ttl",
    .code   = 23,
    .__type = "uint8"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hb44b45a9_5004_4ef5_8e6a_aa8629e1afb1,
    .name   = "tcp_ttl",
    .code   = 37,
    .__type = "uint8"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h50f01ca7_c650_46f0_8f50_39a67ec657da,
    .name   = "mtu",
    .code   = 26,
    .__type = "uint16"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h9d31c057_6085_4810_96af_eeac7d3c5308,
    .name   = "lease_time",
    .code   = 51,
    .__type = "uint32"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hea1e2e7a_9585_46ee_ad49_adfdefc0c4ef,
    .name   = "T1",
    .code   = 58,
    .__type = "uint32"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hbc83a233_554b_453a_afca_1eadf76810d2,
    .name   = "T2",
    .code   = 59,
    .__type = "uint32"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h1ab3eeca_0523_4101_9076_eea77d0232f4,
    .name   = "bootfile_name",
    .code   = 67,
    .__type = "str"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'ha5c20b69_f7f3_4fa8_b550_8697aec6cbb7,
    .name   = "wpad",
    .code   = 252,
    .__type = "str"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h1516bcb6_cc93_4233_a63f_bd29c8601831,
    .name   = "path_prefix",
    .code   = 210,
    .__type = "str"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hc98e13cd_f653_473c_85c1_850dcad685fc,
    .name   = "tftp_server_address",
    .code   = 150,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hfbe06e70_b43d_4dd9_9b21_2f27eb5da5df,
    .name   = "arp_cache_timeout",
    .code   = 35,
    .__type = "uint32"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h2af54a3c_545c_4104_ae1c_432caa3e085e,
    .name   = "tcp_keepalive_interval",
    .code   = 38,
    .__type = "uint32"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h4b2144e8_8d3f_4d96_9032_fe23c1866cd4,
    .name   = "domain_search_list",
    .code   = 119,
    .__type = "domains"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'hb7236164_eea4_4bf2_9306_8619a9e3ad1d,
    .name   = "broadcast_address",
    .code   = 28,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h32224b72_1561_4279_b430_982423b62a69,
    .name   = "netbios_name_server",
    .code   = 44,
    .__type = "ipv4"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h691db4ae_624e_43e2_9f4a_5ed9de58f0e5,
    .name   = "netbios_node_type",
    .code   = 46,
    .__type = "uint8"
).

sb::Out_DHCP_Options (
    ._uuid  = 128'h2d738583_96f4_4a78_99a1_f8f7fe328f3f,
    .name   = "bootfile_name_alt",
    .code   = 254,
    .__type = "str"
).


/*
 * DHCPv6 options: fixed table
 */
sb::Out_DHCPv6_Options (
    ._uuid  = 128'h100b2659_0ec0_4da7_9ec3_25997f92dc00,
    .name   = "server_id",
    .code   = 2,
    .__type = "mac"
).

sb::Out_DHCPv6_Options (
    ._uuid  = 128'h53f49b50_db75_4b0d_83df_50d31009ca9c,
    .name   = "ia_addr",
    .code   = 5,
    .__type = "ipv6"
).

sb::Out_DHCPv6_Options (
    ._uuid  = 128'he3619685_d4f7_42ad_936b_4f4440b7eeb4,
    .name   = "dns_server",
    .code   = 23,
    .__type = "ipv6"
).

sb::Out_DHCPv6_Options (
    ._uuid  = 128'hcb8a4e7f_a312_4cb1_a846_e474d9f0c531,
    .name   = "domain_search",
    .code   = 24,
    .__type = "str"
).


/*
 * DNS: copied from NB + datapaths column pointer to LS datapaths that use the record
 */

function map_to_lowercase(m_in: Map<string,string>): Map<string,string> {
    var m_out = map_empty();
    for (node in m_in) {
        (var k, var v) = node;
        m_out.insert(string_to_lowercase(k), string_to_lowercase(v))
    };
    m_out
}

sb::Out_DNS(._uuid        = hash128(nbdns._uuid),
           .records      = map_to_lowercase(nbdns.records),
           .datapaths    = datapaths,
           .external_ids = nbdns.external_ids.insert_imm("dns_id", uuid2str(nbdns._uuid))) :-
    nb::DNS[nbdns],
    LogicalSwitchDNS(ls_uuid, nbdns._uuid),
    var datapaths = ls_uuid.group_by(nbdns).to_set().

/*
 * RBAC_Permission: fixed
 */

sb::Out_RBAC_Permission (
    ._uuid          = 128'h7df3749a_1754_4a78_afa4_3abf526fe510,
    .table          = "Chassis",
    .authorization  = set_singleton("name"),
    .insert_delete  = true,
    .update         = ["nb_cfg", "external_ids", "encaps",
                       "vtep_logical_switches", "other_config",
                       "transport_zones"].to_set()
).

sb::Out_RBAC_Permission (
    ._uuid          = 128'h07e623f7_137c_4a11_9084_3b3f89cb4a54,
    .table          = "Chassis_Private",
    .authorization  = set_singleton("name"),
    .insert_delete  = true,
    .update         = ["nb_cfg", "nb_cfg_timestamp", "chassis", "external_ids"].to_set()
).

sb::Out_RBAC_Permission (
    ._uuid          = 128'h94bec860_431e_4d95_82e7_3b75d8997241,
    .table          = "Encap",
    .authorization  = set_singleton("chassis_name"),
    .insert_delete  = true,
    .update         = ["type", "options", "ip"].to_set()
).

sb::Out_RBAC_Permission (
    ._uuid          = 128'hd8ceff1a_2b11_48bd_802f_4a991aa4e908,
    .table          = "Port_Binding",
    .authorization  = set_singleton(""),
    .insert_delete  = false,
    .update         = ["chassis", "encap", "up", "virtual_parent"].to_set()
).

sb::Out_RBAC_Permission (
    ._uuid          = 128'h6ffdc696_8bfb_4d82_b620_a00d39270b2f,
    .table          = "MAC_Binding",
    .authorization  = set_singleton(""),
    .insert_delete  = true,
    .update         = ["logical_port", "ip", "mac", "datapath"].to_set()
).

sb::Out_RBAC_Permission (
    ._uuid          = 128'h39231c7e_4bf1_41d0_ada4_1d8a319c0da3,
    .table          = "Service_Monitor",
    .authorization  = set_singleton(""),
    .insert_delete  = false,
    .update         = set_singleton("status")
).

sb::Out_RBAC_Permission (
    ._uuid          = 128'h5256f48e_172c_4d85_8f04_e199fa817633,
    .table          = "IGMP_Group",
    .authorization  = set_singleton(""),
    .insert_delete  = true,
    .update         = ["address", "chassis", "datapath", "ports"].to_set()
).

sb::Out_RBAC_Permission (
    ._uuid          = 128'h2e5cbf3d_26f6_4f8a_9926_d6f77f61654f,
    .table          = "Controller_Event",
    .authorization  = set_singleton(""),
    .insert_delete  = true,
    .update         = ["chassis", "event_info", "event_type",
                       "seq_num"].to_set()
).

sb::Out_RBAC_Permission (
    ._uuid          = 128'hb70964fc_322f_4ae5_aee4_ff6afadcc126,
    .table          = "FDB",
    .authorization  = set_singleton(""),
    .insert_delete  = true,
    .update         = ["dp_key", "mac", "port_key"].to_set()
).

/*
 * RBAC_Role: fixed
 */
sb::Out_RBAC_Role (
    ._uuid       = 128'ha406b472_5de8_4456_9f38_bf344c911b22,
    .name        = "ovn-controller",
    .permissions = [
        "Chassis" -> 128'h7df3749a_1754_4a78_afa4_3abf526fe510,
        "Chassis_Private" -> 128'h07e623f7_137c_4a11_9084_3b3f89cb4a54,
        "Controller_Event" -> 128'h2e5cbf3d_26f6_4f8a_9926_d6f77f61654f,
        "Encap" -> 128'h94bec860_431e_4d95_82e7_3b75d8997241,
        "FDB" -> 128'hb70964fc_322f_4ae5_aee4_ff6afadcc126,
        "Port_Binding" -> 128'hd8ceff1a_2b11_48bd_802f_4a991aa4e908,
        "MAC_Binding" -> 128'h6ffdc696_8bfb_4d82_b620_a00d39270b2f,
        "Service_Monitor"-> 128'h39231c7e_4bf1_41d0_ada4_1d8a319c0da3]

).

/* Output modified Logical_Switch_Port table with dynamic address updated */
nb::Out_Logical_Switch_Port(._uuid                  = lsp._uuid,
                           .tag                    = tag,
                           .dynamic_addresses      = dynamic_addresses,
                           .up                     = Some{up}) :-
    SwitchPortNewDynamicAddress(&SwitchPort{.lsp = lsp, .up = up}, opt_dyn_addr),
    var dynamic_addresses = opt_dyn_addr.and_then(|a| Some{"${a}"}),
    SwitchPortNewDynamicTag(lsp._uuid, opt_tag),
    var tag = match (opt_tag) {
        None -> lsp.tag,
        Some{t} -> Some{t}
    }.

relation LRPIPv6Prefix0(lrp_uuid: uuid, ipv6_prefix: string)
LRPIPv6Prefix0(lrp._uuid, ipv6_prefix) :-
    lrp in nb::Logical_Router_Port(),
    lrp.options.get_bool_def("prefix", false),
    sb::Port_Binding(.logical_port = lrp.name, .options = options),
    Some{var ipv6_ra_pd_list} = options.get("ipv6_ra_pd_list"),
    var parts = string_split(ipv6_ra_pd_list, ","),
    Some{var ipv6_prefix} = parts.nth(1).

relation LRPIPv6Prefix(lrp_uuid: uuid, ipv6_prefix: Option<string>)
LRPIPv6Prefix(lrp_uuid, Some{ipv6_prefix}) :-
    LRPIPv6Prefix0(lrp_uuid, ipv6_prefix).
LRPIPv6Prefix(lrp_uuid, None) :-
    nb::Logical_Router_Port(._uuid = lrp_uuid),
    not LRPIPv6Prefix0(lrp_uuid, _).

nb::Out_Logical_Router_Port(._uuid = _uuid,
                           .ipv6_prefix = to_set(ipv6_prefix)) :-
    nb::Logical_Router_Port(._uuid = _uuid, .name = name),
    LRPIPv6Prefix(_uuid, ipv6_prefix).

typedef Pipeline = Ingress | Egress

typedef Stage = Stage{
    pipeline    : Pipeline,
    table_id    : integer,
    table_name  : string
}

/* Logical switch ingress stages. */
function s_SWITCH_IN_PORT_SEC_L2():     Stage { Stage{Ingress,  0, "ls_in_port_sec_l2"} }
function s_SWITCH_IN_PORT_SEC_IP():     Stage { Stage{Ingress,  1, "ls_in_port_sec_ip"} }
function s_SWITCH_IN_PORT_SEC_ND():     Stage { Stage{Ingress,  2, "ls_in_port_sec_nd"} }
function s_SWITCH_IN_LOOKUP_FDB():      Stage { Stage{Ingress,  3, "ls_in_lookup_fdb"} }
function s_SWITCH_IN_PUT_FDB():         Stage { Stage{Ingress,  4, "ls_in_put_fdb"} }
function s_SWITCH_IN_PRE_ACL():         Stage { Stage{Ingress,  5, "ls_in_pre_acl"} }
function s_SWITCH_IN_PRE_LB():          Stage { Stage{Ingress,  6, "ls_in_pre_lb"} }
function s_SWITCH_IN_PRE_STATEFUL():    Stage { Stage{Ingress,  7, "ls_in_pre_stateful"} }
function s_SWITCH_IN_ACL_HINT():        Stage { Stage{Ingress,  8, "ls_in_acl_hint"} }
function s_SWITCH_IN_ACL():             Stage { Stage{Ingress,  9, "ls_in_acl"} }
function s_SWITCH_IN_QOS_MARK():        Stage { Stage{Ingress, 10, "ls_in_qos_mark"} }
function s_SWITCH_IN_QOS_METER():       Stage { Stage{Ingress, 11, "ls_in_qos_meter"} }
function s_SWITCH_IN_LB():              Stage { Stage{Ingress, 12, "ls_in_lb"} }
function s_SWITCH_IN_STATEFUL():        Stage { Stage{Ingress, 13, "ls_in_stateful"} }
function s_SWITCH_IN_PRE_HAIRPIN():     Stage { Stage{Ingress, 14, "ls_in_pre_hairpin"} }
function s_SWITCH_IN_NAT_HAIRPIN():     Stage { Stage{Ingress, 15, "ls_in_nat_hairpin"} }
function s_SWITCH_IN_HAIRPIN():         Stage { Stage{Ingress, 16, "ls_in_hairpin"} }
function s_SWITCH_IN_ARP_ND_RSP():      Stage { Stage{Ingress, 17, "ls_in_arp_rsp"} }
function s_SWITCH_IN_DHCP_OPTIONS():    Stage { Stage{Ingress, 18, "ls_in_dhcp_options"} }
function s_SWITCH_IN_DHCP_RESPONSE():   Stage { Stage{Ingress, 19, "ls_in_dhcp_response"} }
function s_SWITCH_IN_DNS_LOOKUP():      Stage { Stage{Ingress, 20, "ls_in_dns_lookup"} }
function s_SWITCH_IN_DNS_RESPONSE():    Stage { Stage{Ingress, 21, "ls_in_dns_response"} }
function s_SWITCH_IN_EXTERNAL_PORT():   Stage { Stage{Ingress, 22, "ls_in_external_port"} }
function s_SWITCH_IN_L2_LKUP():         Stage { Stage{Ingress, 23, "ls_in_l2_lkup"} }
function s_SWITCH_IN_L2_UNKNOWN():      Stage { Stage{Ingress, 24, "ls_in_l2_unknown"} }

/* Logical switch egress stages. */
function s_SWITCH_OUT_PRE_LB():         Stage { Stage{ Egress,  0, "ls_out_pre_lb"} }
function s_SWITCH_OUT_PRE_ACL():        Stage { Stage{ Egress,  1, "ls_out_pre_acl"} }
function s_SWITCH_OUT_PRE_STATEFUL():   Stage { Stage{ Egress,  2, "ls_out_pre_stateful"} }
function s_SWITCH_OUT_LB():             Stage { Stage{ Egress,  3, "ls_out_lb"} }
function s_SWITCH_OUT_ACL_HINT():       Stage { Stage{ Egress,  4, "ls_out_acl_hint"} }
function s_SWITCH_OUT_ACL():            Stage { Stage{ Egress,  5, "ls_out_acl"} }
function s_SWITCH_OUT_QOS_MARK():       Stage { Stage{ Egress,  6, "ls_out_qos_mark"} }
function s_SWITCH_OUT_QOS_METER():      Stage { Stage{ Egress,  7, "ls_out_qos_meter"} }
function s_SWITCH_OUT_STATEFUL():       Stage { Stage{ Egress,  8, "ls_out_stateful"} }
function s_SWITCH_OUT_PORT_SEC_IP():    Stage { Stage{ Egress,  9, "ls_out_port_sec_ip"} }
function s_SWITCH_OUT_PORT_SEC_L2():    Stage { Stage{ Egress, 10, "ls_out_port_sec_l2"} }

/* Logical router ingress stages. */
function s_ROUTER_IN_ADMISSION():       Stage { Stage{Ingress,  0, "lr_in_admission"} }
function s_ROUTER_IN_LOOKUP_NEIGHBOR(): Stage { Stage{Ingress,  1, "lr_in_lookup_neighbor"} }
function s_ROUTER_IN_LEARN_NEIGHBOR():  Stage { Stage{Ingress,  2, "lr_in_learn_neighbor"} }
function s_ROUTER_IN_IP_INPUT():        Stage { Stage{Ingress,  3, "lr_in_ip_input"} }
function s_ROUTER_IN_DEFRAG():          Stage { Stage{Ingress,  4, "lr_in_defrag"} }
function s_ROUTER_IN_UNSNAT():          Stage { Stage{Ingress,  5, "lr_in_unsnat"} }
function s_ROUTER_IN_DNAT():            Stage { Stage{Ingress,  6, "lr_in_dnat"} }
function s_ROUTER_IN_ECMP_STATEFUL():   Stage { Stage{Ingress,  7, "lr_in_ecmp_stateful"} }
function s_ROUTER_IN_ND_RA_OPTIONS():   Stage { Stage{Ingress,  8, "lr_in_nd_ra_options"} }
function s_ROUTER_IN_ND_RA_RESPONSE():  Stage { Stage{Ingress,  9, "lr_in_nd_ra_response"} }
function s_ROUTER_IN_IP_ROUTING():      Stage { Stage{Ingress, 10, "lr_in_ip_routing"} }
function s_ROUTER_IN_IP_ROUTING_ECMP(): Stage { Stage{Ingress, 11, "lr_in_ip_routing_ecmp"} }
function s_ROUTER_IN_POLICY():          Stage { Stage{Ingress, 12, "lr_in_policy"} }
function s_ROUTER_IN_POLICY_ECMP():     Stage { Stage{Ingress, 13, "lr_in_policy_ecmp"} }
function s_ROUTER_IN_ARP_RESOLVE():     Stage { Stage{Ingress, 14, "lr_in_arp_resolve"} }
function s_ROUTER_IN_CHK_PKT_LEN():     Stage { Stage{Ingress, 15, "lr_in_chk_pkt_len"} }
function s_ROUTER_IN_LARGER_PKTS():     Stage { Stage{Ingress, 16, "lr_in_larger_pkts"} }
function s_ROUTER_IN_GW_REDIRECT():     Stage { Stage{Ingress, 17, "lr_in_gw_redirect"} }
function s_ROUTER_IN_ARP_REQUEST():     Stage { Stage{Ingress, 18, "lr_in_arp_request"} }

/* Logical router egress stages. */
function s_ROUTER_OUT_UNDNAT():         Stage { Stage{ Egress,  0, "lr_out_undnat"} }
function s_ROUTER_OUT_SNAT():           Stage { Stage{ Egress,  1, "lr_out_snat"} }
function s_ROUTER_OUT_EGR_LOOP():       Stage { Stage{ Egress,  2, "lr_out_egr_loop"} }
function s_ROUTER_OUT_DELIVERY():       Stage { Stage{ Egress,  3, "lr_out_delivery"} }

/*
 * OVS register usage:
 *
 * Logical Switch pipeline:
 * +----+----------------------------------------------+---+------------------+
 * | R0 |     REGBIT_{CONNTRACK/DHCP/DNS}              |   |                  |
 * |    |     REGBIT_{HAIRPIN/HAIRPIN_REPLY}           | X |                  |
 * +----+----------------------------------------------+ X |                  |
 * | R1 |         ORIG_DIP_IPV4 (>= IN_STATEFUL)       | R |                  |
 * +----+----------------------------------------------+ E |                  |
 * | R2 |         ORIG_TP_DPORT (>= IN_STATEFUL)       | G |                  |
 * +----+----------------------------------------------+ 0 |                  |
 * | R3 |                   UNUSED                     |   |                  |
 * +----+----------------------------------------------+---+------------------+
 * | R4 |                   UNUSED                     |   |                  |
 * +----+----------------------------------------------+ X |   ORIG_DIP_IPV6  |
 * | R5 |                   UNUSED                     | X | (>= IN_STATEFUL) |
 * +----+----------------------------------------------+ R |                  |
 * | R6 |                   UNUSED                     | E |                  |
 * +----+----------------------------------------------+ G |                  |
 * | R7 |                   UNUSED                     | 1 |                  |
 * +----+----------------------------------------------+---+------------------+
 * | R8 |                   UNUSED                     |
 * +----+----------------------------------------------+
 * | R9 |                   UNUSED                     |
 * +----+----------------------------------------------+
 *
 * Logical Router pipeline:
 * +-----+--------------------------+---+-----------------+---+---------------+
 * | R0  | REGBIT_ND_RA_OPTS_RESULT |   |                 |   |               |
 * |     |   (= IN_ND_RA_OPTIONS)   | X |                 |   |               |
 * |     |      NEXT_HOP_IPV4       | R |                 |   |               |
 * |     |      (>= IP_INPUT)       | E | INPORT_ETH_ADDR | X |               |
 * +-----+--------------------------+ G |   (< IP_INPUT)  | X |               |
 * | R1  |   SRC_IPV4 for ARP-REQ   | 0 |                 | R |               |
 * |     |      (>= IP_INPUT)       |   |                 | E | NEXT_HOP_IPV6 |
 * +-----+--------------------------+---+-----------------+ G | (>= IP_INPUT) |
 * | R2  |        UNUSED            | X |                 | 0 |               |
 * |     |                          | R |                 |   |               |
 * +-----+--------------------------+ E |     UNUSED      |   |               |
 * | R3  |        UNUSED            | G |                 |   |               |
 * |     |                          | 1 |                 |   |               |
 * +-----+--------------------------+---+-----------------+---+---------------+
 * | R4  |        UNUSED            | X |                 |   |               |
 * |     |                          | R |                 |   |               |
 * +-----+--------------------------+ E |     UNUSED      | X |               |
 * | R5  |        UNUSED            | G |                 | X |               |
 * |     |                          | 2 |                 | R |SRC_IPV6 for NS|
 * +-----+--------------------------+---+-----------------+ E | (>= IP_INPUT) |
 * | R6  |        UNUSED            | X |                 | G |               |
 * |     |                          | R |                 | 1 |               |
 * +-----+--------------------------+ E |     UNUSED      |   |               |
 * | R7  |        UNUSED            | G |                 |   |               |
 * |     |                          | 3 |                 |   |               |
 * +-----+--------------------------+---+-----------------+---+---------------+
 * | R8  |     ECMP_GROUP_ID        |   |                 |
 * |     |     ECMP_MEMBER_ID       | X |                 |
 * +-----+--------------------------+ R |                 |
 * |     | REGBIT_{                 | E |                 |
 * |     |   EGRESS_LOOPBACK/       | G |     UNUSED      |
 * | R9  |   PKT_LARGER/            | 4 |                 |
 * |     |   LOOKUP_NEIGHBOR_RESULT/|   |                 |
 * |     |   SKIP_LOOKUP_NEIGHBOR}  |   |                 |
 * +-----+--------------------------+---+-----------------+
 *
 */

/* Register definitions specific to routers. */
function rEG_NEXT_HOP(): string = "reg0" /* reg0 for IPv4, xxreg0 for IPv6 */
function rEG_SRC(): string = "reg1"      /* reg1 for IPv4, xxreg1 for IPv6 */

/* Register definitions specific to switches. */
function rEGBIT_CONNTRACK_DEFRAG() : string = "reg0[0]"
function rEGBIT_CONNTRACK_COMMIT() : string = "reg0[1]"
function rEGBIT_CONNTRACK_NAT()    : string = "reg0[2]"
function rEGBIT_DHCP_OPTS_RESULT() : string = "reg0[3]"
function rEGBIT_DNS_LOOKUP_RESULT(): string = "reg0[4]"
function rEGBIT_ND_RA_OPTS_RESULT(): string = "reg0[5]"
function rEGBIT_HAIRPIN()          : string = "reg0[6]"
function rEGBIT_ACL_HINT_ALLOW_NEW(): string = "reg0[7]"
function rEGBIT_ACL_HINT_ALLOW()   : string = "reg0[8]"
function rEGBIT_ACL_HINT_DROP()    : string = "reg0[9]"
function rEGBIT_ACL_HINT_BLOCK()   : string = "reg0[10]"
function rEGBIT_LKUP_FDB()         : string = "reg0[11]"
function rEGBIT_HAIRPIN_REPLY()    : string = "reg0[12]"

function rEG_ORIG_DIP_IPV4()       : string = "reg1"
function rEG_ORIG_DIP_IPV6()       : string = "xxreg1"
function rEG_ORIG_TP_DPORT()       : string = "reg2[0..15]"

/* Register definitions for switches and routers. */

/* Indicate that this packet has been recirculated using egress
 * loopback.  This allows certain checks to be bypassed, such as a
* logical router dropping packets with source IP address equals
* one of the logical router's own IP addresses. */
function rEGBIT_EGRESS_LOOPBACK()  : string = "reg9[0]"
/* Register to store the result of check_pkt_larger action. */
function rEGBIT_PKT_LARGER()       : string = "reg9[1]"
function rEGBIT_LOOKUP_NEIGHBOR_RESULT() : string = "reg9[2]"
function rEGBIT_LOOKUP_NEIGHBOR_IP_RESULT() : string = "reg9[3]"

/* Register to store the eth address associated to a router port for packets
 * received in S_ROUTER_IN_ADMISSION.
 */
function rEG_INPORT_ETH_ADDR() : string = "xreg0[0..47]"

/* Register for ECMP bucket selection. */
function rEG_ECMP_GROUP_ID()  : string = "reg8[0..15]"
function rEG_ECMP_MEMBER_ID() : string = "reg8[16..31]"

function fLAGBIT_NOT_VXLAN() : string = "flags[1] == 0"

function mFF_N_LOG_REGS()          : bit<32> = 10

/*
 * Generating sb::Logical_Flow and sb::Logical_DP_Group.
 *
 * Some logical flows occur in multiple logical datapaths.  These can
 * be represented two ways: either as multiple Logical_Flow records
 * (each with logical_datapath set appropriately) or as a single
 * Logical_Flow record that points to a Logical_DP_Group record that
 * lists all the datapaths it's in.  (It would be possible to mix or
 * duplicate these methods, but we don't do that.)  We have to support
 * both:
 *
 *    - There's a setting "use_logical_dp_groups" that globally
 *      enables or disables this feature.
 *
 *    - Some flows can't use this feature even if it's globally
 *      enabled, due to ovn-controller bugs (see commit bfed224006750
 *      "northd: Add support for Logical Datapath Groups.").  Flows
 *      that can't be shared must get added into AnnotatedFlow with
 *      'shared' set to 'false', instead of Flow.
 */

relation Flow(
    logical_datapath: uuid,
    stage:            Stage,
    priority:         integer,
    __match:          string,
    actions:          string,
    external_ids:     Map<string,string>
)

/* If this option is 'true' northd will combine logical flows that differ by
 * logical datapath only by creating a datapath group. */
relation UseLogicalDatapathGroups[bool]
UseLogicalDatapathGroups[use_logical_dp_groups] :-
    nb in nb::NB_Global(),
    var use_logical_dp_groups = nb.options.get_bool_def("use_logical_dp_groups", false).
UseLogicalDatapathGroups[false] :-
    Unit(),
    not nb in nb::NB_Global().

relation AnnotatedFlow(f: Flow, shared: bool)
AnnotatedFlow(f, b) :- UseLogicalDatapathGroups[b], Flow[f].

relation UniqueFlow[Flow]
AnnotatedFlow(f, false) :- UniqueFlow[f].

relation AggregatedFlow (
    logical_datapaths: Set<uuid>,
    stage:             Stage,
    priority:          integer,
    __match:           string,
    actions:           string,
    external_ids:      Map<string,string>
)
AggregatedFlow(.logical_datapaths = g.to_set(),
               .stage = stage,
               .priority = priority,
               .__match = __match,
               .actions = actions,
               .external_ids = external_ids) :-
    AnnotatedFlow(Flow{logical_datapath, stage, priority, __match, actions, external_ids}, true),
    var g = logical_datapath.group_by((stage, priority, __match, actions, external_ids)).
AggregatedFlow(.logical_datapaths = set_singleton(logical_datapath),
               .stage = stage,
               .priority = priority,
               .__match = __match,
               .actions = actions,
               .external_ids = external_ids) :-
    AnnotatedFlow(Flow{logical_datapath, stage, priority, __match, actions, external_ids}, false).

for (f in AggregatedFlow()) {
    var pipeline = if (f.stage.pipeline == Ingress) "ingress" else "egress" in
    var external_ids = f.external_ids.insert_imm("stage-name", f.stage.table_name) in
    if (f.logical_datapaths.size() == 1) {
        Some{var dp} = f.logical_datapaths.nth(0) in
        sb::Out_Logical_Flow(
            ._uuid = hash128((dp, f.stage, f.priority, f.__match, f.actions, f.external_ids)),
            .logical_datapath = Some{dp},
            .logical_dp_group = None,
            .pipeline         = pipeline,
            .table_id         = f.stage.table_id,
            .priority         = f.priority,
            .__match          = f.__match,
            .actions          = f.actions,
            .external_ids     = external_ids)
    } else {
        var group_uuid = hash128(f.logical_datapaths) in {
            sb::Out_Logical_Flow(
                ._uuid = hash128((group_uuid, f.stage, f.priority, f.__match, f.actions, f.external_ids)),
                .logical_datapath = None,
                .logical_dp_group = Some{group_uuid},
                .pipeline         = pipeline,
                .table_id         = f.stage.table_id,
                .priority         = f.priority,
                .__match          = f.__match,
                .actions          = f.actions,
                .external_ids     = external_ids);
            sb::Out_Logical_DP_Group(._uuid = group_uuid, .datapaths = f.logical_datapaths)
        }
    }
}

/* Logical flows for forwarding groups. */
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = s_SWITCH_IN_ARP_ND_RSP(),
     .priority         = 50,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(fg_uuid)) :-
    sw in &Switch(),
    var fg_uuid = FlatMap(sw.ls.forwarding_groups),
    fg in nb::Forwarding_Group(._uuid = fg_uuid),
    not fg.child_port.is_empty(),
    var __match = "arp.tpa == ${fg.vip} && arp.op == 1",
    var actions = "eth.dst = eth.src; "
                  "eth.src = ${fg.vmac}; "
                  "arp.op = 2; /* ARP reply */ "
                  "arp.tha = arp.sha; "
                  "arp.sha = ${fg.vmac}; "
                  "arp.tpa = arp.spa; "
                  "arp.spa = ${fg.vip}; "
                  "outport = inport; "
                  "flags.loopback = 1; "
                  "output;".

function escape_child_ports(child_port: Set<string>): string {
    var escaped = vec_with_capacity(child_port.size());
    for (s in child_port) {
        escaped.push(json_string_escape(s))
    };
    escaped.join(",")
}
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = s_SWITCH_IN_L2_LKUP(),
     .priority         = 50,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = map_empty()) :-
    sw in &Switch(),
    var fg_uuid = FlatMap(sw.ls.forwarding_groups),
    fg in nb::Forwarding_Group(._uuid = fg_uuid),
    not fg.child_port.is_empty(),
    var __match = "eth.dst == ${fg.vmac}",
    var actions = "fwd_group(" ++
                  if (fg.liveness) { "liveness=\"true\"," } else { "" } ++
                  "childports=" ++ escape_child_ports(fg.child_port) ++ ");".

/* Logical switch ingress table PORT_SEC_L2: admission control framework
 * (priority 100) */
for (sw in &Switch()) {
    if (not sw.is_vlan_transparent) {
        /* Block logical VLANs. */
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = s_SWITCH_IN_PORT_SEC_L2(),
             .priority         = 100,
             .__match          = "vlan.present",
             .actions          = "drop;",
             .external_ids     = map_empty() /*TODO: check*/)
    };

    /* Broadcast/multicast source address is invalid */
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_IN_PORT_SEC_L2(),
         .priority         = 100,
         .__match          = "eth.src[40]",
         .actions          = "drop;",
         .external_ids     = map_empty() /*TODO: check*/)
    /* Port security flows have priority 50 (see below) and will continue to the next table
       if packet source is acceptable. */
}

// space-separated set of strings
function join(strings: Set<string>, sep: string): string {
    strings.to_vec().join(sep)
}

function build_port_security_ipv6_flow(
    pipeline: Pipeline,
    ea: eth_addr,
    ipv6_addrs: Vec<ipv6_netaddr>): string =
{
    var ip6_addrs = vec_empty();

    /* Allow link-local address. */
    ip6_addrs.push(ea.to_ipv6_lla().string_mapped());

    /* Allow ip6.dst=ff00::/8 for multicast packets */
    if (pipeline == Egress) {
        ip6_addrs.push("ff00::/8")
    };
    for (addr in ipv6_addrs) {
        ip6_addrs.push(addr.match_network())
    };

    var dir = if (pipeline == Ingress) { "src" } else { "dst" };
    " && ip6.${dir} == {" ++ ip6_addrs.join(", ") ++ "}"
}

function build_port_security_ipv6_nd_flow(
    ea: eth_addr,
    ipv6_addrs: Vec<ipv6_netaddr>): string =
{
    var __match = " && ip6 && nd && ((nd.sll == ${eth_addr_zero()} || "
                  "nd.sll == ${ea}) || ((nd.tll == ${eth_addr_zero()} || "
                  "nd.tll == ${ea})";
    if (ipv6_addrs.is_empty()) {
        __match ++ "))"
    } else {
        __match = __match ++ " && (nd.target == ${ea.to_ipv6_lla()}";

        for(addr in ipv6_addrs) {
            __match = __match ++ " || nd.target == ${addr.match_network()}"
        };
        __match ++ ")))"
    }
}

/* Pre-ACL */
for (&Switch(.ls =ls)) {
    /* Ingress and Egress Pre-ACL Table (Priority 0): Packets are
     * allowed by default. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_ACL(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_ACL(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_ACL(),
         .priority         = 110,
         .__match          = "eth.dst == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_ACL(),
         .priority         = 110,
         .__match          = "eth.src == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty())
}


/* If there are any stateful ACL rules in this datapath, we must
 * send all IP packets through the conntrack action, which handles
 * defragmentation, in order to match L4 headers. */

for (&SwitchPort(.lsp = lsp@nb::Logical_Switch_Port{.__type = "router"},
                 .json_name = lsp_name,
                 .sw = &Switch{.ls = ls, .has_stateful_acl = true})) {
    /* Can't use ct() for router ports. Consider the
     * following configuration: lp1(10.0.0.2) on
     * hostA--ls1--lr0--ls2--lp2(10.0.1.2) on hostB, For a
     * ping from lp1 to lp2, First, the response will go
     * through ct() with a zone for lp2 in the ls2 ingress
     * pipeline on hostB.  That ct zone knows about this
     * connection. Next, it goes through ct() with the zone
     * for the router port in the egress pipeline of ls2 on
     * hostB.  This zone does not know about the connection,
     * as the icmp request went through the logical router
     * on hostA, not hostB. This would only work with
     * distributed conntrack state across all chassis. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_ACL(),
         .priority         = 110,
         .__match          = "ip && inport == ${lsp_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid));
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_ACL(),
         .priority         = 110,
         .__match          = "ip && outport == ${lsp_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid))
}

for (&SwitchPort(.lsp = lsp@nb::Logical_Switch_Port{.__type = "localnet"},
                 .json_name = lsp_name,
                 .sw = &Switch{.ls = ls, .has_stateful_acl = true})) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_ACL(),
         .priority         = 110,
         .__match          = "ip && inport == ${lsp_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid));
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_ACL(),
         .priority         = 110,
         .__match          = "ip && outport == ${lsp_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid))
}

for (&Switch(.ls = ls, .has_stateful_acl = true)) {
    /* Ingress and Egress Pre-ACL Table (Priority 110).
     *
     * Not to do conntrack on ND and ICMP destination
     * unreachable packets. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_ACL(),
         .priority         = 110,
         .__match          = "nd || nd_rs || nd_ra || mldv1 || mldv2 || "
                             "(udp && udp.src == 546 && udp.dst == 547)",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_ACL(),
         .priority         = 110,
         .__match          = "nd || nd_rs || nd_ra || mldv1 || mldv2 || "
                             "(udp && udp.src == 546 && udp.dst == 547)",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* Ingress and Egress Pre-ACL Table (Priority 100).
     *
     * Regardless of whether the ACL is "from-lport" or "to-lport",
     * we need rules in both the ingress and egress table, because
     * the return traffic needs to be followed.
     *
     * 'REGBIT_CONNTRACK_DEFRAG' is set to let the pre-stateful table send
     * it to conntrack for tracking and defragmentation. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_ACL(),
         .priority         = 100,
         .__match          = "ip",
         .actions          = "${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_ACL(),
         .priority         = 100,
         .__match          = "ip",
         .actions          = "${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
         .external_ids     = map_empty())
}

/* Pre-LB */
for (&Switch(.ls = ls)) {
    /* Do not send ND packets to conntrack */
    var __match = "nd || nd_rs || nd_ra || mldv1 || mldv2" in {
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_IN_PRE_LB(),
             .priority         = 110,
             .__match          = __match,
             .actions          = "next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_OUT_PRE_LB(),
             .priority         = 110,
             .__match          = __match,
             .actions          = "next;",
             .external_ids     = map_empty())
    };

    /* Do not send service monitor packets to conntrack. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_LB(),
         .priority         = 110,
         .__match          = "eth.dst == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_LB(),
         .priority         = 110,
         .__match          = "eth.src == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* Allow all packets to go to next tables by default. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_LB(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_LB(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

for (&SwitchPort(.lsp = lsp, .json_name = lsp_name, .sw = &Switch{.ls = ls}))
if (lsp.__type == "router" or lsp.__type == "localnet") {
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_LB(),
         .priority         = 110,
         .__match          = "ip && inport == ${lsp_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid));
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_LB(),
         .priority         = 110,
         .__match          = "ip && outport == ${lsp_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid))
}

relation HasEventElbMeter(has_meter: bool)

HasEventElbMeter(true) :-
    nb::Meter(.name = "event-elb").

HasEventElbMeter(false) :-
    Unit(),
    not nb::Meter(.name = "event-elb").

/* Empty LoadBalancer Controller event */
function build_empty_lb_event_flow(key: string, lb: Ref<nb::Load_Balancer>,
                                   meter: bool): Option<(string, string)> {
    (var ip, var port) = match (ip_address_and_port_from_lb_key(key)) {
        Some{(ip, port)} -> (ip, port),
        _ -> return None
    };

    var protocol = match (lb.protocol) {
        Some{"tcp"} -> "tcp",
        _ -> "udp"
    };
    var meter = match (meter) {
        true -> "event-elb",
        _ -> ""
    };
    var vip = match (port) {
        0 -> "${ip}",
        _ -> "${ip.to_bracketed_string()}:${port}"
    };

    var __match = vec_with_capacity(2);
    __match.push("${ip.ipX()}.dst == ${ip}");
    if (port != 0) {
        __match.push("${protocol}.dst == ${port}");
    };

    var action = "trigger_event("
                 "event = \"empty_lb_backends\", "
                 "meter = \"${meter}\", "
                 "vip = \"${vip}\", "
                 "protocol = \"${protocol}\", "
                 "load_balancer = \"${uuid2str(lb._uuid)}\");";

    Some{(__match.join(" && "), action)}
}

/* Contains the load balancers for which an event should be sent each time it
 * runs out of backends.
 *
 * The preferred way to do this by setting an individual Load_Balancer's
 * options:event=true.
 *
 * The deprecated way is to set nb::NB_Global options:controller_event=true,
 * which enables events for every load balancer.
 */
relation LoadBalancerEmptyEvents(lb: Ref<nb::Load_Balancer>)
LoadBalancerEmptyEvents(lb) :-
    nb::NB_Global(.options = global_options),
    var global_events = global_options.get_bool_def("controller_event", false),
    lb in &LoadBalancerRef[nb::Load_Balancer{.options = local_options}],
    var local_events = local_options.get_bool_def("event", false),
    global_events or local_events.

Flow(.logical_datapath = sw.ls._uuid,
     .stage            = s_SWITCH_IN_PRE_LB(),
     .priority         = 130,
     .__match          = __match,
     .actions          = __action,
     .external_ids     = stage_hint(lb._uuid)) :-
    SwitchLBVIP(.sw_uuid = sw_uuid, .lb = lb, .vip = vip, .backends = backends),
    LoadBalancerEmptyEvents(lb),
    not lb.options.get_bool_def("reject", false),
    sw in &Switch(.ls = nb::Logical_Switch{._uuid = sw_uuid}),
    backends == "",
    HasEventElbMeter(has_elb_meter),
    Some {(var __match, var __action)} = build_empty_lb_event_flow(
        vip, lb, has_elb_meter).

/* 'REGBIT_CONNTRACK_DEFRAG' is set to let the pre-stateful table send
 * packet to conntrack for defragmentation.
 *
 * Send all the packets to conntrack in the ingress pipeline if the
 * logical switch has a load balancer with VIP configured. Earlier
 * we used to set the REGBIT_CONNTRACK_DEFRAG flag in the ingress pipeline
 * if the IP destination matches the VIP. But this causes few issues when
 * a logical switch has no ACLs configured with allow-related.
 * To understand the issue, lets a take a TCP load balancer -
 * 10.0.0.10:80=10.0.0.3:80.
 * If a logical port - p1 with IP - 10.0.0.5 opens a TCP connection with
 * the VIP - 10.0.0.10, then the packet in the ingress pipeline of 'p1'
 * is sent to the p1's conntrack zone id and the packet is load balanced
 * to the backend - 10.0.0.3. For the reply packet from the backend lport,
 * it is not sent to the conntrack of backend lport's zone id. This is fine
 * as long as the packet is valid. Suppose the backend lport sends an
 *  invalid TCP packet (like incorrect sequence number), the packet gets
 * delivered to the lport 'p1' without unDNATing the packet to the
 * VIP - 10.0.0.10. And this causes the connection to be reset by the
 * lport p1's VIF.
 *
 * We can't fix this issue by adding a logical flow to drop ct.inv packets
 * in the egress pipeline since it will drop all other connections not
 * destined to the load balancers.
 *
 * To fix this issue, we send all the packets to the conntrack in the
 * ingress pipeline if a load balancer is configured. We can now
 * add a lflow to drop ct.inv packets.
 */
for (sw in &Switch(.has_lb_vip = true)) {
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_IN_PRE_LB(),
         .priority         = 100,
         .__match          = "ip",
         .actions          = "${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_LB(),
         .priority         = 100,
         .__match          = "ip",
         .actions          = "${rEGBIT_CONNTRACK_DEFRAG()} = 1; next;",
         .external_ids     = map_empty())
}

/* Pre-stateful */
for (&Switch(.ls = ls)) {
    /* Ingress and Egress pre-stateful Table (Priority 0): Packets are
     * allowed by default. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_STATEFUL(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_STATEFUL(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* If REGBIT_CONNTRACK_DEFRAG is set as 1, then the packets should be
     * sent to conntrack for tracking and defragmentation. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PRE_STATEFUL(),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_DEFRAG()} == 1",
         .actions          = "ct_next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PRE_STATEFUL(),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_DEFRAG()} == 1",
         .actions          = "ct_next;",
         .external_ids     = map_empty())
}

function acl_log_meter_name(meter_name: string, acl_uuid: uuid): string =
{
    meter_name ++ "__" ++ uuid2str(acl_uuid)
}

function build_acl_log(acl: nb::ACL, fair_meter: bool): string =
{
    if (not acl.log) {
        ""
    } else {
        var strs = vec_empty();
        match (acl.name) {
            None -> (),
            Some{name} -> strs.push("name=${json_string_escape(name)}")
        };
        /* If a severity level isn't specified, default to "info". */
        match (acl.severity) {
            None -> strs.push("severity=info"),
            Some{severity} -> strs.push("severity=${severity}")
        };
        match (acl.action) {
            "drop" -> {
                strs.push("verdict=drop")
            },
            "reject" -> {
                strs.push("verdict=reject")
            },
            "allow" -> {
                strs.push("verdict=allow")
            },
            "allow-related" -> {
                strs.push("verdict=allow")
            },
            _ -> ()
        };
        match (acl.meter) {
            Some{meter} -> {
                var name = match (fair_meter) {
                    true -> acl_log_meter_name(meter, acl._uuid),
                    false -> meter
                };
                strs.push("meter=${json_string_escape(name)}")
            },
            None -> ()
        };
        "log(${strs.join(\", \")}); "
    }
}

/* Due to various hard-coded priorities need to implement ACLs, the
 * northbound database supports a smaller range of ACL priorities than
 * are available to logical flows.  This value is added to an ACL
 * priority to determine the ACL's logical flow priority. */
function oVN_ACL_PRI_OFFSET(): integer = 1000

/* Intermediate relation that stores reject ACLs.
 * The following rules generate logical flows for these ACLs.
 */
relation Reject(
    lsuuid: uuid,
    pipeline: Pipeline,
    stage: Stage,
    acl: nb::ACL,
    fair_meter: bool,
    extra_match: string,
    extra_actions: string)

/* build_reject_acl_rules() */
function next_to_stage(stage: Stage): string {
    var pipeline = match (stage.pipeline) {
        Ingress -> "ingress",
        Egress -> "egress"
    };
    "next(pipeline=${pipeline},table=${stage.table_id})"
}
for (Reject(lsuuid, pipeline, stage, acl, fair_meter, extra_match_, extra_actions_)) {
    var extra_match = match (extra_match_) {
        "" -> "",
        s -> "(${s}) && "
    } in
    var extra_actions = match (extra_actions_) {
        "" -> "",
        s -> "${s} "
    } in
    var next_stage = match (pipeline) {
        Ingress  -> s_SWITCH_OUT_QOS_MARK(),
        Egress -> s_SWITCH_IN_L2_LKUP()
    } in
    var acl_log = build_acl_log(acl, fair_meter) in
    var __match = extra_match ++ acl.__match in
    var actions = acl_log ++ extra_actions ++ "reg0 = 0; "
                  "reject { "
                  "/* eth.dst <-> eth.src; ip.dst <-> ip.src; is implicit. */ "
                  "outport <-> inport; ${next_to_stage(next_stage)}; };" in
    Flow(.logical_datapath = lsuuid,
         .stage            = stage,
         .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
         .__match          = __match,
         .actions          = actions,
         .external_ids     = stage_hint(acl._uuid))
}

/* build_acls */
for (sw in &Switch(.ls = ls))
var has_stateful = sw.has_stateful_acl or sw.has_lb_vip in
{
    /* Ingress and Egress ACL Table (Priority 0): Packets are allowed by
     * default.  A related rule at priority 1 is added below if there
     * are any stateful ACLs in this datapath. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_ACL(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_ACL(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    if (has_stateful) {
        /* Ingress and Egress ACL Table (Priority 1).
         *
         * By default, traffic is allowed.  This is partially handled by
         * the Priority 0 ACL flows added earlier, but we also need to
         * commit IP flows.  This is because, while the initiater's
         * direction may not have any stateful rules, the server's may
         * and then its return traffic would not have an associated
         * conntrack entry and would return "+invalid".
         *
         * We use "ct_commit" for a connection that is not already known
         * by the connection tracker.  Once a connection is committed,
         * subsequent packets will hit the flow at priority 0 that just
         * uses "next;"
         *
         * We also check for established connections that have ct_label.blocked
         * set on them.  That's a connection that was disallowed, but is
         * now allowed by policy again since it hit this default-allow flow.
         * We need to set ct_label.blocked=0 to let the connection continue,
         * which will be done by ct_commit() in the "stateful" stage.
         * Subsequent packets will hit the flow at priority 0 that just
         * uses "next;". */
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_IN_ACL(),
             .priority         = 1,
             .__match          = "ip && (!ct.est || (ct.est && ct_label.blocked == 1))",
             .actions          = "${rEGBIT_CONNTRACK_COMMIT()} = 1; next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_OUT_ACL(),
             .priority         = 1,
             .__match          = "ip && (!ct.est || (ct.est && ct_label.blocked == 1))",
             .actions          = "${rEGBIT_CONNTRACK_COMMIT()} = 1; next;",
             .external_ids     = map_empty());

        /* Ingress and Egress ACL Table (Priority 65535).
         *
         * Always drop traffic that's in an invalid state.  Also drop
         * reply direction packets for connections that have been marked
         * for deletion (bit 0 of ct_label is set).
         *
         * This is enforced at a higher priority than ACLs can be defined. */
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_IN_ACL(),
             .priority         = 65535,
             .__match          = "ct.inv || (ct.est && ct.rpl && ct_label.blocked == 1)",
             .actions          = "drop;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_OUT_ACL(),
             .priority         = 65535,
             .__match          = "ct.inv || (ct.est && ct.rpl && ct_label.blocked == 1)",
             .actions          = "drop;",
             .external_ids     = map_empty());

        /* Ingress and Egress ACL Table (Priority 65535).
         *
         * Allow reply traffic that is part of an established
         * conntrack entry that has not been marked for deletion
         * (bit 0 of ct_label).  We only match traffic in the
         * reply direction because we want traffic in the request
         * direction to hit the currently defined policy from ACLs.
         *
         * This is enforced at a higher priority than ACLs can be defined. */
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_IN_ACL(),
             .priority         = 65535,
             .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv "
                                 "&& ct.rpl && ct_label.blocked == 0",
             .actions          = "next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_OUT_ACL(),
             .priority         = 65535,
             .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv "
                                 "&& ct.rpl && ct_label.blocked == 0",
             .actions          = "next;",
             .external_ids     = map_empty());

        /* Ingress and Egress ACL Table (Priority 65535).
         *
         * Allow traffic that is related to an existing conntrack entry that
         * has not been marked for deletion (bit 0 of ct_label).
         *
         * This is enforced at a higher priority than ACLs can be defined.
         *
         * NOTE: This does not support related data sessions (eg,
         * a dynamically negotiated FTP data channel), but will allow
         * related traffic such as an ICMP Port Unreachable through
         * that's generated from a non-listening UDP port.  */
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_IN_ACL(),
             .priority         = 65535,
             .__match          = "!ct.est && ct.rel && !ct.new && !ct.inv "
                                 "&& ct_label.blocked == 0",
             .actions          = "next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_OUT_ACL(),
             .priority         = 65535,
             .__match          = "!ct.est && ct.rel && !ct.new && !ct.inv "
                                 "&& ct_label.blocked == 0",
             .actions          = "next;",
             .external_ids     = map_empty());

        /* Ingress and Egress ACL Table (Priority 65535).
         *
         * Not to do conntrack on ND packets. */
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_IN_ACL(),
             .priority         = 65535,
             .__match          = "nd || nd_ra || nd_rs || mldv1 || mldv2",
             .actions          = "next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_OUT_ACL(),
             .priority         = 65535,
             .__match          = "nd || nd_ra || nd_rs || mldv1 || mldv2",
             .actions          = "next;",
             .external_ids     = map_empty())
    };

    /* Add a 34000 priority flow to advance the DNS reply from ovn-controller,
     * if the CMS has configured DNS records for the datapath.
     */
    if (sw.has_dns_records) {
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_OUT_ACL(),
             .priority         = 34000,
             .__match          = "udp.src == 53",
             .actions          = if has_stateful "ct_commit; next;" else "next;",
             .external_ids     = map_empty())
    };

    /* Add a 34000 priority flow to advance the service monitor reply
     * packets to skip applying ingress ACLs. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_ACL(),
         .priority         = 34000,
         .__match          = "eth.dst == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_ACL(),
         .priority         = 34000,
         .__match          = "eth.src == $svc_monitor_mac",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* This stage builds hints for the IN/OUT_ACL stage. Based on various
 * combinations of ct flags packets may hit only a subset of the logical
 * flows in the IN/OUT_ACL stage.
 *
 * Populating ACL hints first and storing them in registers simplifies
 * the logical flow match expressions in the IN/OUT_ACL stage and
 * generates less openflows.
 *
 * Certain combinations of ct flags might be valid matches for multiple
 * types of ACL logical flows (e.g., allow/drop). In such cases hints
 * corresponding to all potential matches are set.
 */
input relation AclHintStages[Stage]
AclHintStages[s_SWITCH_IN_ACL_HINT()].
AclHintStages[s_SWITCH_OUT_ACL_HINT()].
for (sw in &Switch(.ls = ls)) {
    for (AclHintStages[stage]) {
        /* In any case, advance to the next stage. */
        Flow(ls._uuid, stage, 0, "1", "next;", map_empty())
    };

    for (AclHintStages[stage])
    if (sw.has_stateful_acl or sw.has_lb_vip) {
        /* New, not already established connections, may hit either allow
         * or drop ACLs. For allow ACLs, the connection must also be committed
         * to conntrack so we set REGBIT_ACL_HINT_ALLOW_NEW.
         */
        Flow(ls._uuid, stage, 7, "ct.new && !ct.est",
             "${rEGBIT_ACL_HINT_ALLOW_NEW()} = 1; "
             "${rEGBIT_ACL_HINT_DROP()} = 1; "
             "next;", map_empty());

        /* Already established connections in the "request" direction that
         * are already marked as "blocked" may hit either:
         * - allow ACLs for connections that were previously allowed by a
         *   policy that was deleted and is being readded now. In this case
         *   the connection should be recommitted so we set
         *   REGBIT_ACL_HINT_ALLOW_NEW.
         * - drop ACLs.
         */
        Flow(ls._uuid, stage, 6, "!ct.new && ct.est && !ct.rpl && ct_label.blocked == 1",
             "${rEGBIT_ACL_HINT_ALLOW_NEW()} = 1; "
             "${rEGBIT_ACL_HINT_DROP()} = 1; "
             "next;", map_empty());

        /* Not tracked traffic can either be allowed or dropped. */
        Flow(ls._uuid, stage, 5, "!ct.trk",
             "${rEGBIT_ACL_HINT_ALLOW()} = 1; "
             "${rEGBIT_ACL_HINT_DROP()} = 1; "
             "next;", map_empty());

        /* Already established connections in the "request" direction may hit
         * either:
         * - allow ACLs in which case the traffic should be allowed so we set
         *   REGBIT_ACL_HINT_ALLOW.
         * - drop ACLs in which case the traffic should be blocked and the
         *   connection must be committed with ct_label.blocked set so we set
         *   REGBIT_ACL_HINT_BLOCK.
         */
        Flow(ls._uuid, stage, 4, "!ct.new && ct.est && !ct.rpl && ct_label.blocked == 0",
             "${rEGBIT_ACL_HINT_ALLOW()} = 1; "
             "${rEGBIT_ACL_HINT_BLOCK()} = 1; "
             "next;", map_empty());

        /* Not established or established and already blocked connections may
         * hit drop ACLs.
         */
        Flow(ls._uuid, stage, 3, "!ct.est",
             "${rEGBIT_ACL_HINT_DROP()} = 1; "
             "next;", map_empty());
        Flow(ls._uuid, stage, 2, "ct.est && ct_label.blocked == 1",
             "${rEGBIT_ACL_HINT_DROP()} = 1; "
             "next;", map_empty());

        /* Established connections that were previously allowed might hit
         * drop ACLs in which case the connection must be committed with
         * ct_label.blocked set.
         */
        Flow(ls._uuid, stage, 1, "ct.est && ct_label.blocked == 0",
             "${rEGBIT_ACL_HINT_BLOCK()} = 1; "
             "next;", map_empty())
    }
}

/* Ingress or Egress ACL Table (Various priorities). */
for (&SwitchACL(.sw = sw@&Switch{.ls = ls}, .acl = &acl, .has_fair_meter = fair_meter)) {
    /* consider_acl */
    var has_stateful = sw.has_stateful_acl or sw.has_lb_vip in
    var ingress = acl.direction == "from-lport" in
    var stage = if (ingress) { s_SWITCH_IN_ACL() } else { s_SWITCH_OUT_ACL() } in
    var pipeline = if ingress Ingress else Egress in
    var stage_hint = stage_hint(acl._uuid) in
    var acl_log = build_acl_log(acl, fair_meter) in
    if (acl.action == "allow" or acl.action == "allow-related") {
        /* If there are any stateful flows, we must even commit "allow"
         * actions.  This is because, while the initiater's
         * direction may not have any stateful rules, the server's
         * may and then its return traffic would not have an
         * associated conntrack entry and would return "+invalid". */
        if (not has_stateful) {
            Flow(.logical_datapath = ls._uuid,
                 .stage            = stage,
                 .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                 .__match          = acl.__match,
                 .actions          = "${acl_log}next;",
                 .external_ids     = stage_hint)
        } else {
            /* Commit the connection tracking entry if it's a new
             * connection that matches this ACL.  After this commit,
             * the reply traffic is allowed by a flow we create at
             * priority 65535, defined earlier.
             *
             * It's also possible that a known connection was marked for
             * deletion after a policy was deleted, but the policy was
             * re-added while that connection is still known.  We catch
             * that case here and un-set ct_label.blocked (which will be done
             * by ct_commit in the "stateful" stage) to indicate that the
             * connection should be allowed to resume.
             */
            Flow(.logical_datapath = ls._uuid,
                 .stage            = stage,
                 .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                 .__match          = "${rEGBIT_ACL_HINT_ALLOW_NEW()} == 1 && (${acl.__match})",
                 .actions          = "${rEGBIT_CONNTRACK_COMMIT()} = 1; ${acl_log}next;",
                 .external_ids     = stage_hint);

            /* Match on traffic in the request direction for an established
             * connection tracking entry that has not been marked for
             * deletion.  There is no need to commit here, so we can just
             * proceed to the next table. We use this to ensure that this
             * connection is still allowed by the currently defined
             * policy. Match untracked packets too. */
            Flow(.logical_datapath = ls._uuid,
                 .stage            = stage,
                 .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                 .__match          = "${rEGBIT_ACL_HINT_ALLOW()} == 1 && (${acl.__match})",
                 .actions          = "${acl_log}next;",
                 .external_ids     = stage_hint)
        }
    } else if (acl.action == "drop" or acl.action == "reject") {
        /* The implementation of "drop" differs if stateful ACLs are in
         * use for this datapath.  In that case, the actions differ
         * depending on whether the connection was previously committed
         * to the connection tracker with ct_commit. */
        if (has_stateful) {
            /* If the packet is not tracked or not part of an established
             * connection, then we can simply reject/drop it. */
            var __match = "${rEGBIT_ACL_HINT_DROP()} == 1" in
            if (acl.action == "reject") {
                Reject(ls._uuid, pipeline, stage, acl, fair_meter, __match, "")
            } else {
                Flow(.logical_datapath = ls._uuid,
                     .stage            = stage,
                     .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                     .__match          = __match ++ " && (${acl.__match})",
                     .actions          = "${acl_log}/* drop */",
                     .external_ids     = stage_hint)
            };
            /* For an existing connection without ct_label set, we've
             * encountered a policy change. ACLs previously allowed
             * this connection and we committed the connection tracking
             * entry.  Current policy says that we should drop this
             * connection.  First, we set bit 0 of ct_label to indicate
             * that this connection is set for deletion.  By not
             * specifying "next;", we implicitly drop the packet after
             * updating conntrack state.  We would normally defer
             * ct_commit() to the "stateful" stage, but since we're
             * rejecting/dropping the packet, we go ahead and do it here.
             */
            var __match = "${rEGBIT_ACL_HINT_BLOCK()} == 1" in
            var actions = "ct_commit { ct_label.blocked = 1; }; " in
            if (acl.action == "reject") {
                Reject(ls._uuid, pipeline, stage, acl, fair_meter, __match, actions)
            } else {
                Flow(.logical_datapath = ls._uuid,
                     .stage            = stage,
                     .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                     .__match          = __match ++ " && (${acl.__match})",
                     .actions          = "${actions}${acl_log}/* drop */",
                     .external_ids     = stage_hint)
            }
        } else {
            /* There are no stateful ACLs in use on this datapath,
             * so a "reject/drop" ACL is simply the "reject/drop"
             * logical flow action in all cases. */
            if (acl.action == "reject") {
                Reject(ls._uuid, pipeline, stage, acl, fair_meter, "", "")
            } else {
                Flow(.logical_datapath = ls._uuid,
                     .stage            = stage,
                     .priority         = acl.priority + oVN_ACL_PRI_OFFSET(),
                     .__match          = acl.__match,
                     .actions          = "${acl_log}/* drop */",
                     .external_ids     = stage_hint)
            }
        }
    }
}

/* Add 34000 priority flow to allow DHCP reply from ovn-controller to all
 * logical ports of the datapath if the CMS has configured DHCPv4 options.
 * */
for (SwitchPortDHCPv4Options(.port = &SwitchPort{.lsp = lsp, .sw = &sw},
                             .dhcpv4_options = dhcpv4_options@&nb::DHCP_Options{.options = options})
     if lsp.__type != "external") {
    (Some{var server_id}, Some{var server_mac}, Some{var lease_time}) =
        (options.get("server_id"), options.get("server_mac"), options.get("lease_time")) in
    var has_stateful = sw.has_stateful_acl or sw.has_lb_vip in
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_OUT_ACL(),
         .priority         = 34000,
         .__match          = "outport == ${json_string_escape(lsp.name)} "
                             "&& eth.src == ${server_mac} "
                             "&& ip4.src == ${server_id} && udp && udp.src == 67 "
                             "&& udp.dst == 68",
         .actions          = if (has_stateful) "ct_commit; next;" else "next;",
         .external_ids     = stage_hint(dhcpv4_options._uuid))
}

for (SwitchPortDHCPv6Options(.port = &SwitchPort{.lsp = lsp, .sw = &sw},
                             .dhcpv6_options = dhcpv6_options@&nb::DHCP_Options{.options=options} )
     if lsp.__type != "external") {
    Some{var server_mac} = options.get("server_id") in
    Some{var ea} = eth_addr_from_string(server_mac) in
    var server_ip = ea.to_ipv6_lla() in
    /* Get the link local IP of the DHCPv6 server from the
     * server MAC. */
    var has_stateful = sw.has_stateful_acl or sw.has_lb_vip in
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_OUT_ACL(),
         .priority         = 34000,
         .__match          = "outport == ${json_string_escape(lsp.name)} "
                             "&& eth.src == ${server_mac} "
                             "&& ip6.src == ${server_ip} && udp && udp.src == 547 "
                             "&& udp.dst == 546",
         .actions          = if (has_stateful) "ct_commit; next;" else "next;",
         .external_ids     = stage_hint(dhcpv6_options._uuid))
}

relation QoSAction(qos: uuid, key_action: string, value_action: integer)

QoSAction(qos, k, v) :-
    nb::QoS(._uuid = qos, .action = actions),
    var action = FlatMap(actions),
    (var k, var v) = action.

/* QoS rules */
for (&Switch(.ls = ls)) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_QOS_MARK(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_QOS_MARK(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_QOS_METER(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_QOS_METER(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

for (SwitchQoS(.sw = &sw, .qos = &qos)) {
    var ingress = if (qos.direction == "from-lport") true else false in
    var pipeline = if ingress "ingress" else "egress" in {
        var stage = if (ingress) { s_SWITCH_IN_QOS_MARK() } else { s_SWITCH_OUT_QOS_MARK() } in
        /* FIXME: Can value_action be negative? */
        for (QoSAction(qos._uuid, key_action, value_action)) {
            if (key_action == "dscp") {
                Flow(.logical_datapath = sw.ls._uuid,
                     .stage            = stage,
                     .priority         = qos.priority,
                     .__match          = qos.__match,
                     .actions          = "ip.dscp = ${value_action}; next;",
                     .external_ids     = stage_hint(qos._uuid))
            }
        };

        (var burst, var rate) = {
            var rate = 0;
            var burst = 0;
            for (bw in qos.bandwidth) {
                /* FIXME: Can value_bandwidth be negative? */
                (var key_bandwidth, var value_bandwidth) = bw;
                if (key_bandwidth == "rate") {
                    rate = value_bandwidth
                } else if (key_bandwidth == "burst") {
                    burst = value_bandwidth
                } else ()
            };
            (burst, rate)
        } in
        if (rate != 0) {
            var stage = if (ingress) { s_SWITCH_IN_QOS_METER() } else { s_SWITCH_OUT_QOS_METER() } in
            var meter_action = if (burst != 0) {
                    "set_meter(${rate}, ${burst}); next;"
                } else {
                    "set_meter(${rate}); next;"
                } in
            /* Ingress and Egress QoS Meter Table.
             *
             * We limit the bandwidth of this flow by adding a meter table.
             */
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = stage,
                 .priority         = qos.priority,
                 .__match          = qos.__match,
                 .actions          = meter_action,
                 .external_ids     = stage_hint(qos._uuid))
        }
    }
}

/* LB rules */
for (&Switch(.ls = ls, .has_lb_vip = has_lb_vip)) {
    /* Ingress and Egress LB Table (Priority 0): Packets are allowed by
     * default.  */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_LB(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_LB(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    if (not ls.load_balancer.is_empty()) {
        for (&SwitchPort(.lsp = lsp@nb::Logical_Switch_Port{.__type = "router"},
                         .json_name = lsp_name,
                         .sw = &Switch{.ls = ls})) {
            Flow(.logical_datapath = ls._uuid,
                 .stage            = s_SWITCH_IN_LB(),
                 .priority         = 65535,
                 .__match          = "ip && inport == ${lsp_name}",
                 .actions          = "next;",
                 .external_ids     = stage_hint(lsp._uuid));
            Flow(.logical_datapath = ls._uuid,
                 .stage            = s_SWITCH_OUT_LB(),
                 .priority         = 65535,
                 .__match          = "ip && outport == ${lsp_name}",
                 .actions          = "next;",
                 .external_ids     = stage_hint(lsp._uuid))
        }
    };

    if (has_lb_vip) {
        /* Ingress and Egress LB Table (Priority 65534).
         *
         * Send established traffic through conntrack for just NAT. */
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_IN_LB(),
             .priority         = 65534,
             .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv && ct_label.natted == 1",
             .actions          = "${rEGBIT_CONNTRACK_NAT()} = 1; next;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_OUT_LB(),
             .priority         = 65534,
             .__match          = "ct.est && !ct.rel && !ct.new && !ct.inv && ct_label.natted == 1",
             .actions          = "${rEGBIT_CONNTRACK_NAT()} = 1; next;",
             .external_ids     = map_empty())
    }
}

/* stateful rules */
relation LbProtocol[string]
LbProtocol["tcp"].
LbProtocol["udp"].
LbProtocol["sctp"].
for (&Switch(.ls = ls)) {
    /* Ingress and Egress stateful Table (Priority 0): Packets are
     * allowed by default. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_STATEFUL(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_STATEFUL(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* If REGBIT_CONNTRACK_COMMIT is set as 1, then the packets should be
     * committed to conntrack. We always set ct_label.blocked to 0 here as
     * any packet that makes it this far is part of a connection we
     * want to allow to continue. */
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_STATEFUL(),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_COMMIT()} == 1",
         .actions          = "ct_commit { ct_label.blocked = 0; }; next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_STATEFUL(),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_COMMIT()} == 1",
         .actions          = "ct_commit { ct_label.blocked = 0; }; next;",
         .external_ids     = map_empty());

    /* If REGBIT_CONNTRACK_NAT is set as 1, then packets should just be sent
     * through nat (without committing).
     *
     * REGBIT_CONNTRACK_COMMIT is set for new connections and
     * REGBIT_CONNTRACK_NAT is set for established connections. So they
     * don't overlap.
     *
     * In the ingress pipeline, also store the original destination IP and
     * transport port to be used when detecting hairpin packets.
     */
    for (LbProtocol[protocol]) {
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_IN_STATEFUL(),
             .priority         = 100,
             .__match          = "${rEGBIT_CONNTRACK_NAT()} == 1 && ip4 && ${protocol}",
             .actions          = "${rEG_ORIG_DIP_IPV4()} = ip4.dst; "
                                 "${rEG_ORIG_TP_DPORT()} = ${protocol}.dst; ct_lb;",
             .external_ids     = map_empty());
        Flow(.logical_datapath = ls._uuid,
             .stage            = s_SWITCH_IN_STATEFUL(),
             .priority         = 100,
             .__match          = "${rEGBIT_CONNTRACK_NAT()} == 1 && ip6 && ${protocol}",
             .actions          = "${rEG_ORIG_DIP_IPV6()} = ip6.dst; "
                                 "${rEG_ORIG_TP_DPORT()} = ${protocol}.dst; ct_lb;",
             .external_ids     = map_empty())
    };

    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_STATEFUL(),
         .priority         = 100,
         .__match          = "${rEGBIT_CONNTRACK_NAT()} == 1",
         .actions          = "ct_lb;",
         .external_ids     = map_empty())
}

/* Load balancing rules for new connections get committed to conntrack
 * table.  So even if REGBIT_CONNTRACK_COMMIT is set in a previous table
 * a higher priority rule for load balancing below also commits the
 * connection, so it is okay if we do not hit the above match on
 * REGBIT_CONNTRACK_COMMIT. */
function get_match_for_lb_key(ip_address: v46_ip,
                              port: bit<16>,
                              protocol: Option<string>,
                              redundancy: bool): string = {
    var port_match = if (port != 0) {
        var proto = if (protocol == Some{"udp"}) {
            "udp"
        } else {
            "tcp"
        };
        if (redundancy) { " && ${proto}" } else { "" } ++
        " && ${proto}.dst == ${port}"
    } else {
        ""
    };

    var ip_match = match (ip_address) {
        IPv4{ipv4} -> "ip4.dst == ${ipv4}",
        IPv6{ipv6} -> "ip6.dst == ${ipv6}"
    };

    if (redundancy) { "ip && " } else { "" } ++ ip_match ++ port_match
}
/* New connections in Ingress table. */

function ct_lb(backends: string,
               selection_fields: Set<string>, protocol: Option<string>): string {
    var args = vec_with_capacity(2);
    args.push("backends=${backends}");

    if (not selection_fields.is_empty()) {
        var hash_fields = vec_with_capacity(selection_fields.size());
        for (sf in selection_fields) {
            var hf = match ((sf, protocol)) {
                ("tp_src", Some{p}) -> "${p}_src",
                ("tp_dst", Some{p}) -> "${p}_dst",
                _ -> sf
            };
            hash_fields.push(hf);
        };
        args.push("hash_fields=" ++ json_string_escape(hash_fields.join(",")));
    };

    "ct_lb(" ++ args.join("; ") ++ ");"
}
function build_lb_vip_actions(lbvip: Ref<LBVIPWithStatus>,
                              stage: Stage,
                              actions0: string): string {
    var up_backends = set_empty();
    for (pair in lbvip.backends) {
        (var backend, var up) = pair;
        if (up) {
            up_backends.insert("${backend.ip.to_bracketed_string()}:${backend.port}")
        }
    };

    if (up_backends.is_empty()) {
        if (lbvip.lb.options.get_bool_def("reject", false)) {
            return "reg0 = 0; reject { outport <-> inport; ${next_to_stage(stage)};};"
        } else if (lbvip.health_check.is_some()) {
            return "drop;"
        } // else fall through
    };

    var actions = ct_lb(up_backends.to_vec().join(","), lbvip.lb.selection_fields,
                        lbvip.lb.protocol);
    actions0 ++ actions
}
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = s_SWITCH_IN_STATEFUL(),
     .priority         = priority,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(lb._uuid)) :-
    sw in &Switch(),
    LBVIPWithStatus[lbvip@&LBVIPWithStatus{.lb = lb}],
    sw.ls.load_balancer.contains(lb._uuid),
    var priority = if (lbvip.vip_port != 0) { 120 } else { 110 },
    var actions = {
        /* Store the original destination IP to be used when generating
         * hairpin flows.
         */
        var actions0 = match (lbvip.vip_addr) {
            IPv4{ipv4} -> "${rEG_ORIG_DIP_IPV4()} = ${ipv4}; ",
            IPv6{ipv6} -> "${rEG_ORIG_DIP_IPV6()} = ${ipv6}; "
        };

        /* Store the original destination port to be used when generating
         * hairpin flows.
         */
        var actions1 = if (lbvip.vip_port != 0) {
            "${rEG_ORIG_TP_DPORT()} = ${lbvip.vip_port}; "
        } else {
            ""
        };

        build_lb_vip_actions(lbvip, s_SWITCH_OUT_QOS_MARK(), actions0 ++ actions1)
    },
    var __match = "ct.new && " ++ get_match_for_lb_key(lbvip.vip_addr, lbvip.vip_port, lb.protocol, false).

/* Ingress Pre-Hairpin/Nat-Hairpin/Hairpin tabled (Priority 0).
 * Packets that don't need hairpinning should continue processing.
 */
Flow(.logical_datapath = ls_uuid,
     .stage = stage,
     .priority = 0,
     .__match = "1",
     .actions = "next;",
     .external_ids = map_empty()) :-
     &Switch(.ls = nb::Logical_Switch{._uuid = ls_uuid}),
     var stages = [s_SWITCH_IN_PRE_HAIRPIN(),
                   s_SWITCH_IN_NAT_HAIRPIN(),
                   s_SWITCH_IN_HAIRPIN()],
     var stage = FlatMap(stages).
for (&Switch(.ls = nb::Logical_Switch{._uuid = ls_uuid}, .has_lb_vip = true)) {
    /* Check if the packet needs to be hairpinned.
     * Set REGBIT_HAIRPIN in the original direction and
     * REGBIT_HAIRPIN_REPLY in the reply direction.
     */
    Flow(.logical_datapath = ls_uuid,
         .stage = s_SWITCH_IN_PRE_HAIRPIN(),
         .priority = 100,
         .__match = "ip && ct.trk",
         .actions = "${rEGBIT_HAIRPIN()} = chk_lb_hairpin(); "
                    "${rEGBIT_HAIRPIN_REPLY()} = chk_lb_hairpin_reply(); "
                    "next;",
         .external_ids = stage_hint(ls_uuid));

    /* If packet needs to be hairpinned, snat the src ip with the VIP
     * for new sessions. */
    Flow(.logical_datapath = ls_uuid,
         .stage = s_SWITCH_IN_NAT_HAIRPIN(),
         .priority = 100,
         .__match = "ip && ct.new && ct.trk && ${rEGBIT_HAIRPIN()} == 1",
         .actions = "ct_snat_to_vip; next;",
         .external_ids = stage_hint(ls_uuid));
     
    /* If packet needs to be hairpinned, for established sessions there
     * should already be an SNAT conntrack entry.
     */
    Flow(.logical_datapath = ls_uuid,
         .stage = s_SWITCH_IN_NAT_HAIRPIN(),
         .priority = 100,
         .__match = "ip && ct.est && ct.trk && ${rEGBIT_HAIRPIN()} == 1",
         .actions = "ct_snat;",
         .external_ids = stage_hint(ls_uuid));

    /* For the reply of hairpinned traffic, snat the src ip to the VIP. */
    Flow(.logical_datapath = ls_uuid,
         .stage = s_SWITCH_IN_NAT_HAIRPIN(),
         .priority = 90,
         .__match = "ip && ${rEGBIT_HAIRPIN_REPLY()} == 1",
         .actions = "ct_snat;",
         .external_ids = stage_hint(ls_uuid));

    /* Ingress Hairpin table.
    * - Priority 1: Packets that were SNAT-ed for hairpinning should be
    *   looped back (i.e., swap ETH addresses and send back on inport).
    */
    Flow(.logical_datapath = ls_uuid,
         .stage = s_SWITCH_IN_HAIRPIN(),
         .priority = 1,
         .__match = "(${rEGBIT_HAIRPIN()} == 1 || ${rEGBIT_HAIRPIN_REPLY()} == 1)",
         .actions = "eth.dst <-> eth.src; outport = inport; flags.loopback = 1; output;",
         .external_ids = stage_hint(ls_uuid))
}

/* Logical switch ingress table PORT_SEC_L2: ingress port security - L2 (priority 50)
                  ingress table PORT_SEC_IP: ingress port security - IP (priority 90 and 80)
                  ingress table PORT_SEC_ND: ingress port security - ND (priority 90 and 80) */
for (&SwitchPort(.lsp = lsp, .sw = &sw, .json_name = json_name, .ps_eth_addresses = ps_eth_addresses)
     if lsp.is_enabled() and lsp.__type != "external") {
     for (pbinding in sb::Out_Port_Binding(.logical_port = lsp.name)) {
        var __match = if (ps_eth_addresses.is_empty()) {
                "inport == ${json_name}"
            } else {
                "inport == ${json_name} && eth.src == {${ps_eth_addresses.join(\" \")}}"
            } in
        var actions = match (pbinding.options.get("qdisc_queue_id")) {
                None -> "next;",
                Some{id} -> "set_queue(${id}); next;"
            } in
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = s_SWITCH_IN_PORT_SEC_L2(),
             .priority         = 50,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(lsp._uuid))
    }
}

/**
* Build port security constraints on IPv4 and IPv6 src and dst fields
* and add logical flows to S_SWITCH_(IN/OUT)_PORT_SEC_IP stage.
*
* For each port security of the logical port, following
* logical flows are added
*   - If the port security has IPv4 addresses,
*     - Priority 90 flow to allow IPv4 packets for known IPv4 addresses
*
*   - If the port security has IPv6 addresses,
*     - Priority 90 flow to allow IPv6 packets for known IPv6 addresses
*
*   - If the port security has IPv4 addresses or IPv6 addresses or both
*     - Priority 80 flow to drop all IPv4 and IPv6 traffic
*/
for (SwitchPortPSAddresses(.port = &port@SwitchPort{.sw = &sw}, .ps_addrs = ps)
     if port.is_enabled() and
        (ps.ipv4_addrs.len() > 0 or ps.ipv6_addrs.len() > 0) and
        port.lsp.__type != "external")
{
    if (ps.ipv4_addrs.len() > 0) {
        var dhcp_match = "inport == ${port.json_name}"
                         " && eth.src == ${ps.ea}"
                         " && ip4.src == 0.0.0.0"
                         " && ip4.dst == 255.255.255.255"
                         " && udp.src == 68 && udp.dst == 67" in {
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = s_SWITCH_IN_PORT_SEC_IP(),
                 .priority         = 90,
                 .__match          = dhcp_match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(port.lsp._uuid))
        };
        var addrs = {
            var addrs = vec_empty();
            for (addr in ps.ipv4_addrs) {
                /* When the netmask is applied, if the host portion is
                 * non-zero, the host can only use the specified
                 * address.  If zero, the host is allowed to use any
                 * address in the subnet.
                 */
                addrs.push(addr.match_host_or_network())
            };
            addrs
        } in
        var __match =
            "inport == ${port.json_name} && eth.src == ${ps.ea} && ip4.src == {" ++
            addrs.join(", ") ++ "}" in
        {
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage         = s_SWITCH_IN_PORT_SEC_IP(),
                 .priority         = 90,
                 .__match          = __match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(port.lsp._uuid))
        }
    };
    if (ps.ipv6_addrs.len() > 0) {
        var dad_match = "inport == ${port.json_name}"
                        " && eth.src == ${ps.ea}"
                        " && ip6.src == ::"
                        " && ip6.dst == ff02::/16"
                        " && icmp6.type == {131, 135, 143}" in
        {
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = s_SWITCH_IN_PORT_SEC_IP(),
                 .priority         = 90,
                 .__match          = dad_match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(port.lsp._uuid))
        };
        var __match = "inport == ${port.json_name} && eth.src == ${ps.ea}" ++
                      build_port_security_ipv6_flow(Ingress, ps.ea, ps.ipv6_addrs) in
        {
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = s_SWITCH_IN_PORT_SEC_IP(),
                 .priority         = 90,
                 .__match          = __match,
                 .actions          = "next;",
                 .external_ids     = stage_hint(port.lsp._uuid))
        }
    };
    var __match = "inport == ${port.json_name} && eth.src == ${ps.ea} && ip" in
    {
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = s_SWITCH_IN_PORT_SEC_IP(),
             .priority         = 80,
             .__match          = __match,
             .actions          = "drop;",
             .external_ids     = stage_hint(port.lsp._uuid))
    }
}

/**
 * Build port security constraints on ARP and IPv6 ND fields
 * and add logical flows to S_SWITCH_IN_PORT_SEC_ND stage.
 *
 * For each port security of the logical port, following
 * logical flows are added
 *   - If the port security has no IP (both IPv4 and IPv6) or
 *     if it has IPv4 address(es)
 *      - Priority 90 flow to allow ARP packets for known MAC addresses
 *        in the eth.src and arp.spa fields. If the port security
 *        has IPv4 addresses, allow known IPv4 addresses in the arp.tpa field.
 *
 *   - If the port security has no IP (both IPv4 and IPv6) or
 *     if it has IPv6 address(es)
 *     - Priority 90 flow to allow IPv6 ND packets for known MAC addresses
 *       in the eth.src and nd.sll/nd.tll fields. If the port security
 *       has IPv6 addresses, allow known IPv6 addresses in the nd.target field
 *       for IPv6 Neighbor Advertisement packet.
 *
 *   - Priority 80 flow to drop ARP and IPv6 ND packets.
 */
for (SwitchPortPSAddresses(.port = &port@SwitchPort{.sw = &sw}, .ps_addrs = ps)
     if port.is_enabled() and port.lsp.__type != "external")
{
    var no_ip = ps.ipv4_addrs.is_empty() and ps.ipv6_addrs.is_empty() in
    {
        if (not ps.ipv4_addrs.is_empty() or no_ip) {
            var __match = {
                var prefix = "inport == ${port.json_name} && eth.src == ${ps.ea} && arp.sha == ${ps.ea}";
                if (not ps.ipv4_addrs.is_empty()) {
                    var spas = vec_empty();
                    for (addr in ps.ipv4_addrs) {
                        spas.push(addr.match_host_or_network())
                    };
                    prefix ++ " && arp.spa == {${spas.join(\", \")}}"
                } else {
                    prefix
                }
            } in {
                Flow(.logical_datapath = sw.ls._uuid,
                     .stage            = s_SWITCH_IN_PORT_SEC_ND(),
                     .priority         = 90,
                     .__match          = __match,
                     .actions          = "next;",
                     .external_ids     = stage_hint(port.lsp._uuid))
            }
        };
        if (not ps.ipv6_addrs.is_empty() or no_ip) {
            var __match = "inport == ${port.json_name} && eth.src == ${ps.ea}" ++
                          build_port_security_ipv6_nd_flow(ps.ea, ps.ipv6_addrs) in
            {
                Flow(.logical_datapath = sw.ls._uuid,
                     .stage            = s_SWITCH_IN_PORT_SEC_ND(),
                     .priority         = 90,
                     .__match          = __match,
                     .actions          = "next;",
                     .external_ids     = stage_hint(port.lsp._uuid))
            }
        };
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = s_SWITCH_IN_PORT_SEC_ND(),
             .priority         = 80,
             .__match          = "inport == ${port.json_name} && (arp || nd)",
             .actions          = "drop;",
             .external_ids     = stage_hint(port.lsp._uuid))
    }
}

/* Ingress table PORT_SEC_ND and PORT_SEC_IP: Port security - IP and ND, by
 * default goto next.  (priority 0)*/
for (&Switch(.ls = ls)) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PORT_SEC_ND(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_PORT_SEC_IP(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Ingress table ARP_ND_RSP: ARP/ND responder, skip requests coming from
 * localnet and vtep ports. (priority 100); see ovn-northd.8.xml for the
 * rationale. */
for (&SwitchPort(.lsp = lsp, .sw = &sw, .json_name = json_name)
     if lsp.is_enabled() and
        (lsp.__type == "localnet" or lsp.__type == "vtep"))
{
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_IN_ARP_ND_RSP(),
         .priority         = 100,
         .__match          = "inport == ${json_name}",
         .actions          = "next;",
         .external_ids     = stage_hint(lsp._uuid))
}

function lsp_is_up(lsp: nb::Logical_Switch_Port): bool = {
    lsp.up == Some{true}
}

/* Ingress table ARP_ND_RSP: ARP/ND responder, reply for known IPs.
 * (priority 50). */
/* Handle
 *  - GARPs for virtual ip which belongs to a logical port
 *    of type 'virtual' and bind that port.
 *
 *  - ARP reply from the virtual ip which belongs to a logical
 *    port of type 'virtual' and bind that port.
 * */
 Flow(.logical_datapath = sp.sw.ls._uuid,
      .stage            = s_SWITCH_IN_ARP_ND_RSP(),
      .priority         = 100,
      .__match          = "inport == ${vp.json_name} && "
                          "((arp.op == 1 && arp.spa == ${virtual_ip} && arp.tpa == ${virtual_ip}) || "
                          "(arp.op == 2 && arp.spa == ${virtual_ip}))",
      .actions          = "bind_vport(${sp.json_name}, inport); next;",
      .external_ids     = stage_hint(lsp._uuid)) :-
    sp in &SwitchPort(.lsp = lsp@nb::Logical_Switch_Port{.__type = "virtual"}),
    Some{var virtual_ip} = lsp.options.get("virtual-ip"),
    Some{var virtual_parents} = lsp.options.get("virtual-parents"),
    Some{var ip} = ip_parse(virtual_ip),
    var vparent = FlatMap(string_split(virtual_parents, ",")),
    vp in &SwitchPort(.lsp = nb::Logical_Switch_Port{.name = vparent}),
    vp.sw == sp.sw.

/*
 * Add ARP/ND reply flows if either the
 *  - port is up and it doesn't have 'unknown' address defined or
 *  - port type is router or
 *  - port type is localport
 */
for (CheckLspIsUp[check_lsp_is_up]) {
    for (SwitchPortIPv4Address(.port = &SwitchPort{.lsp = lsp, .sw = &sw, .json_name = json_name},
                               .ea = ea, .addr = addr)
         if lsp.is_enabled() and
            ((lsp_is_up(lsp) or not check_lsp_is_up)
             or lsp.__type == "router" or lsp.__type == "localport") and
            lsp.__type != "external" and lsp.__type != "virtual" and
            not lsp.addresses.contains("unknown"))
    {
        var __match = "arp.tpa == ${addr.addr} && arp.op == 1" in
        {
            var actions = "eth.dst = eth.src; "
                          "eth.src = ${ea}; "
                          "arp.op = 2; /* ARP reply */ "
                          "arp.tha = arp.sha; "
                          "arp.sha = ${ea}; "
                          "arp.tpa = arp.spa; "
                          "arp.spa = ${addr.addr}; "
                          "outport = inport; "
                          "flags.loopback = 1; "
                          "output;" in
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = s_SWITCH_IN_ARP_ND_RSP(),
                 .priority         = 50,
                 .__match          = __match,
                 .actions          = actions,
                 .external_ids     = stage_hint(lsp._uuid));

            /* Do not reply to an ARP request from the port that owns the
             * address (otherwise a DHCP client that ARPs to check for a
             * duplicate address will fail).  Instead, forward it the usual
             * way.
             *
             * (Another alternative would be to simply drop the packet.  If
             * everything is working as it is configured, then this would
             * produce equivalent results, since no one should reply to the
             * request.  But ARPing for one's own IP address is intended to
             * detect situations where the network is not working as
             * configured, so dropping the request would frustrate that
             * intent.) */
            Flow(.logical_datapath = sw.ls._uuid,
                 .stage            = s_SWITCH_IN_ARP_ND_RSP(),
                 .priority         = 100,
                 .__match          = __match ++ " && inport == ${json_name}",
                 .actions          = "next;",
                 .external_ids     = stage_hint(lsp._uuid))
        }
    }
}

/* For ND solicitations, we need to listen for both the
 * unicast IPv6 address and its all-nodes multicast address,
 * but always respond with the unicast IPv6 address. */
for (SwitchPortIPv6Address(.port = &SwitchPort{.lsp = lsp, .json_name = json_name, .sw = &sw},
                           .ea = ea, .addr = addr)
     if lsp.is_enabled() and
        (lsp_is_up(lsp) or lsp.__type == "router" or lsp.__type == "localport") and
        lsp.__type != "external" and lsp.__type != "virtual")
{
    var __match = "nd_ns && ip6.dst == {${addr.addr}, ${addr.solicited_node()}} && nd.target == ${addr.addr}" in
    var actions = "${if (lsp.__type == \"router\") \"nd_na_router\" else \"nd_na\"} { "
                  "eth.src = ${ea}; "
                  "ip6.src = ${addr.addr}; "
                  "nd.target = ${addr.addr}; "
                  "nd.tll = ${ea}; "
                  "outport = inport; "
                  "flags.loopback = 1; "
                  "output; "
                  "};" in
    {
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = s_SWITCH_IN_ARP_ND_RSP(),
             .priority         = 50,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(lsp._uuid));

        /* Do not reply to a solicitation from the port that owns the
         * address (otherwise DAD detection will fail). */
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = s_SWITCH_IN_ARP_ND_RSP(),
             .priority         = 100,
             .__match          = __match ++ " && inport == ${json_name}",
             .actions          = "next;",
             .external_ids     = stage_hint(lsp._uuid))
    }
}

/* Ingress table ARP_ND_RSP: ARP/ND responder, by default goto next.
 * (priority 0)*/
for (ls in nb::Logical_Switch) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_ARP_ND_RSP(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Ingress table ARP_ND_RSP: ARP/ND responder for service monitor source ip.
 * (priority 110)*/
Flow(.logical_datapath = sp.sw.ls._uuid,
     .stage            = s_SWITCH_IN_ARP_ND_RSP(),
     .priority         = 110,
     .__match          = "arp.tpa == ${svc_mon_src_ip} && arp.op == 1",
     .actions          = "eth.dst = eth.src; "
                         "eth.src = ${svc_monitor_mac}; "
                         "arp.op = 2; /* ARP reply */ "
                         "arp.tha = arp.sha; "
                         "arp.sha = ${svc_monitor_mac}; "
                         "arp.tpa = arp.spa; "
                         "arp.spa = ${svc_mon_src_ip}; "
                         "outport = inport; "
                         "flags.loopback = 1; "
                         "output;",
     .external_ids     = stage_hint(lbvip.lb._uuid)) :-
    LBVIP[lbvip],
    var lbvipbackend = FlatMap(lbvip.backends),
    Some{var svc_monitor} = lbvipbackend.svc_monitor,
    sp in &SwitchPort(
        .lsp = nb::Logical_Switch_Port{.name = svc_monitor.port_name}),
    var svc_mon_src_ip = svc_monitor.src_ip,
    SvcMonitorMac(svc_monitor_mac).

function build_dhcpv4_action(
    lsp_json_key: string,
    dhcpv4_options: nb::DHCP_Options,
    offer_ip: in_addr) : Option<(string, string, string)> =
{
    match (ip_parse_masked(dhcpv4_options.cidr)) {
        Left{err} -> {
            /* cidr defined is invalid */
            None
        },
        Right{(var host_ip, var mask)} -> {
            if (not (offer_ip, host_ip).same_network(mask)) {
               /* the offer ip of the logical port doesn't belong to the cidr
                * defined in the DHCPv4 options.
                */
                None
            } else {
                match ((dhcpv4_options.options.get("server_id"),
                        dhcpv4_options.options.get("server_mac"),
                        dhcpv4_options.options.get("lease_time")))
                {
                    (Some{var server_ip}, Some{var server_mac}, Some{var lease_time}) -> {
                        var options_map = dhcpv4_options.options;

                        /* server_mac is not DHCPv4 option, delete it from the smap. */
                        options_map.remove("server_mac");
                        options_map.insert("netmask", "${mask}");

                        /* We're not using SMAP_FOR_EACH because we want a consistent order of the
                         * options on different architectures (big or little endian, SSE4.2) */
                        var options = vec_empty();
                        for (node in options_map) {
                            (var k, var v) = node;
                            options.push("${k} = ${v}")
                        };
                        var options_action = "${rEGBIT_DHCP_OPTS_RESULT()} = put_dhcp_opts(offerip = ${offer_ip}, " ++
                                             options.join(", ") ++ "); next;";
                        var response_action = "eth.dst = eth.src; eth.src = ${server_mac}; "
                                              "ip4.src = ${server_ip}; udp.src = 67; "
                                              "udp.dst = 68; outport = inport; flags.loopback = 1; "
                                              "output;";

                        var ipv4_addr_match = "ip4.src == ${offer_ip} && ip4.dst == {${server_ip}, 255.255.255.255}";
                        Some{(options_action, response_action, ipv4_addr_match)}
                    },
                    _ -> {
                        /* "server_id", "server_mac" and "lease_time" should be
                         * present in the dhcp_options. */
                        //static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT(1, 5);
                        warn("Required DHCPv4 options not defined for lport - ${lsp_json_key}");
                        None
                    }
                }
            }
        }
    }
}

function build_dhcpv6_action(
    lsp_json_key: string,
    dhcpv6_options: nb::DHCP_Options,
    offer_ip: in6_addr): Option<(string, string)> =
{
    match (ipv6_parse_masked(dhcpv6_options.cidr)) {
        Left{err} -> {
            /* cidr defined is invalid */
            //warn("cidr is invalid - ${err}");
            None
        },
        Right{(var host_ip, var mask)} -> {
            if (not (offer_ip, host_ip).same_network(mask)) {
                /* offer_ip doesn't belongs to the cidr defined in lport's DHCPv6
                 * options.*/
                //warn("ip does not belong to cidr");
                None
            } else {
                /* "server_id" should be the MAC address. */
                match (dhcpv6_options.options.get("server_id")) {
                    None -> {
                        warn("server_id not present in the DHCPv6 options for lport ${lsp_json_key}");
                        None
                    },
                    Some{server_mac} -> {
                        match (eth_addr_from_string(server_mac)) {
                            None -> {
                                warn("server_id not present in the DHCPv6 options for lport ${lsp_json_key}");
                                None
                            },
                            Some{ea} -> {
                                /* Get the link local IP of the DHCPv6 server from the server MAC. */
                                var server_ip = ea.to_ipv6_lla().string_mapped();
                                var ia_addr = offer_ip.string_mapped();
                                var options = vec_empty();

                                /* Check whether the dhcpv6 options should be configured as stateful.
                                 * Only reply with ia_addr option for dhcpv6 stateful address mode. */
                                if (not dhcpv6_options.options.get_bool_def("dhcpv6_stateless", false)) {
                                    options.push("ia_addr = ${ia_addr}")
                                } else ();

                                /* We're not using SMAP_FOR_EACH because we want a consistent order of the
                                 * options on different architectures (big or little endian, SSE4.2) */
                                // FIXME: enumerate map in ascending order of keys. Is this good enough?
                                for (node in dhcpv6_options.options) {
                                    (var k, var v) = node;
                                    if (k != "dhcpv6_stateless") {
                                        options.push("${k} = ${v}")
                                    } else ()
                                };

                                var options_action = "${rEGBIT_DHCP_OPTS_RESULT()} = put_dhcpv6_opts(" ++
                                                     options.join(", ") ++
                                                     "); next;";
                                var response_action = "eth.dst = eth.src; eth.src = ${server_mac}; "
                                                      "ip6.dst = ip6.src; ip6.src = ${server_ip}; udp.src = 547; "
                                                       "udp.dst = 546; outport = inport; flags.loopback = 1; "
                                                       "output;";
                                Some{(options_action, response_action)}
                            }
                        }
                    }
                }
            }
        }
    }
}

/* If 'names' has one element, returns json_string_escape() for it.
 * Otherwise, returns json_string_escape() of all of its elements inside "{...}".
 */
function json_string_escape_vec(names: Vec<string>): string
{
    match ((names.len(), names.nth(0))) {
        (1, Some{name}) -> json_string_escape(name),
        _ -> {
            var json_names = vec_with_capacity(names.len());
            for (name in names) {
                json_names.push(json_string_escape(name));
            };
            "{" ++ json_names.join(", ") ++ "}"
        }
    }
}

/*
 * Ordinarily, returns a single match against 'lsp'.
 *
 * If 'lsp' is an external port, returns a match against the localnet port(s) on
 * its switch along with a condition that it only operate if 'lsp' is
 * chassis-resident.  This makes sense as a condition for sending DHCP replies
 * to external ports because only one chassis should send such a reply.
 *
 * Returns a prefix and a suffix string.  There is no reason for this except
 * that it makes it possible to exactly mimic the format used by ovn-northd.c
 * so that text-based comparisons do not show differences.  (This fails if
 * there's more than one localnet port since the C version uses multiple flows
 * in that case.)
 */
function match_dhcp_input(lsp: Ref<SwitchPort>): (string, string) =
{
    if (lsp.lsp.__type == "external" and not lsp.sw.localnet_ports.is_empty()) {
        ("inport == " ++ json_string_escape_vec(lsp.sw.localnet_ports.map(|x| x.1)) ++ " && ",
         " && is_chassis_resident(${lsp.json_name})")
    } else {
        ("inport == ${lsp.json_name} && ", "")
    }
}

/* Logical switch ingress tables DHCP_OPTIONS and DHCP_RESPONSE: DHCP options
 * and response priority 100 flows. */
for (lsp in &SwitchPort
         /* Don't add the DHCP flows if the port is not enabled or if the
          * port is a router port. */
         if (lsp.is_enabled() and lsp.lsp.__type != "router")
         /* If it's an external port and there is no localnet port
          * and if it doesn't belong to an HA chassis group ignore it. */
         and (lsp.lsp.__type != "external"
              or (not lsp.sw.localnet_ports.is_empty()
                  and lsp.lsp.ha_chassis_group.is_some())))
{
    for (lps in LogicalSwitchPort(.lport = lsp.lsp._uuid, .lswitch = lsuuid)) {
        var json_key = json_string_escape(lsp.lsp.name) in
        (var pfx, var sfx) = match_dhcp_input(lsp) in
        {
            /* DHCPv4 options enabled for this port */
            Some{var dhcpv4_options_uuid} = lsp.lsp.dhcpv4_options in
            {
                for (dhcpv4_options in nb::DHCP_Options(._uuid = dhcpv4_options_uuid)) {
                    for (SwitchPortIPv4Address(.port = &SwitchPort{.lsp = nb::Logical_Switch_Port{._uuid = lsp.lsp._uuid}}, .ea = ea, .addr = addr)) {
                        Some{(var options_action, var response_action, var ipv4_addr_match)} =
                            build_dhcpv4_action(json_key, dhcpv4_options, addr.addr) in
                        {
                            var __match =
                                pfx ++ "eth.src == ${ea} && "
                                "ip4.src == 0.0.0.0 && ip4.dst == 255.255.255.255 && "
                                "udp.src == 68 && udp.dst == 67" ++ sfx
                            in
                            Flow(.logical_datapath = lsuuid,
                                 .stage            = s_SWITCH_IN_DHCP_OPTIONS(),
                                 .priority         = 100,
                                 .__match          = __match,
                                 .actions          = options_action,
                                 .external_ids     = stage_hint(lsp.lsp._uuid));

                            /* Allow ip4.src = OFFER_IP and
                             * ip4.dst = {SERVER_IP, 255.255.255.255} for the below
                             * cases
                             *  -  When the client wants to renew the IP by sending
                             *     the DHCPREQUEST to the server ip.
                             *  -  When the client wants to renew the IP by
                             *     broadcasting the DHCPREQUEST.
                             */
                            var __match = pfx ++ "eth.src == ${ea} && "
                                "${ipv4_addr_match} && udp.src == 68 && udp.dst == 67" ++ sfx in
                            Flow(.logical_datapath = lsuuid,
                                 .stage            = s_SWITCH_IN_DHCP_OPTIONS(),
                                 .priority         = 100,
                                 .__match          = __match,
                                 .actions          = options_action,
                                 .external_ids     = stage_hint(lsp.lsp._uuid));

                            /* If REGBIT_DHCP_OPTS_RESULT is set, it means the
                             * put_dhcp_opts action  is successful. */
                            var __match = pfx ++ "eth.src == ${ea} && "
                                "ip4 && udp.src == 68 && udp.dst == 67 && " ++
                                rEGBIT_DHCP_OPTS_RESULT() ++ sfx in
                            Flow(.logical_datapath = lsuuid,
                                 .stage            = s_SWITCH_IN_DHCP_RESPONSE(),
                                 .priority         = 100,
                                 .__match          = __match,
                                 .actions          = response_action,
                                 .external_ids     = stage_hint(lsp.lsp._uuid))
                            // FIXME: is there a constraint somewhere that guarantees that build_dhcpv4_action
                            // returns Some() for at most 1 address in lsp_addrs? Otherwise, simulate this break
                            // by computing an aggregate that returns the first element of a group.
                            //break;
                        }
                    }
                }
            };

            /* DHCPv6 options enabled for this port */
            Some{var dhcpv6_options_uuid} = lsp.lsp.dhcpv6_options in
            {
                for (dhcpv6_options in nb::DHCP_Options(._uuid = dhcpv6_options_uuid)) {
                    for (SwitchPortIPv6Address(.port = &SwitchPort{.lsp = nb::Logical_Switch_Port{._uuid = lsp.lsp._uuid}}, .ea = ea, .addr = addr)) {
                        Some{(var options_action, var response_action)} =
                            build_dhcpv6_action(json_key, dhcpv6_options, addr.addr) in
                        {
                            var __match = pfx ++ "eth.src == ${ea}"
                                " && ip6.dst == ff02::1:2 && udp.src == 546 &&"
                                " udp.dst == 547" ++ sfx in
                            {
                                Flow(.logical_datapath = lsuuid,
                                     .stage            = s_SWITCH_IN_DHCP_OPTIONS(),
                                     .priority         = 100,
                                     .__match          = __match,
                                     .actions          = options_action,
                                     .external_ids     = stage_hint(lsp.lsp._uuid));

                                /* If REGBIT_DHCP_OPTS_RESULT is set to 1, it means the
                                 * put_dhcpv6_opts action is successful */
                                Flow(.logical_datapath = lsuuid,
                                     .stage            = s_SWITCH_IN_DHCP_RESPONSE(),
                                     .priority         = 100,
                                     .__match          = __match ++ " && ${rEGBIT_DHCP_OPTS_RESULT()}",
                                     .actions          = response_action,
                                     .external_ids     = stage_hint(lsp.lsp._uuid))
                                // FIXME: is there a constraint somewhere that guarantees that build_dhcpv4_action
                                // returns Some() for at most 1 address in lsp_addrs? Otherwise, simulate this breaks
                                // by computing an aggregate that returns the first element of a group.
                                //break;
                            }
                        }
                    }
                }
            }
        }
    }
}

/* Logical switch ingress tables DNS_LOOKUP and DNS_RESPONSE: DNS lookup and
 * response priority 100 flows.
 */
for (LogicalSwitchHasDNSRecords(ls, true))
{
    Flow(.logical_datapath = ls,
         .stage            = s_SWITCH_IN_DNS_LOOKUP(),
         .priority         = 100,
         .__match          = "udp.dst == 53",
         .actions          = "${rEGBIT_DNS_LOOKUP_RESULT()} = dns_lookup(); next;",
         .external_ids     = map_empty());

    var action = "eth.dst <-> eth.src; ip4.src <-> ip4.dst; "
                 "udp.dst = udp.src; udp.src = 53; outport = inport; "
                 "flags.loopback = 1; output;" in
    Flow(.logical_datapath = ls,
         .stage            = s_SWITCH_IN_DNS_RESPONSE(),
         .priority         = 100,
         .__match          = "udp.dst == 53 && ${rEGBIT_DNS_LOOKUP_RESULT()}",
         .actions          = action,
         .external_ids     = map_empty());

    var action = "eth.dst <-> eth.src; ip6.src <-> ip6.dst; "
                 "udp.dst = udp.src; udp.src = 53; outport = inport; "
                 "flags.loopback = 1; output;" in
    Flow(.logical_datapath = ls,
         .stage            = s_SWITCH_IN_DNS_RESPONSE(),
         .priority         = 100,
         .__match          = "udp.dst == 53 && ${rEGBIT_DNS_LOOKUP_RESULT()}",
         .actions          = action,
         .external_ids     = map_empty())
}

/* Ingress table DHCP_OPTIONS and DHCP_RESPONSE: DHCP options and response, by
 * default goto next. (priority 0).
 *
 * Ingress table DNS_LOOKUP and DNS_RESPONSE: DNS lookup and response, by
 * default goto next.  (priority 0).

 * Ingress table EXTERNAL_PORT - External port handling, by default goto next.
 * (priority 0). */
for (ls in nb::Logical_Switch) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_DHCP_OPTIONS(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_DHCP_RESPONSE(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_DNS_LOOKUP(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_DNS_RESPONSE(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_IN_EXTERNAL_PORT(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

Flow(.logical_datapath = sw.ls._uuid,
     .stage = s_SWITCH_IN_L2_LKUP(),
     .priority = 110,
     .__match = "eth.dst == $svc_monitor_mac",
     .actions = "handle_svc_check(inport);",
     .external_ids = map_empty()) :-
    sw in &Switch().

for (sw in &Switch(.ls = ls, .mcast_cfg = &mcast_cfg)
        if (mcast_cfg.enabled)) {
    for (SwitchMcastFloodRelayPorts(sw, relay_ports)) {
        for (SwitchMcastFloodReportPorts(sw, flood_report_ports)) {
            for (SwitchMcastFloodPorts(sw, flood_ports)) {
                var flood_relay = not relay_ports.is_empty() in
                var flood_reports = not flood_report_ports.is_empty() in
                var flood_static = not flood_ports.is_empty() in
                var igmp_act = {
                    if (flood_reports) {
                        var mrouter_static = json_string_escape(mC_MROUTER_STATIC().0);
                        "clone { "
                            "outport = ${mrouter_static}; "
                            "output; "
                        "};igmp;"
                    } else {
                        "igmp;"
                    }
                } in {
                    /* Punt IGMP traffic to controller. */
                    UniqueFlow[Flow{.logical_datapath = ls._uuid,
                                    .stage            = s_SWITCH_IN_L2_LKUP(),
                                    .priority         = 100,
                                    .__match          = "ip4 && ip.proto == 2",
                                    .actions          = "${igmp_act}",
                                    .external_ids     = map_empty()}];

                    /* Punt MLD traffic to controller. */
                    UniqueFlow[Flow{.logical_datapath = ls._uuid,
                                    .stage            = s_SWITCH_IN_L2_LKUP(),
                                    .priority         = 100,
                                    .__match          = "mldv1 || mldv2",
                                    .actions          = "${igmp_act}",
                                    .external_ids     = map_empty()}];

                    /* Flood all IP multicast traffic destined to 224.0.0.X to
                     * all ports - RFC 4541, section 2.1.2, item 2.
                     */
                    var flood = json_string_escape(mC_FLOOD().0) in
                    UniqueFlow[Flow{.logical_datapath = ls._uuid,
                                    .stage            = s_SWITCH_IN_L2_LKUP(),
                                    .priority         = 85,
                                    .__match          = "ip4.mcast && ip4.dst == 224.0.0.0/24",
                                    .actions          = "outport = ${flood}; output;",
                                    .external_ids     = map_empty()}];

                    /* Flood all IPv6 multicast traffic destined to reserved
                     * multicast IPs (RFC 4291, 2.7.1).
                     */
                    var flood = json_string_escape(mC_FLOOD().0) in
                    UniqueFlow[Flow{.logical_datapath = ls._uuid,
                                    .stage            = s_SWITCH_IN_L2_LKUP(),
                                    .priority         = 85,
                                    .__match          = "ip6.mcast_flood",
                                    .actions          = "outport = ${flood}; output;",
                                    .external_ids     = map_empty()}];

                    /* Forward uregistered IP multicast to routers with relay
                     * enabled and to any ports configured to flood IP
                     * multicast traffic. If configured to flood unregistered
                     * traffic this will be handled by the L2 multicast flow.
                     */
                    if (not mcast_cfg.flood_unreg) {
                        var relay_act = {
                            if (flood_relay) {
                                var rtr_flood = json_string_escape(mC_MROUTER_FLOOD().0);
                                "clone { "
                                    "outport = ${rtr_flood}; "
                                    "output; "
                                "}; "
                            } else {
                                ""
                            }
                        } in
                        var static_act = {
                            if (flood_static) {
                                var mc_static = json_string_escape(mC_STATIC().0);
                                "outport =${mc_static}; output;"
                            } else {
                                ""
                            }
                        } in
                        var drop_act = {
                            if (not flood_relay and not flood_static) {
                                "drop;"
                            } else {
                                ""
                            }
                        } in
                        UniqueFlow[Flow{.logical_datapath = ls._uuid,
                                        .stage            = s_SWITCH_IN_L2_LKUP(),
                                        .priority         = 80,
                                        .__match          = "ip4.mcast || ip6.mcast",
                                        .actions          =
                                           "${relay_act}${static_act}${drop_act}",
                                        .external_ids     = map_empty()}]
                    }
                }
            }
        }
    }
}

/* Ingress table L2_LKUP: Add IP multicast flows learnt from IGMP/MLD (priority
 * 90). */
for (IgmpSwitchMulticastGroup(.address = address, .switch = &sw)) {
    /* RFC 4541, section 2.1.2, item 2: Skip groups in the 224.0.0.X
     * range.
     *
     * RFC 4291, section 2.7.1: Skip groups that correspond to all
     * hosts.
     */
    Some{var ip} = ip46_parse(address) in
    (var skip_address) = match (ip) {
        IPv4{ipv4} -> ipv4.is_local_multicast(),
        IPv6{ipv6} -> ipv6.is_all_hosts()
    } in
    var ipX = ip.ipX() in
    for (SwitchMcastFloodRelayPorts(&sw, relay_ports) if not skip_address) {
        for (SwitchMcastFloodPorts(&sw, flood_ports)) {
            var flood_relay = not relay_ports.is_empty() in
            var flood_static = not flood_ports.is_empty() in
            var mc_rtr_flood = json_string_escape(mC_MROUTER_FLOOD().0) in
            var mc_static = json_string_escape(mC_STATIC().0) in
            var relay_act = {
                if (flood_relay) {
                    "clone { "
                        "outport = ${mc_rtr_flood}; output; "
                    "};"
                } else {
                    ""
                }
            } in
            var static_act = {
                if (flood_static) {
                    "clone { "
                        "outport =${mc_static}; "
                        "output; "
                    "};"
                } else {
                    ""
                }
            } in
            UniqueFlow[Flow{.logical_datapath = sw.ls._uuid,
                            .stage            = s_SWITCH_IN_L2_LKUP(),
                            .priority         = 90,
                            .__match          = "eth.mcast && ${ipX} && ${ipX}.dst == ${address}",
                            .actions          =
                               "${relay_act} ${static_act} outport = \"${address}\"; "
                               "output;",
                            .external_ids     = map_empty()}]
        }
    }
}

/* Table EXTERNAL_PORT: External port. Drop ARP request for router ips from
 * external ports on chassis not binding those ports.  This makes the router
 * pipeline to be run only on the chassis binding the external ports.
 *
 * For an external port X on logical switch LS, if X is not resident on this
 * chassis, drop ARP requests arriving on localnet ports from X's Ethernet
 * address, if the ARP request is asking to translate the IP address of a
 * router port on LS. */
Flow(.logical_datapath = sp.sw.ls._uuid,
     .stage            = s_SWITCH_IN_EXTERNAL_PORT(),
     .priority         = 100,
     .__match          = ("inport == ${json_string_escape(localnet_port.1)} && "
                          "eth.src == ${lp_addr.ea} && "
                          "!is_chassis_resident(${sp.json_name}) && "
                          "arp.tpa == ${rp_addr.addr} && arp.op == 1"),
     .actions          = "drop;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(),
    sp.lsp.__type == "external",
    var localnet_port = FlatMap(sp.sw.localnet_ports),
    var lp_addr = FlatMap(sp.static_addresses),
    rp in &SwitchPort(.sw = sp.sw),
    rp.lsp.__type == "router",
    SwitchPortIPv4Address(.port = rp, .addr = rp_addr).
Flow(.logical_datapath = sp.sw.ls._uuid,
     .stage            = s_SWITCH_IN_EXTERNAL_PORT(),
     .priority         = 100,
     .__match          = ("inport == ${json_string_escape(localnet_port.1)} && "
                          "eth.src == ${lp_addr.ea} && "
                          "!is_chassis_resident(${sp.json_name}) && "
                          "nd_ns && ip6.dst == {${rp_addr.addr}, ${rp_addr.solicited_node()}} && "
                          "nd.target == ${rp_addr.addr}"),
     .actions          = "drop;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(),
    sp.lsp.__type == "external",
    var localnet_port = FlatMap(sp.sw.localnet_ports),
    var lp_addr = FlatMap(sp.static_addresses),
    rp in &SwitchPort(.sw = sp.sw),
    rp.lsp.__type == "router",
    SwitchPortIPv6Address(.port = rp, .addr = rp_addr).
Flow(.logical_datapath = sp.sw.ls._uuid,
     .stage            = s_SWITCH_IN_EXTERNAL_PORT(),
     .priority         = 100,
     .__match          = ("inport == ${json_string_escape(localnet_port.1)} && "
                          "eth.src == ${lp_addr.ea} && "
                          "eth.dst == ${ea} && "
                          "!is_chassis_resident(${sp.json_name})"),
     .actions          = "drop;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(),
    sp.lsp.__type == "external",
    var localnet_port = FlatMap(sp.sw.localnet_ports),
    var lp_addr = FlatMap(sp.static_addresses),
    rp in &SwitchPort(.sw = sp.sw),
    rp.lsp.__type == "router",
    SwitchPortAddresses(.port = rp, .addrs = LPortAddress{.ea = ea}).

/* Ingress table L2_LKUP: Destination lookup, broadcast and multicast handling
 * (priority 100). */
for (ls in nb::Logical_Switch) {
    var mc_flood = json_string_escape(mC_FLOOD().0) in
    UniqueFlow[Flow{.logical_datapath = ls._uuid,
                    .stage            = s_SWITCH_IN_L2_LKUP(),
                    .priority         = 70,
                    .__match          = "eth.mcast",
                    .actions          = "outport = ${mc_flood}; output;",
                    .external_ids     = map_empty()}]
}

/* Ingress table L2_LKUP: Destination lookup, unicast handling (priority 50).
*/
for (SwitchPortStaticAddresses(.port = &SwitchPort{.lsp = lsp, .json_name = json_name, .sw = &sw},
                               .addrs = addrs)
     if lsp.__type != "external") {
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_IN_L2_LKUP(),
         .priority         = 50,
         .__match          = "eth.dst == ${addrs.ea}",
         .actions          = "outport = ${json_name}; output;",
         .external_ids     = stage_hint(lsp._uuid))
}

/*
 * Ingress table L2_LKUP: Flows that flood self originated ARP/ND packets in the
 * switching domain.
 */
/* Self originated ARP requests/ND need to be flooded to the L2 domain
 * (except on router ports).  Determine that packets are self originated
 * by also matching on source MAC. Matching on ingress port is not
 * reliable in case this is a VLAN-backed network.
 * Priority: 75.
 */

/* Returns 'true' if the IP 'addr' is on the same subnet with one of the
 * IPs configured on the router port.
 */
function lrouter_port_ip_reachable(rp: Ref<RouterPort>, addr: v46_ip): bool {
    match (addr) {
        IPv4{ipv4} -> {
            for (na in rp.networks.ipv4_addrs) {
                if ((ipv4, na.addr).same_network(na.netmask())) {
                    return true
                }
            }
        },
        IPv6{ipv6} -> {
            for (na in rp.networks.ipv6_addrs) {
                if ((ipv6, na.addr).same_network(na.netmask())) {
                    return true
                }
            }
        }
    };
    false
}
UniqueFlow[Flow{.logical_datapath = sw.ls._uuid,
                .stage            = s_SWITCH_IN_L2_LKUP(),
                .priority         = 75,
                .__match          = __match,
                .actions          = actions,
                .external_ids     = stage_hint(sp.lsp._uuid)}] :-
    sp in &SwitchPort(.sw = sw@&Switch{.has_non_router_port = true}, .peer = Some{rp}),
    rp.is_enabled(),
    var eth_src_set = {
        var eth_src_set = set_singleton("${rp.networks.ea}");
        for (nat in rp.router.nats) {
            match (nat.nat.external_mac) {
                Some{mac} ->
                    if (lrouter_port_ip_reachable(rp, nat.external_ip)) {
                        eth_src_set.insert(mac)
                    } else (),
                _ -> ()
            }
        };
        eth_src_set
    },
    var eth_src = "{" ++ eth_src_set.to_vec().join(", ") ++ "}",
    var __match = "eth.src == ${eth_src} && (arp.op == 1 || nd_ns)",
    var mc_flood_l2 = json_string_escape(mC_FLOOD_L2().0),
    var actions = "outport = ${mc_flood_l2}; output;".

/* Forward ARP requests for owned IP addresses (L3, VIP, NAT) only to this
 * router port.
 * Priority: 80.
 */
function get_arp_forward_ips(rp: Ref<RouterPort>): (Set<string>, Set<string>) = {
    var all_ips_v4 = set_empty();
    var all_ips_v6 = set_empty();

    (var lb_ips_v4, var lb_ips_v6)
        = get_router_load_balancer_ips(deref(rp.router));
    for (a in lb_ips_v4) {
        /* Check if the ovn port has a network configured on which we could
         * expect ARP requests for the LB VIP.
         */
        match (ip_parse(a)) {
            Some{ipv4} -> if (lrouter_port_ip_reachable(rp, IPv4{ipv4})) {
                all_ips_v4.insert(a)
            },
            _ -> ()
        }
    };
    for (a in lb_ips_v6) {
        /* Check if the ovn port has a network configured on which we could
         * expect NS requests for the LB VIP.
         */
        match (ipv6_parse(a)) {
            Some{ipv6} -> if (lrouter_port_ip_reachable(rp, IPv6{ipv6})) {
                all_ips_v6.insert(a)
            },
            _ -> ()
        }
    };

    for (nat in rp.router.nats) {
        if (nat.nat.__type != "snat") {
            /* Check if the ovn port has a network configured on which we could
             * expect ARP requests/NS for the DNAT external_ip.
             */
            if (lrouter_port_ip_reachable(rp, nat.external_ip)) {
                match (nat.external_ip) {
                    IPv4{_} -> all_ips_v4.insert(nat.nat.external_ip),
                    IPv6{_} -> all_ips_v6.insert(nat.nat.external_ip)
                }
            }
        }
    };

    for (a in rp.networks.ipv4_addrs) {
        all_ips_v4.insert("${a.addr}")
    };
    for (a in rp.networks.ipv6_addrs) {
        all_ips_v6.insert("${a.addr}")
    };

    (all_ips_v4, all_ips_v6)
}
/* Packets received from VXLAN tunnels have already been through the
 * router pipeline so we should skip them. Normally this is done by the
 * multicast_group implementation (VXLAN packets skip table 32 which
 * delivers to patch ports) but we're bypassing multicast_groups.
 * (This is why we match against fLAGBIT_NOT_VXLAN() here.)
 */
AnnotatedFlow(.f = Flow{.logical_datapath = sw.ls._uuid,
                        .stage            = s_SWITCH_IN_L2_LKUP(),
                        .priority         = 80,
                        .__match          = fLAGBIT_NOT_VXLAN() ++
                                            " && arp.op == 1 && arp.tpa == { " ++
                                            all_ips_v4.to_vec().join(", ") ++ "}",
                        .actions          = if (sw.has_non_router_port) {
                                                "clone {outport = ${sp.json_name}; output; }; "
                                                "outport = ${mc_flood_l2}; output;"
                                            } else {
                                                "outport = ${sp.json_name}; output;"
                                            },
                        .external_ids     = stage_hint(sp.lsp._uuid)},
              .shared = not sw.has_non_router_port) :-
    sp in &SwitchPort(.sw = sw, .peer = Some{rp}),
    rp.is_enabled(),
    (var all_ips_v4, _) = get_arp_forward_ips(rp),
    not all_ips_v4.is_empty(),
    var mc_flood_l2 = json_string_escape(mC_FLOOD_L2().0).
AnnotatedFlow(.f = Flow{.logical_datapath = sw.ls._uuid,
                        .stage            = s_SWITCH_IN_L2_LKUP(),
                        .priority         = 80,
                        .__match          = fLAGBIT_NOT_VXLAN() ++
                                            " && nd_ns && nd.target == { " ++
                                            all_ips_v6.to_vec().join(", ") ++ "}",
                        .actions          = if (sw.has_non_router_port) {
                                                "clone {outport = ${sp.json_name}; output; }; "
                                                "outport = ${mc_flood_l2}; output;"
                                            } else {
                                                "outport = ${sp.json_name}; output;"
                                            },
                        .external_ids     = stage_hint(sp.lsp._uuid)},
              .shared = not sw.has_non_router_port) :-
    sp in &SwitchPort(.sw = sw, .peer = Some{rp}),
    rp.is_enabled(),
    (_, var all_ips_v6) = get_arp_forward_ips(rp),
    not all_ips_v6.is_empty(),
    var mc_flood_l2 = json_string_escape(mC_FLOOD_L2().0).

for (SwitchPortNewDynamicAddress(.port = &SwitchPort{.lsp = lsp, .json_name = json_name, .sw = &sw},
                                 .address = Some{addrs})
     if lsp.__type != "external") {
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_IN_L2_LKUP(),
         .priority         = 50,
         .__match          = "eth.dst == ${addrs.ea}",
         .actions          = "outport = ${json_name}; output;",
         .external_ids     = stage_hint(lsp._uuid))
}

for (&SwitchPort(.lsp = lsp,
                 .json_name = json_name,
                 .sw = &sw,
                 .peer = Some{&RouterPort{.lrp = lrp,
                                          .is_redirect = is_redirect,
                                          .router = &Router{.lr = lr,
                                                            .redirect_port_name = redirect_port_name}}})
     if (lsp.addresses.contains("router") and lsp.__type != "external"))
{
    Some{var mac} = scan_eth_addr(lrp.mac) in {
        var add_chassis_resident_check =
            not sw.localnet_ports.is_empty() and
            (/* The peer of this port represents a distributed
              * gateway port. The destination lookup flow for the
              * router's distributed gateway port MAC address should
              * only be programmed on the "redirect-chassis". */
             is_redirect or
             /* Check if the option 'reside-on-redirect-chassis'
              * is set to true on the peer port. If set to true
              * and if the logical switch has a localnet port, it
              * means the router pipeline for the packets from
              * this logical switch should be run on the chassis
              * hosting the gateway port.
              */
              lrp.options.get_bool_def("reside-on-redirect-chassis", false)) in
        var __match = if (add_chassis_resident_check) {
            /* The destination lookup flow for the router's
             * distributed gateway port MAC address should only be
             * programmed on the "redirect-chassis". */
            "eth.dst == ${mac} && is_chassis_resident(${redirect_port_name})"
        } else {
            "eth.dst == ${mac}"
        } in
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = s_SWITCH_IN_L2_LKUP(),
             .priority         = 50,
             .__match          = __match,
             .actions          = "outport = ${json_name}; output;",
             .external_ids     = stage_hint(lsp._uuid));

        /* Add ethernet addresses specified in NAT rules on
         * distributed logical routers. */
        if (is_redirect) {
            for (LogicalRouterNAT(.lr = lr._uuid, .nat = nat)) {
                if (nat.nat.__type == "dnat_and_snat") {
                    Some{var lport} = nat.nat.logical_port in
                    Some{var emac} = nat.nat.external_mac in
                    Some{var nat_mac} = eth_addr_from_string(emac) in
                    var __match = "eth.dst == ${nat_mac} && is_chassis_resident(${json_string_escape(lport)})" in
                    Flow(.logical_datapath = sw.ls._uuid,
                         .stage            = s_SWITCH_IN_L2_LKUP(),
                         .priority         = 50,
                         .__match          = __match,
                         .actions          = "outport = ${json_name}; output;",
                         .external_ids     = stage_hint(nat.nat._uuid))
                }
            }
        }
    }
}
// FIXME: do we care about this?
/*        } else {
            static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT(1, 1);

            VLOG_INFO_RL(&rl,
                         "%s: invalid syntax '%s' in addresses column",
                         op->nbsp->name, op->nbsp->addresses[i]);
        }*/

/* Ingress table L2_LKUP and L2_UNKNOWN: Destination lookup for unknown MACs (priority 0). */
for (sw in &Switch(.ls = nb::Logical_Switch{._uuid = ls_uuid})) {
    Flow(.logical_datapath = ls_uuid,
         .stage            = s_SWITCH_IN_L2_LKUP(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "outport = get_fdb(eth.dst); next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls_uuid,
         .stage            = s_SWITCH_IN_L2_UNKNOWN(),
         .priority         = 50,
         .__match          = "outport == \"none\"",
         .actions          = if (sw.has_unknown_ports) {
                                 var mc_unknown = json_string_escape(mC_UNKNOWN().0);
                                 "outport = ${mc_unknown}; output;"
                             } else {
                                 "drop;"
                             },
         .external_ids     = map_empty());

    Flow(.logical_datapath = ls_uuid,
         .stage            = s_SWITCH_IN_L2_UNKNOWN(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "output;",
         .external_ids     = map_empty())
}

/* Egress tables PORT_SEC_IP: Egress port security - IP (priority 0)
 * Egress table PORT_SEC_L2: Egress port security L2 - multicast/broadcast (priority 100). */
for (&Switch(.ls = ls)) {
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PORT_SEC_IP(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = ls._uuid,
         .stage            = s_SWITCH_OUT_PORT_SEC_L2(),
         .priority         = 100,
         .__match          = "eth.mcast",
         .actions          = "output;",
         .external_ids     = map_empty())
}

Flow(.logical_datapath = ls_uuid,
     .stage = s_SWITCH_IN_LOOKUP_FDB(),
     .priority = 100,
     .__match = "inport == ${sp.json_name}",
     .actions = "$[rEGBIT_LKUP_FDB()} = lookup_fdb(inport, eth.src); next;",
     .external_ids = stage_hint(lsp_uuid)),
Flow(.logical_datapath = ls_uuid,
     .stage = s_SWITCH_IN_LOOKUP_FDB(),
     .priority = 100,
     .__match = "inport == ${sp.json_name} && ${rEGBIT_LKUP_FDB()} == 0",
     .actions = "put_fdb(inport, eth.src); next;",
     .external_ids = stage_hint(lsp_uuid)) :-
    LogicalSwitchPortWithUnknownAddress(ls_uuid, lsp_uuid),
    sp in &SwitchPort(.lsp = nb::Logical_Switch_Port{._uuid = lsp_uuid, .__type = ""},
                      .ps_addresses = vec_empty()).

Flow(.logical_datapath = ls._uuid,
     .stage            = s_SWITCH_IN_LOOKUP_FDB(),
     .priority         = 0,
     .__match          = "1",
     .actions          = "next;",
     .external_ids     = map_empty()),
Flow(.logical_datapath = ls._uuid,
     .stage            = s_SWITCH_IN_PUT_FDB(),
     .priority         = 0,
     .__match          = "1",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    &Switch(.ls = ls).

/* Egress table PORT_SEC_IP: Egress port security - IP (priorities 90 and 80)
 * if port security enabled.
 *
 * Egress table PORT_SEC_L2: Egress port security - L2 (priorities 50 and 150).
 *
 * Priority 50 rules implement port security for enabled logical port.
 *
 * Priority 150 rules drop packets to disabled logical ports, so that they
 * don't even receive multicast or broadcast packets. */
Flow(.logical_datapath = sw.ls._uuid,
     .stage            = s_SWITCH_OUT_PORT_SEC_L2(),
     .priority         = 50,
     .__match          = __match,
     .actions          = queue_action ++ "output;",
     .external_ids     = stage_hint(lsp._uuid)) :-
    &SwitchPort(.sw = &sw, .lsp = lsp, .json_name = json_name, .ps_eth_addresses = ps_eth_addresses),
    lsp.is_enabled(),
    lsp.__type != "external",
    var __match = if (ps_eth_addresses.is_empty()) {
            "outport == ${json_name}"
        } else {
            "outport == ${json_name} && eth.dst == {${ps_eth_addresses.join(\" \")}}"
        },
    pbinding in sb::Out_Port_Binding(.logical_port = lsp.name),
    var queue_action = match ((lsp.__type,
                               pbinding.options.get("qdisc_queue_id"))) {
        ("localnet", Some{queue_id}) -> "set_queue(${queue_id});",
        _ -> ""
    }.

for (&SwitchPort(.lsp = lsp, .json_name = json_name, .sw = &sw)
     if not lsp.is_enabled() and lsp.__type != "external") {
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_OUT_PORT_SEC_L2(),
         .priority         = 150,
         .__match          = "outport == {$json_name}",
         .actions          = "drop;",
         .external_ids     = stage_hint(lsp._uuid))
}

for (SwitchPortPSAddresses(.port = &SwitchPort{.lsp = lsp, .json_name = json_name, .sw = &sw},
                           .ps_addrs = ps)
     if (ps.ipv4_addrs.len() > 0 or ps.ipv6_addrs.len() > 0)
         and lsp.__type != "external")
{
    if (ps.ipv4_addrs.len() > 0) {
        var addrs = {
            var addrs = vec_empty();
            for (addr in ps.ipv4_addrs) {
                /* When the netmask is applied, if the host portion is
                 * non-zero, the host can only use the specified
                 * address.  If zero, the host is allowed to use any
                 * address in the subnet.
                 */
                addrs.push(addr.match_host_or_network());
                if (addr.plen < 32 and not addr.host().is_zero()) {
                    addrs.push("${addr.bcast()}")
                }
            };
            addrs
        } in
        var __match =
            "outport == ${json_name} && eth.dst == ${ps.ea} && ip4.dst == {255.255.255.255, 224.0.0.0/4, " ++
            addrs.join(", ") ++ "}" in
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = s_SWITCH_OUT_PORT_SEC_IP(),
             .priority         = 90,
             .__match          = __match,
             .actions          = "next;",
             .external_ids     = stage_hint(lsp._uuid))
    };
    if (ps.ipv6_addrs.len() > 0) {
        var __match = "outport == ${json_name} && eth.dst == ${ps.ea}" ++
                      build_port_security_ipv6_flow(Egress, ps.ea, ps.ipv6_addrs) in
        Flow(.logical_datapath = sw.ls._uuid,
             .stage            = s_SWITCH_OUT_PORT_SEC_IP(),
             .priority         = 90,
             .__match          = __match,
             .actions          = "next;",
             .external_ids     = stage_hint(lsp._uuid))
    };
    var __match = "outport == ${json_name} && eth.dst == ${ps.ea} && ip" in
    Flow(.logical_datapath = sw.ls._uuid,
         .stage            = s_SWITCH_OUT_PORT_SEC_IP(),
         .priority         = 80,
         .__match          = __match,
         .actions          = "drop;",
         .external_ids     = stage_hint(lsp._uuid))
}

/* Logical router ingress table ADMISSION: Admission control framework. */
for (&Router(.lr = lr)) {
    /* Logical VLANs not supported.
     * Broadcast/multicast source address is invalid. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_ADMISSION(),
         .priority         = 100,
         .__match          = "vlan.present || eth.src[40]",
         .actions          = "drop;",
         .external_ids     = map_empty())
}

/* Logical router ingress table ADMISSION: match (priority 50). */
for (&RouterPort(.lrp = lrp,
                 .json_name = json_name,
                 .networks = lrp_networks,
                 .router = &router,
                 .is_redirect = is_redirect)
     /* Drop packets from disabled logical ports (since logical flow
      * tables are default-drop). */
     if lrp.is_enabled())
{
    //if (op->derived) {
    //    /* No ingress packets should be received on a chassisredirect
    //     * port. */
    //    continue;
    //}

    /* Store the ethernet address of the port receiving the packet.
     * This will save us from having to match on inport further down in
     * the pipeline.
     */
    var actions = "${rEG_INPORT_ETH_ADDR()} = ${lrp_networks.ea}; next;" in {
        Flow(.logical_datapath = router.lr._uuid,
             .stage            = s_ROUTER_IN_ADMISSION(),
             .priority         = 50,
             .__match          = "eth.mcast && inport == ${json_name}",
             .actions          = actions,
             .external_ids     = stage_hint(lrp._uuid));

        var __match =
            "eth.dst == ${lrp_networks.ea} && inport == ${json_name}" ++
            if is_redirect {
                /* Traffic with eth.dst = l3dgw_port->lrp_networks.ea
                 * should only be received on the "redirect-chassis". */
                " && is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"
            } else { "" } in
        Flow(.logical_datapath = router.lr._uuid,
             .stage            = s_ROUTER_IN_ADMISSION(),
             .priority         = 50,
             .__match          = __match,
             .actions          = actions,
             .external_ids     = stage_hint(lrp._uuid))
    }
}


/* Logical router ingress table LOOKUP_NEIGHBOR and
 * table LEARN_NEIGHBOR. */
/* Learn MAC bindings from ARP/IPv6 ND.
 *
 * For ARP packets, table LOOKUP_NEIGHBOR does a lookup for the
 * (arp.spa, arp.sha) in the mac binding table using the 'lookup_arp'
 * action and stores the result in REGBIT_LOOKUP_NEIGHBOR_RESULT bit.
 * If "always_learn_from_arp_request" is set to false, it will also
 * lookup for the (arp.spa) in the mac binding table using the
 * "lookup_arp_ip" action for ARP request packets, and stores the
 * result in REGBIT_LOOKUP_NEIGHBOR_IP_RESULT bit; or set that bit
 * to "1" directly for ARP response packets.
 *
 * For IPv6 ND NA packets, table LOOKUP_NEIGHBOR does a lookup
 * for the (nd.target, nd.tll) in the mac binding table using the
 * 'lookup_nd' action and stores the result in
 * REGBIT_LOOKUP_NEIGHBOR_RESULT bit. If
 * "always_learn_from_arp_request" is set to false,
 * REGBIT_LOOKUP_NEIGHBOR_IP_RESULT bit is set.
 *
 * For IPv6 ND NS packets, table LOOKUP_NEIGHBOR does a lookup
 * for the (ip6.src, nd.sll) in the mac binding table using the
 * 'lookup_nd' action and stores the result in
 * REGBIT_LOOKUP_NEIGHBOR_RESULT bit. If
 * "always_learn_from_arp_request" is set to false, it will also lookup
 * for the (ip6.src) in the mac binding table using the "lookup_nd_ip"
 * action and stores the result in REGBIT_LOOKUP_NEIGHBOR_IP_RESULT
 * bit.
 *
 * Table LEARN_NEIGHBOR learns the mac-binding using the action
 * - 'put_arp/put_nd'. Learning mac-binding is skipped if
 *   REGBIT_LOOKUP_NEIGHBOR_RESULT bit is set or
 *   REGBIT_LOOKUP_NEIGHBOR_IP_RESULT is not set.
 *
 * */

/* Flows for LOOKUP_NEIGHBOR. */
for (&Router(.lr = lr, .learn_from_arp_request = learn_from_arp_request))
var rLNR = rEGBIT_LOOKUP_NEIGHBOR_RESULT() in
var rLNIR = rEGBIT_LOOKUP_NEIGHBOR_IP_RESULT() in
{
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_LOOKUP_NEIGHBOR(),
         .priority         = 100,
         .__match          = "arp.op == 2",
         .actions          =
             "${rLNR} = lookup_arp(inport, arp.spa, arp.sha); " ++
             { if (learn_from_arp_request) "" else "${rLNIR} = 1; " } ++
             "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_LOOKUP_NEIGHBOR(),
         .priority         = 100,
         .__match          = "nd_na",
         .actions          =
             "${rLNR} = lookup_nd(inport, nd.target, nd.tll); " ++
             { if (learn_from_arp_request) "" else "${rLNIR} = 1; " } ++
             "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_LOOKUP_NEIGHBOR(),
         .priority         = 100,
         .__match          = "nd_ns",
         .actions          =
             "${rLNR} = lookup_nd(inport, ip6.src, nd.sll); " ++
             { if (learn_from_arp_request) "" else
               "${rLNIR} = lookup_nd_ip(inport, ip6.src); " } ++
             "next;",
         .external_ids     = map_empty());

    /* For other packet types, we can skip neighbor learning.
     * So set REGBIT_LOOKUP_NEIGHBOR_RESULT to 1. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_LOOKUP_NEIGHBOR(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "${rLNR} = 1; next;",
         .external_ids     = map_empty());

    /* Flows for LEARN_NEIGHBOR. */
    /* Skip Neighbor learning if not required. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_LEARN_NEIGHBOR(),
         .priority         = 100,
         .__match          =
             "${rLNR} == 1" ++
             { if (learn_from_arp_request) "" else " || ${rLNIR} == 0" },
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_LEARN_NEIGHBOR(),
         .priority         = 90,
         .__match          = "arp",
         .actions          = "put_arp(inport, arp.spa, arp.sha); next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_LEARN_NEIGHBOR(),
         .priority         = 90,
         .__match          = "arp",
         .actions          = "put_arp(inport, arp.spa, arp.sha); next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_LEARN_NEIGHBOR(),
         .priority         = 90,
         .__match          = "nd_na",
         .actions          = "put_nd(inport, nd.target, nd.tll); next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_LEARN_NEIGHBOR(),
         .priority         = 90,
         .__match          = "nd_ns",
         .actions          = "put_nd(inport, ip6.src, nd.sll); next;",
         .external_ids     = map_empty())
}

/* Check if we need to learn mac-binding from ARP requests. */
for (RouterPortNetworksIPv4Addr(rp@&RouterPort{.router = router}, addr)) {
    var is_l3dgw_port = match (router.l3dgw_port) {
        Some{l3dgw_lrp} -> l3dgw_lrp._uuid == rp.lrp._uuid,
        None -> false
    } in
    var has_redirect_port = router.redirect_port_name != "" in
    var chassis_residence = match (is_l3dgw_port and has_redirect_port) {
        true -> " && is_chassis_resident(${router.redirect_port_name})",
        false -> ""
    } in
    var rLNR = rEGBIT_LOOKUP_NEIGHBOR_RESULT() in
    var rLNIR = rEGBIT_LOOKUP_NEIGHBOR_IP_RESULT() in
    var match0 = "inport == ${rp.json_name} && "
                 "arp.spa == ${addr.match_network()}" in
    var match1 = "arp.op == 1" ++ chassis_residence in
    var learn_from_arp_request = router.learn_from_arp_request in {
       if (not learn_from_arp_request) {
            /* ARP request to this address should always get learned,
             * so add a priority-110 flow to set
             * REGBIT_LOOKUP_NEIGHBOR_IP_RESULT to 1. */
            var __match = [match0, "arp.tpa == ${addr.addr}", match1] in
            var actions = "${rLNR} = lookup_arp(inport, arp.spa, arp.sha); "
                          "${rLNIR} = 1; "
                          "next;" in
            Flow(.logical_datapath = router.lr._uuid,
                 .stage            = s_ROUTER_IN_LOOKUP_NEIGHBOR(),
                 .priority         = 110,
                 .__match          = __match.join(" && "),
                 .actions          = actions,
                 .external_ids     = stage_hint(rp.lrp._uuid))
        };

        var actions = "${rLNR} = lookup_arp(inport, arp.spa, arp.sha); " ++
                      { if (learn_from_arp_request) "" else
                        "${rLNIR} = lookup_arp_ip(inport, arp.spa); " } ++
                      "next;" in
        Flow(.logical_datapath = router.lr._uuid,
             .stage            = s_ROUTER_IN_LOOKUP_NEIGHBOR(),
             .priority         = 100,
             .__match          = "${match0} && ${match1}",
             .actions          = actions,
             .external_ids     = stage_hint(rp.lrp._uuid))
    }
}


/* Logical router ingress table IP_INPUT: IP Input. */
for (router in &Router(.lr = lr, .mcast_cfg = &mcast_cfg)) {
    /* L3 admission control: drop multicast and broadcast source, localhost
     * source or destination, and zero network source or destination
     * (priority 100). */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 100,
         .__match          = "ip4.src_mcast ||"
         "ip4.src == 255.255.255.255 || "
         "ip4.src == 127.0.0.0/8 || "
         "ip4.dst == 127.0.0.0/8 || "
         "ip4.src == 0.0.0.0/8 || "
         "ip4.dst == 0.0.0.0/8",
         .actions          = "drop;",
         .external_ids     = map_empty());

   /* Drop ARP packets (priority 85). ARP request packets for router's own
    * IPs are handled with priority-90 flows.
    * Drop IPv6 ND packets (priority 85). ND NA packets for router's own
    * IPs are handled with priority-90 flows.
    */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 85,
         .__match          = "arp || nd",
         .actions          = "drop;",
         .external_ids     = map_empty());

    /* Allow IPv6 multicast traffic that's supposed to reach the
     * router pipeline (e.g., router solicitations).
     */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 84,
         .__match          = "nd_rs || nd_ra",
         .actions          = "next;",
         .external_ids     = map_empty());

    /* Drop other reserved multicast. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 83,
         .__match          = "ip6.mcast_rsvd",
         .actions          = "drop;",
         .external_ids     = map_empty());

    /* Allow other multicast if relay enabled (priority 82). */
    var mcast_action = { if (mcast_cfg.relay) { "next;" } else { "drop;" } } in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 82,
         .__match          = "ip4.mcast || ip6.mcast",
         .actions          = mcast_action,
         .external_ids     = map_empty());

    /* Drop Ethernet local broadcast.  By definition this traffic should
     * not be forwarded.*/
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 50,
         .__match          = "eth.bcast",
         .actions          = "drop;",
         .external_ids     = map_empty());

    /* TTL discard */
    Flow(
        .logical_datapath = lr._uuid,
        .stage            = s_ROUTER_IN_IP_INPUT(),
        .priority         = 30,
        .__match          = "ip4 && ip.ttl == {0, 1}",
        .actions          = "drop;",
        .external_ids     = map_empty());

    /* Pass other traffic not already handled to the next table for
     * routing. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

function format_v4_networks(networks: lport_addresses, add_bcast: bool): string =
{
    var addrs = vec_empty();
    for (addr in networks.ipv4_addrs) {
        addrs.push("${addr.addr}");
        if (add_bcast) {
            addrs.push("${addr.bcast()}")
        } else ()
    };
    if (addrs.len() == 1) {
        addrs.join(", ")
    } else {
        "{" ++ addrs.join(", ") ++ "}"
    }
}

function format_v6_networks(networks: lport_addresses): string =
{
    var addrs = vec_empty();
    for (addr in networks.ipv6_addrs) {
        addrs.push("${addr.addr}")
    };
    if (addrs.len() == 1) {
        addrs.join(", ")
    } else {
        "{" ++ addrs.join(", ") ++ "}"
    }
}

/* The following relation is used in ARP reply flow generation to determine whether
 * the is_chassis_resident check must be added to the flow.
 */
relation AddChassisResidentCheck_(lrp: uuid, add_check: bool)

AddChassisResidentCheck_(lrp._uuid, res) :-
    &SwitchPort(.peer = Some{&RouterPort{.lrp = lrp, .router = &router, .is_redirect = is_redirect}},
                .sw = sw),
    router.l3dgw_port.is_some(),
    not sw.localnet_ports.is_empty(),
    var res = if (is_redirect) {
        /* Traffic with eth.src = l3dgw_port->lrp_networks.ea
         * should only be sent from the "redirect-chassis", so that
         * upstream MAC learning points to the "redirect-chassis".
         * Also need to avoid generation of multiple ARP responses
         * from different chassis. */
        true
    } else {
        /* Check if the option 'reside-on-redirect-chassis'
         * is set to true on the router port. If set to true
         * and if peer's logical switch has a localnet port, it
         * means the router pipeline for the packets from
         * peer's logical switch is be run on the chassis
         * hosting the gateway port and it should reply to the
         * ARP requests for the router port IPs.
         */
        lrp.options.get_bool_def("reside-on-redirect-chassis", false)
    }.


relation AddChassisResidentCheck(lrp: uuid, add_check: bool)

AddChassisResidentCheck(lrp, add_check) :-
    AddChassisResidentCheck_(lrp, add_check).

AddChassisResidentCheck(lrp, false) :-
    nb::Logical_Router_Port(._uuid = lrp),
    not AddChassisResidentCheck_(lrp, _).


/* Logical router ingress table IP_INPUT: IP Input for IPv4. */
for (&RouterPort(.router = &router, .networks = networks, .lrp = lrp)
     if (not networks.ipv4_addrs.is_empty()))
{
    /* L3 admission control: drop packets that originate from an
     * IPv4 address owned by the router or a broadcast address
     * known to the router (priority 100). */
    var __match = "ip4.src == "                                  ++
                   format_v4_networks(networks, true)            ++
                   " && ${rEGBIT_EGRESS_LOOPBACK()} == 0" in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 100,
         .__match          = __match,
         .actions          = "drop;",
         .external_ids     = stage_hint(lrp._uuid));

    /* ICMP echo reply.  These flows reply to ICMP echo requests
     * received for the router's IP address. Since packets only
     * get here as part of the logical router datapath, the inport
     * (i.e. the incoming locally attached net) does not matter.
     * The ip.ttl also does not matter (RFC1812 section 4.2.2.9) */
    var __match = "ip4.dst == "                                  ++
                  format_v4_networks(networks, false)            ++
                  " && icmp4.type == 8 && icmp4.code == 0" in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 90,
         .__match          = __match,
         .actions          = "ip4.dst <-> ip4.src; "
                             "ip.ttl = 255; "
                             "icmp4.type = 0; "
                             "flags.loopback = 1; "
                             "next; ",
         .external_ids     = stage_hint(lrp._uuid))
}

/* Priority-90-92 flows handle ARP requests and ND packets. Most are
 * per logical port but DNAT addresses can be handled per datapath
 * for non gateway router ports.
 *
 * Priority 91 and 92 flows are added for each gateway router
 * port to handle the special cases. In case we get the packet
 * on a regular port, just reply with the port's ETH address.
 */
LogicalRouterNatArpNdFlow(router, nat) :-
    router in &Router(.lr = nb::Logical_Router{._uuid = lr}),
    LogicalRouterNAT(.lr = lr, .nat = nat@NAT{.nat = &nb::NAT{.__type = __type}}),
    /* Skip SNAT entries for now, we handle unique SNAT IPs separately
     * below.
     */
    __type != "snat".
/* Now handle SNAT entries too, one per unique SNAT IP. */
LogicalRouterNatArpNdFlow(router, nat) :-
    router in &Router(.snat_ips = snat_ips),
    var snat_ip = FlatMap(snat_ips),
    (var ip, var nats) = snat_ip,
    Some{var nat} = nats.nth(0).

relation LogicalRouterNatArpNdFlow(router: Ref<Router>, nat: NAT)
LogicalRouterArpNdFlow(router, nat, None, rEG_INPORT_ETH_ADDR(), None, false, 90) :-
    LogicalRouterNatArpNdFlow(router, nat).

/* ARP / ND handling for external IP addresses.
 *
 * DNAT and SNAT IP addresses are external IP addresses that need ARP
 * handling.
 *
 * These are already taken care globally, per router. The only
 * exception is on the l3dgw_port where we might need to use a
 * different ETH address.
 */
LogicalRouterPortNatArpNdFlow(router, nat, l3dgw_port) :-
    router in &Router(.lr = lr, .l3dgw_port = Some{l3dgw_port}),
    LogicalRouterNAT(lr._uuid, nat),
    /* Skip SNAT entries for now, we handle unique SNAT IPs separately
     * below.
     */
    nat.nat.__type != "snat".
/* Now handle SNAT entries too, one per unique SNAT IP. */
LogicalRouterPortNatArpNdFlow(router, nat, l3dgw_port) :-
    router in &Router(.l3dgw_port = Some{l3dgw_port}, .snat_ips = snat_ips),
    var snat_ip = FlatMap(snat_ips),
    (var ip, var nats) = snat_ip,
    Some{var nat} = nats.nth(0).

/* Respond to ARP/NS requests on the chassis that binds the gw
 * port. Drop the ARP/NS requests on other chassis.
 */
relation LogicalRouterPortNatArpNdFlow(router: Ref<Router>, nat: NAT, lrp: nb::Logical_Router_Port)
LogicalRouterArpNdFlow(router, nat, Some{lrp}, mac, Some{extra_match}, false, 92),
LogicalRouterArpNdFlow(router, nat, Some{lrp}, mac, None, true, 91) :-
    LogicalRouterPortNatArpNdFlow(router, nat, lrp),
    (var mac, var extra_match) = match ((nat.external_mac, nat.nat.logical_port)) {
        (Some{external_mac}, Some{logical_port}) -> (
            /* distributed NAT case, use nat->external_mac */
            external_mac.to_string(),
            /* Traffic with eth.src = nat->external_mac should only be
             * sent from the chassis where nat->logical_port is
             * resident, so that upstream MAC learning points to the
             * correct chassis.  Also need to avoid generation of
             * multiple ARP responses from different chassis. */
            "is_chassis_resident(${json_string_escape(logical_port)})"
        ),
        _ -> (
            rEG_INPORT_ETH_ADDR(),
            /* Traffic with eth.src = l3dgw_port->lrp_networks.ea_s
             * should only be sent from the gateway chassis, so that
             * upstream MAC learning points to the gateway chassis.
             * Also need to avoid generation of multiple ARP responses
             * from different chassis. */
            match (router.redirect_port_name) {
                "" -> "",
                s -> "is_chassis_resident(${s})"
            }
        )
    }.

/* Now divide the ARP/ND flows into ARP and ND. */
relation LogicalRouterArpNdFlow(
    router: Ref<Router>,
    nat: NAT,
    lrp: Option<nb::Logical_Router_Port>,
    mac: string,
    extra_match: Option<string>,
    drop: bool,
    priority: integer)
LogicalRouterArpFlow(router, lrp, ipv4, mac, extra_match, drop, priority,
                     stage_hint(nat.nat._uuid)) :-
    LogicalRouterArpNdFlow(router, nat@NAT{.external_ip = IPv4{ipv4}}, lrp,
                           mac, extra_match, drop, priority).
LogicalRouterNdFlow(router, lrp, "nd_na", ipv6, true, mac, extra_match, drop, priority,
                    stage_hint(nat.nat._uuid)) :-
    LogicalRouterArpNdFlow(router, nat@NAT{.external_ip = IPv6{ipv6}}, lrp,
                           mac, extra_match, drop, priority).

relation LogicalRouterArpFlow(
    lr: Ref<Router>,
    lrp: Option<nb::Logical_Router_Port>,
    ip: in_addr,
    mac: string,
    extra_match: Option<string>,
    drop: bool,
    priority: integer,
    external_ids: Map<string,string>)
Flow(.logical_datapath = lr.lr._uuid,
     .stage = s_ROUTER_IN_IP_INPUT(),
     .priority = priority,
     .__match = __match,
     .actions = actions,
     .external_ids = external_ids) :-
    LogicalRouterArpFlow(.lr = lr, .lrp = lrp, .ip = ip, .mac = mac,
                         .extra_match = extra_match, .drop = drop,
                         .priority = priority, .external_ids = external_ids),
    var __match = {
        var clauses = vec_with_capacity(3);
        match (lrp) {
            Some{p} -> clauses.push("inport == ${json_string_escape(p.name)}"),
            None -> ()
        };
        clauses.push("arp.op == 1 && arp.tpa == ${ip}");
        clauses.append(extra_match.to_vec());
        clauses.join(" && ")
    },
    var actions = if (drop) {
       "drop;"
    } else {
        "eth.dst = eth.src; "
        "eth.src = ${mac}; "
        "arp.op = 2; /* ARP reply */ "
        "arp.tha = arp.sha; "
        "arp.sha = ${mac}; "
        "arp.tpa = arp.spa; "
        "arp.spa = ${ip}; "
        "outport = inport; "
        "flags.loopback = 1; "
        "output;"
    }.

relation LogicalRouterNdFlow(
    lr: Ref<Router>,
    lrp: Option<nb::Logical_Router_Port>,
    action: string,
    ip: in6_addr,
    sn_ip: bool,
    mac: string,
    extra_match: Option<string>,
    drop: bool,
    priority: integer,
    external_ids: Map<string,string>)
Flow(.logical_datapath = lr.lr._uuid,
     .stage = s_ROUTER_IN_IP_INPUT(),
     .priority = priority,
     .__match = __match,
     .actions = actions,
     .external_ids = external_ids) :-
    LogicalRouterNdFlow(.lr = lr, .lrp = lrp, .action = action, .ip = ip,
                        .sn_ip = sn_ip, .mac = mac, .extra_match = extra_match,
                        .drop = drop, .priority = priority,
                        .external_ids = external_ids),
    var __match = {
        var clauses = vec_with_capacity(4);
        match (lrp) {
            Some{p} -> clauses.push("inport == ${json_string_escape(p.name)}"),
            None -> ()
        };
        if (sn_ip) {
            clauses.push("ip6.dst == {${ip}, ${ip.solicited_node()}}")
        };
        clauses.push("nd_ns && nd.target == ${ip}");
        clauses.append(extra_match.to_vec());
        clauses.join(" && ")
    },
    var actions = if (drop) {
        "drop;"
    } else {
        "${action} { "
          "eth.src = ${mac}; "
          "ip6.src = ${ip}; "
          "nd.target = ${ip}; "
          "nd.tll = ${mac}; "
          "outport = inport; "
          "flags.loopback = 1; "
          "output; "
        "};"
    }.

/* ICMP time exceeded */
for (RouterPortNetworksIPv4Addr(.port = &RouterPort{.lrp = lrp,
                                                    .json_name = json_name,
                                                    .router = router,
                                                    .networks = networks,
                                                    .is_redirect = is_redirect},
                                .addr = addr))
{
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 40,
         .__match          = "inport == ${json_name} && ip4 && "
                             "ip.ttl == {0, 1} && !ip.later_frag",
         .actions          = "icmp4 {"
                             "eth.dst <-> eth.src; "
                             "icmp4.type = 11; /* Time exceeded */ "
                             "icmp4.code = 0; /* TTL exceeded in transit */ "
                             "ip4.dst = ip4.src; "
                             "ip4.src = ${addr.addr}; "
                             "ip.ttl = 255; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    /* ARP reply.  These flows reply to ARP requests for the router's own
     * IP address. */
    for (AddChassisResidentCheck(lrp._uuid, add_chassis_resident_check)) {
        var __match =
            "arp.spa == ${addr.match_network()}" ++
            if (add_chassis_resident_check) {
                " && is_chassis_resident(${router.redirect_port_name})"
            } else "" in
        LogicalRouterArpFlow(.lr = router,
                             .lrp = Some{lrp},
                             .ip = addr.addr,
                             .mac = rEG_INPORT_ETH_ADDR(),
                             .extra_match = Some{__match},
                             .drop = false,
                             .priority = 90,
                             .external_ids = stage_hint(lrp._uuid))
    }
}

for (&RouterPort(.lrp = lrp,
                 .router = router@&Router{.lr = lr},
                 .json_name = json_name,
                 .networks = networks,
                 .is_redirect = is_redirect))
var residence_check = match (is_redirect) {
    true -> Some{"is_chassis_resident(${router.redirect_port_name})"},
    false -> None
} in {
    for (RouterLBVIP(.router = &Router{.lr = nb::Logical_Router{._uuid= lr._uuid}}, .vip = vip)) {
        Some{(var ip_address, _)} = ip_address_and_port_from_lb_key(vip) in {
            IPv4{var ipv4} = ip_address in
            LogicalRouterArpFlow(.lr = router,
                                 .lrp = Some{lrp},
                                 .ip = ipv4,
                                 .mac = rEG_INPORT_ETH_ADDR(),
                                 .extra_match = residence_check,
                                 .drop = false,
                                 .priority = 90,
                                 .external_ids = map_empty());

            IPv6{var ipv6} = ip_address in
            LogicalRouterNdFlow(.lr = router,
                                .lrp = Some{lrp},
                                .action = "nd_na",
                                .ip = ipv6,
                                .sn_ip = false,
                                .mac = rEG_INPORT_ETH_ADDR(),
                                .extra_match = residence_check,
                                .drop = false,
                                .priority = 90,
                                .external_ids = map_empty())
        }
    }
}

/* Drop IP traffic destined to router owned IPs except if the IP is
 * also a SNAT IP. Those are dropped later, in stage
 * "lr_in_arp_resolve", if unSNAT was unsuccessful.
 *
 * Priority 60.
 */
Flow(.logical_datapath = lr_uuid,
     .stage = s_ROUTER_IN_IP_INPUT(),
     .priority = 60,
     .__match = "ip4.dst == {" ++ match_ips.join(", ") ++ "}",
     .actions = "drop;",
     .external_ids = stage_hint(lrp_uuid)) :-
    &RouterPort(.lrp = nb::Logical_Router_Port{._uuid = lrp_uuid},
                .router = &Router{.snat_ips = snat_ips,
                                  .force_lb_snat = false,
                                  .lr = nb::Logical_Router{._uuid = lr_uuid}},
                .networks = networks),
    var addr = FlatMap(networks.ipv4_addrs),
    not snat_ips.contains_key(IPv4{addr.addr}),
    var match_ips = "${addr.addr}".group_by((lr_uuid, lrp_uuid)).to_vec().
Flow(.logical_datapath = lr_uuid,
     .stage = s_ROUTER_IN_IP_INPUT(),
     .priority = 60,
     .__match = "ip6.dst == {" ++ match_ips.join(", ") ++ "}",
     .actions = "drop;",
     .external_ids = stage_hint(lrp_uuid)) :-
    &RouterPort(.lrp = nb::Logical_Router_Port{._uuid = lrp_uuid},
                .router = &Router{.snat_ips = snat_ips,
                                  .force_lb_snat = false,
                                  .lr = nb::Logical_Router{._uuid = lr_uuid}},
                .networks = networks),
    var addr = FlatMap(networks.ipv6_addrs),
    not snat_ips.contains_key(IPv6{addr.addr}),
    var match_ips = "${addr.addr}".group_by((lr_uuid, lrp_uuid)).to_vec().

for (RouterPortNetworksIPv4Addr(
        .port = &RouterPort{
            .router = &Router{.lr = lr,
                              .l3dgw_port = None,
                              .is_gateway = false},
            .lrp = lrp},
         .addr = addr))
{
    /* UDP/TCP/SCTP port unreachable. */
    var __match = "ip4 && ip4.dst == ${addr.addr} && !ip.later_frag && udp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 80,
         .__match          = __match,
         .actions          = "icmp4 {"
                             "eth.dst <-> eth.src; "
                             "ip4.dst <-> ip4.src; "
                             "ip.ttl = 255; "
                             "icmp4.type = 3; "
                             "icmp4.code = 3; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip4 && ip4.dst == ${addr.addr} && !ip.later_frag && tcp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 80,
         .__match          = __match,
         .actions          = "tcp_reset {"
                             "eth.dst <-> eth.src; "
                             "ip4.dst <-> ip4.src; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip4 && ip4.dst == ${addr.addr} && !ip.later_frag && sctp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 80,
         .__match          = __match,
         .actions          = "sctp_abort {"
                             "eth.dst <-> eth.src; "
                             "ip4.dst <-> ip4.src; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip4 && ip4.dst == ${addr.addr} && !ip.later_frag" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 70,
         .__match          = __match,
         .actions          = "icmp4 {"
                             "eth.dst <-> eth.src; "
                             "ip4.dst <-> ip4.src; "
                             "ip.ttl = 255; "
                             "icmp4.type = 3; "
                             "icmp4.code = 2; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid))
}

/* DHCPv6 reply handling */
Flow(.logical_datapath = rp.router.lr._uuid,
     .stage            = s_ROUTER_IN_IP_INPUT(),
     .priority         = 100,
     .__match          = "ip6.dst == ${ipv6_addr.addr} "
                         "&& udp.src == 547 && udp.dst == 546",
     .actions          = "reg0 = 0; handle_dhcpv6_reply;",
     .external_ids     = stage_hint(rp.lrp._uuid)) :-
    rp in &RouterPort(),
    var ipv6_addr = FlatMap(rp.networks.ipv6_addrs).

/* Logical router ingress table IP_INPUT: IP Input for IPv6. */
for (&RouterPort(.router = &router, .networks = networks, .lrp = lrp)
     if (not networks.ipv6_addrs.is_empty()))
{
    //if (op->derived) {
    //    /* No ingress packets are accepted on a chassisredirect
    //     * port, so no need to program flows for that port. */
    //    continue;
    //}

    /* ICMPv6 echo reply.  These flows reply to echo requests
     * received for the router's IP address. */
    var __match = "ip6.dst == "                   ++
                  format_v6_networks(networks)    ++
                  " && icmp6.type == 128 && icmp6.code == 0" in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 90,
         .__match          = __match,
         .actions          = "ip6.dst <-> ip6.src; "
         "ip.ttl = 255; "
         "icmp6.type = 129; "
         "flags.loopback = 1; "
         "next; ",
         .external_ids     = stage_hint(lrp._uuid))
}

/* ND reply.  These flows reply to ND solicitations for the
 * router's own IP address. */
for (RouterPortNetworksIPv6Addr(.port = &RouterPort{.lrp = lrp,
                                                    .is_redirect = is_redirect,
                                                    .router = router,
                                                    .networks = networks,
                                                    .json_name = json_name},
                                .addr = addr))
{
    var extra_match = if (is_redirect) {
        /* Traffic with eth.src = l3dgw_port->lrp_networks.ea
         * should only be sent from the gateway chassis, so that
         * upstream MAC learning points to the gateway chassis.
         * Also need to avoid generation of multiple ND replies
         * from different chassis. */
        Some{"is_chassis_resident(${json_string_escape(chassis_redirect_name(lrp.name))})"}
    } else None in
    LogicalRouterNdFlow(.lr = router,
                        .lrp = Some{lrp},
                        .action = "nd_na_router",
                        .ip = addr.addr,
                        .sn_ip = true,
                        .mac = rEG_INPORT_ETH_ADDR(),
                        .extra_match = extra_match,
                        .drop = false,
                        .priority = 90,
                        .external_ids = stage_hint(lrp._uuid))
}

/* UDP/TCP/SCTP port unreachable */
for (RouterPortNetworksIPv6Addr(
        .port = &RouterPort{.router = &Router{.lr = lr,
                                              .l3dgw_port = None,
                                              .is_gateway = false},
                            .lrp = lrp,
                            .json_name = json_name},
        .addr = addr))
{
    var __match = "ip6 && ip6.dst == ${addr.addr} && !ip.later_frag && tcp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 80,
         .__match          = __match,
         .actions          = "tcp_reset {"
                             "eth.dst <-> eth.src; "
                             "ip6.dst <-> ip6.src; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip6 && ip6.dst == ${addr.addr} && !ip.later_frag && sctp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 80,
         .__match          = __match,
         .actions          = "sctp_abort {"
                             "eth.dst <-> eth.src; "
                             "ip6.dst <-> ip6.src; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip6 && ip6.dst == ${addr.addr} && !ip.later_frag && udp" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 80,
         .__match          = __match,
         .actions          = "icmp6 {"
                             "eth.dst <-> eth.src; "
                             "ip6.dst <-> ip6.src; "
                             "ip.ttl = 255; "
                             "icmp6.type = 1; "
                             "icmp6.code = 4; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid));

    var __match = "ip6 && ip6.dst == ${addr.addr} && !ip.later_frag" in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 70,
         .__match          = __match,
         .actions          = "icmp6 {"
                             "eth.dst <-> eth.src; "
                             "ip6.dst <-> ip6.src; "
                             "ip.ttl = 255; "
                             "icmp6.type = 1; "
                             "icmp6.code = 3; "
                             "next; };",
         .external_ids     = stage_hint(lrp._uuid))
}

/* ICMPv6 time exceeded */
for (RouterPortNetworksIPv6Addr(.port = &RouterPort{.router = &router,
                                                    .lrp = lrp,
                                                    .json_name = json_name},
                                .addr = addr)
     /* skip link-local address */
     if (not addr.is_lla()))
{
    var __match = "inport == ${json_name} && ip6 && "
                  "ip6.src == ${addr.match_network()} && "
                  "ip.ttl == {0, 1} && !ip.later_frag" in
    var actions = "icmp6 {"
                  "eth.dst <-> eth.src; "
                  "ip6.dst = ip6.src; "
                  "ip6.src = ${addr.addr}; "
                  "ip.ttl = 255; "
                  "icmp6.type = 3; /* Time exceeded */ "
                  "icmp6.code = 0; /* TTL exceeded in transit */ "
                  "next; };" in
    Flow(.logical_datapath = router.lr._uuid,
         .stage            = s_ROUTER_IN_IP_INPUT(),
         .priority         = 40,
         .__match          = __match,
         .actions          = actions,
         .external_ids     = stage_hint(lrp._uuid))
}

/* NAT, Defrag and load balancing. */

function default_allow_flow(datapath: uuid, stage: Stage): Flow {
    Flow{.logical_datapath = datapath,
         .stage            = stage,
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty()}
}
for (&Router(.lr = lr)) {
    /* Packets are allowed by default. */
    Flow[default_allow_flow(lr._uuid, s_ROUTER_IN_DEFRAG())];
    Flow[default_allow_flow(lr._uuid, s_ROUTER_IN_UNSNAT())];
    Flow[default_allow_flow(lr._uuid, s_ROUTER_OUT_SNAT())];
    Flow[default_allow_flow(lr._uuid, s_ROUTER_IN_DNAT())];
    Flow[default_allow_flow(lr._uuid, s_ROUTER_OUT_UNDNAT())];
    Flow[default_allow_flow(lr._uuid, s_ROUTER_OUT_EGR_LOOP())];
    Flow[default_allow_flow(lr._uuid, s_ROUTER_IN_ECMP_STATEFUL())];

    /* Send the IPv6 NS packets to next table. When ovn-controller
     * generates IPv6 NS (for the action - nd_ns{}), the injected
     * packet would go through conntrack - which is not required. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_OUT_SNAT(),
         .priority         = 120,
         .__match          = "nd_ns",
         .actions          = "next;",
         .external_ids     = map_empty())
}

function lrouter_nat_is_stateless(nat: NAT): bool = {
    Some{"true"} == nat.nat.options.get("stateless")
}

/* Handles the match criteria and actions in logical flow
 * based on external ip based NAT rule filter.
 *
 * For ALLOWED_EXT_IPs, we will add an additional match criteria
 * of comparing ip*.src/dst with the allowed external ip address set.
 *
 * For EXEMPTED_EXT_IPs, we will have an additional logical flow
 * where we compare ip*.src/dst with the exempted external ip address set
 * and action says "next" instead of ct*.
 */
function lrouter_nat_add_ext_ip_match(
    router: Ref<Router>,
    nat: NAT,
    __match: string,
    ipX: string,
    is_src: bool,
    mask: v46_ip): (string, Option<Flow>)
{
    var dir = if (is_src) "src" else "dst";
    match (nat.exceptional_ext_ips) {
        None -> ("", None),
        Some{AllowedExtIps{__as}} -> (" && ${ipX}.${dir} == $${__as.name}", None),
        Some{ExemptedExtIps{__as}} -> {
            /* Priority of logical flows corresponding to exempted_ext_ips is
             * +1 of the corresponding regulr NAT rule.
             * For example, if we have following NAT rule and we associate
             * exempted external ips to it:
             * "ovn-nbctl lr-nat-add router dnat_and_snat 10.15.24.139 50.0.0.11"
             *
             * And now we associate exempted external ip address set to it.
             * Now corresponding to above rule we will have following logical
             * flows:
             * lr_out_snat...priority=162, match=(..ip4.dst == $exempt_range),
             *                             action=(next;)
             * lr_out_snat...priority=161, match=(..), action=(ct_snat(....);)
             *
             */
            var priority = match (is_src) {
                true -> {
                    /* S_ROUTER_IN_DNAT uses priority 100 */
                    100 + 1
                },
                false -> {
                    /* S_ROUTER_OUT_SNAT uses priority (mask + 1 + 128 + 1) */
                    var is_gw_router = router.l3dgw_port == None;
                    var mask_1bits = mask.cidr_bits().unwrap_or(8'd0) as integer;
                    mask_1bits + 2 + { if (not is_gw_router) 128 else 0 }
                }
            };

            ("",
             Some{Flow{.logical_datapath = router.lr._uuid,
                       .stage = if (is_src) { s_ROUTER_IN_DNAT() } else { s_ROUTER_OUT_SNAT() },
                       .priority = priority,
                       .__match = "${__match} && ${ipX}.${dir} == $${__as.name}",
                       .actions = "next;",
                       .external_ids = stage_hint(nat.nat._uuid)}})
        }
    }
}

relation LogicalRouterForceSnatFlows(
    logical_router: uuid,
    ips: Set<v46_ip>,
    context: string)
Flow(.logical_datapath = logical_router,
     .stage = s_ROUTER_IN_UNSNAT(),
     .priority = 110,
     .__match = "${ipX} && ${ipX}.dst == ${ip}",
     .actions = "ct_snat;",
     .external_ids = map_empty()),
/* Higher priority rules to force SNAT with the IP addresses
 * configured in the Gateway router.  This only takes effect
 * when the packet has already been DNATed or load balanced once. */
Flow(.logical_datapath = logical_router,
     .stage = s_ROUTER_OUT_SNAT(),
     .priority = 100,
     .__match = "flags.force_snat_for_${context} == 1 && ${ipX}",
     .actions = "ct_snat(${ip});",
     .external_ids = map_empty()) :-
    LogicalRouterForceSnatFlows(.logical_router = logical_router,
                                .ips = ips,
                                .context = context),
    var ip = FlatMap(ips),
    var ipX = ip.ipX().

/* Higher priority rules to force SNAT with the router port ip.
 * This only takes effect when the packet has already been
 * load balanced once. */
for (rp in &RouterPort(.router = &Router{.lr = lr}, .lrp = lrp)) {
    if (lb_force_snat_router_ip(lr.options) and rp.peer != PeerNone) {
        Some{var ipv4} = rp.networks.ipv4_addrs.nth(0) in {
            Flow(.logical_datapath = lr._uuid,
                 .stage = s_ROUTER_IN_UNSNAT(),
                 .priority = 110,
                 .__match = "inport == ${rp.json_name} && ip4.dst == ${ipv4.addr}",
                 .actions = "ct_snat;",
                 .external_ids = map_empty());

            Flow(.logical_datapath = lr._uuid,
                 .stage = s_ROUTER_OUT_SNAT(),
                 .priority = 110,
                 .__match = "flags.force_snat_for_lb == 1 && ip4 && outport == ${rp.json_name}",
                 .actions = "ct_snat(${ipv4.addr});",
                 .external_ids = map_empty());

            if (rp.networks.ipv4_addrs.len() > 1) {
                Warning["Logical router port ${rp.json_name} is configured with multiple IPv4 "
                        "addresses.  Only the first IP [${ipv4.addr}] is considered as SNAT for "
                        "load balancer"]
            }
        };

        /* op->lrp_networks.ipv6_addrs will always have LLA and that will be
         * last in the list. So add the flows only if n_ipv6_addrs > 1. */
        if (rp.networks.ipv6_addrs.len() > 1) {
            Some{var ipv6} = rp.networks.ipv6_addrs.nth(0) in {
                Flow(.logical_datapath = lr._uuid,
                     .stage = s_ROUTER_IN_UNSNAT(),
                     .priority = 110,
                     .__match = "inport == ${rp.json_name} && ip6.dst == ${ipv6.addr}",
                     .actions = "ct_snat;",
                     .external_ids = map_empty());

                Flow(.logical_datapath = lr._uuid,
                     .stage = s_ROUTER_OUT_SNAT(),
                     .priority = 110,
                     .__match = "flags.force_snat_for_lb == 1 && ip6 && outport == ${rp.json_name}",
                     .actions = "ct_snat(${ipv6.addr});",
                     .external_ids = map_empty());

                if (rp.networks.ipv6_addrs.len() > 2) {
                    Warning["Logical router port ${rp.json_name} is configured with multiple IPv6 "
                            "addresses.  Only the first IP [${ipv6.addr}] is considered as SNAT for "
                            "load balancer"]
                }
            }
        }
    }
}

/* NAT rules are only valid on Gateway routers and routers with
 * l3dgw_port (router has a port with "redirect-chassis"
 * specified). */
for (r in &Router(.lr = lr,
                  .l3dgw_port = l3dgw_port,
                  .redirect_port_name = redirect_port_name,
                  .is_gateway = is_gateway)
     if l3dgw_port.is_some() or is_gateway)
{
    for (LogicalRouterNAT(.lr = lr._uuid, .nat = nat)) {
        var ipX = nat.external_ip.ipX() in
        var xx = nat.external_ip.xxreg() in
        /* Check the validity of nat->logical_ip. 'logical_ip' can
         * be a subnet when the type is "snat". */
        Some{(_, var mask)} = ip46_parse_masked(nat.nat.logical_ip) in
        true == match ((mask.is_all_ones(), nat.nat.__type)) {
            (_, "snat") -> true,
            (false, _) -> {
                warn("bad ip ${nat.nat.logical_ip} for dnat in router ${uuid2str(lr._uuid)}");
                false
            },
            _ -> true
        } in
        /* For distributed router NAT, determine whether this NAT rule
         * satisfies the conditions for distributed NAT processing. */
        var mac = match ((l3dgw_port.is_some() and nat.nat.__type == "dnat_and_snat",
                          nat.nat.logical_port, nat.external_mac)) {
            (true, Some{_}, Some{mac}) -> Some{mac},
            _ -> None
        } in
        var stateless = (lrouter_nat_is_stateless(nat)
                         and nat.nat.__type == "dnat_and_snat") in
        {
            /* Ingress UNSNAT table: It is for already established connections'
             * reverse traffic. i.e., SNAT has already been done in egress
             * pipeline and now the packet has entered the ingress pipeline as
             * part of a reply. We undo the SNAT here.
             *
             * Undoing SNAT has to happen before DNAT processing.  This is
             * because when the packet was DNATed in ingress pipeline, it did
             * not know about the possibility of eventual additional SNAT in
             * egress pipeline. */
            if (nat.nat.__type == "snat" or nat.nat.__type == "dnat_and_snat") {
                if (l3dgw_port == None) {
                    /* Gateway router. */
                    var actions = if (stateless) {
                        "${ipX}.dst=${nat.nat.logical_ip}; next;"
                    } else {
                        "ct_snat;"
                    } in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = s_ROUTER_IN_UNSNAT(),
                         .priority         = 90,
                         .__match          = "ip && ${ipX}.dst == ${nat.nat.external_ip}",
                         .actions          = actions,
                         .external_ids     = stage_hint(nat.nat._uuid))
                };
                Some{var gwport} = l3dgw_port in {
                    /* Distributed router. */

                    /* Traffic received on l3dgw_port is subject to NAT. */
                    var __match =
                        "ip && ${ipX}.dst == ${nat.nat.external_ip}"
                        " && inport == ${json_string_escape(gwport.name)}" ++
                        if (mac == None) {
                            /* Flows for NAT rules that are centralized are only
                             * programmed on the "redirect-chassis". */
                            " && is_chassis_resident(${redirect_port_name})"
                        } else { "" } in
                    var actions = if (stateless) {
                        "${ipX}.dst=${nat.nat.logical_ip}; next;"
                    } else {
                        "ct_snat;"
                    } in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = s_ROUTER_IN_UNSNAT(),
                         .priority         = 100,
                         .__match          = __match,
                         .actions          = actions,
                         .external_ids     = stage_hint(nat.nat._uuid))
                }
            };

            /* Ingress DNAT table: Packets enter the pipeline with destination
             * IP address that needs to be DNATted from a external IP address
             * to a logical IP address. */
            var ip_and_ports = "${nat.nat.logical_ip}" ++
                               if (nat.nat.external_port_range != "") {
                                   " ${nat.nat.external_port_range}"
                               } else {
                                   ""
                               } in
            if (nat.nat.__type == "dnat" or nat.nat.__type == "dnat_and_snat") {
                None = l3dgw_port in
                var __match = "ip && ip4.dst == ${nat.nat.external_ip}" in
                (var ext_ip_match, var ext_flow) = lrouter_nat_add_ext_ip_match(
                    r, nat, __match, ipX, true, mask) in
                {
                    /* Gateway router. */
                    /* Packet when it goes from the initiator to destination.
                     * We need to set flags.loopback because the router can
                     * send the packet back through the same interface. */
                    Some{var f} = ext_flow in Flow[f];

                    var flag_action =
                        if (has_force_snat_ip(lr, "dnat")) {
                            /* Indicate to the future tables that a DNAT has taken
                             * place and a force SNAT needs to be done in the
                             * Egress SNAT table. */
                            "flags.force_snat_for_dnat = 1; "
                        } else { "" } in
                    var nat_actions = if (stateless) {
                        "${ipX}.dst=${nat.nat.logical_ip}; next;"
                    } else {
                        "flags.loopback = 1; "
                        "ct_dnat(${ip_and_ports});"
                    } in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = s_ROUTER_IN_DNAT(),
                         .priority         = 100,
                         .__match          = __match ++ ext_ip_match,
                         .actions          = flag_action ++ nat_actions,
                         .external_ids     = stage_hint(nat.nat._uuid))
                };

                Some{var gwport} = l3dgw_port in
                var __match =
                    "ip && ${ipX}.dst == ${nat.nat.external_ip}"
                    " && inport == ${json_string_escape(gwport.name)}" ++
                    if (mac == None) {
                        /* Flows for NAT rules that are centralized are only
                         * programmed on the "redirect-chassis". */
                        " && is_chassis_resident(${redirect_port_name})"
                    } else { "" } in
                (var ext_ip_match, var ext_flow) = lrouter_nat_add_ext_ip_match(
                    r, nat, __match, ipX, true, mask) in
                {
                    /* Distributed router. */
                    /* Traffic received on l3dgw_port is subject to NAT. */
                    Some{var f} = ext_flow in Flow[f];

                    var actions = if (stateless) {
                        "${ipX}.dst=${nat.nat.logical_ip}; next;"
                    } else {
                        "ct_dnat(${ip_and_ports});"
                    } in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = s_ROUTER_IN_DNAT(),
                         .priority         = 100,
                         .__match          = __match ++ ext_ip_match,
                         .actions          = actions,
                         .external_ids     = stage_hint(nat.nat._uuid))
                }
            };

            /* ARP resolve for NAT IPs. */
            Some{var gwport} = l3dgw_port in {
            var gwport_name = json_string_escape(gwport.name) in {
                if (nat.nat.__type == "snat") {
                    var __match = "inport == ${gwport_name} && "
                                  "${ipX}.src == ${nat.nat.external_ip}" in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = s_ROUTER_IN_IP_INPUT(),
                         .priority         = 120,
                         .__match          = __match,
                         .actions          = "next;",
                         .external_ids     = stage_hint(nat.nat._uuid))
                };

                var nexthop_reg = "${xx}${rEG_NEXT_HOP()}" in
                var __match = "outport == ${gwport_name} && "
                              "${nexthop_reg} == ${nat.nat.external_ip}" in
                var dst_mac = match (mac) {
                    Some{value} -> "${value}",
                    None -> gwport.mac
                } in
                Flow(.logical_datapath = lr._uuid,
                     .stage            = s_ROUTER_IN_ARP_RESOLVE(),
                     .priority         = 100,
                     .__match          = __match,
                     .actions          = "eth.dst = ${dst_mac}; next;",
                     .external_ids     = stage_hint(nat.nat._uuid))
                }
            };

            /* Egress UNDNAT table: It is for already established connections'
             * reverse traffic. i.e., DNAT has already been done in ingress
             * pipeline and now the packet has entered the egress pipeline as
             * part of a reply. We undo the DNAT here.
             *
             * Note that this only applies for NAT on a distributed router.
             * Undo DNAT on a gateway router is done in the ingress DNAT
             * pipeline stage. */
            if ((nat.nat.__type == "dnat" or nat.nat.__type == "dnat_and_snat")) {
                Some{var gwport} = l3dgw_port in
                var __match =
                    "ip && ${ipX}.src == ${nat.nat.logical_ip}"
                    " && outport == ${json_string_escape(gwport.name)}" ++
                    if (mac == None) {
                        /* Flows for NAT rules that are centralized are only
                         * programmed on the "redirect-chassis". */
                        " && is_chassis_resident(${redirect_port_name})"
                    } else { "" } in
                var actions =
                    match (mac) {
                        Some{mac_addr} -> "eth.src = ${mac_addr}; ",
                        None -> ""
                    } ++
                    if (stateless) {
                        "${ipX}.src=${nat.nat.external_ip}; next;"
                    } else {
                        "ct_dnat;"
                    } in
                Flow(.logical_datapath = lr._uuid,
                     .stage            = s_ROUTER_OUT_UNDNAT(),
                     .priority         = 100,
                     .__match          = __match,
                     .actions          = actions,
                     .external_ids     = stage_hint(nat.nat._uuid))
            };

            /* Egress SNAT table: Packets enter the egress pipeline with
             * source ip address that needs to be SNATted to a external ip
             * address. */
            var ip_and_ports = "${nat.nat.external_ip}" ++
                               if (nat.nat.external_port_range != "") {
                                   " ${nat.nat.external_port_range}"
                               } else {
                                   ""
                               } in
            if (nat.nat.__type == "snat" or nat.nat.__type == "dnat_and_snat") {
                None = l3dgw_port in
                var __match = "ip && ${ipX}.src == ${nat.nat.logical_ip}" in
                (var ext_ip_match, var ext_flow) = lrouter_nat_add_ext_ip_match(
                    r, nat, __match, ipX, false, mask) in
                {
                    /* Gateway router. */
                    Some{var f} = ext_flow in Flow[f];

                    /* The priority here is calculated such that the
                     * nat->logical_ip with the longest mask gets a higher
                     * priority. */
                    var actions = if (stateless) {
                        "${ipX}.src=${nat.nat.external_ip}; next;"
                    } else {
                        "ct_snat(${ip_and_ports});"
                    } in
                    Some{var plen} = mask.cidr_bits() in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = s_ROUTER_OUT_SNAT(),
                         .priority         = plen as bit<64> + 1,
                         .__match          = __match ++ ext_ip_match,
                         .actions          = actions,
                         .external_ids     = stage_hint(nat.nat._uuid))
                };

                Some{var gwport} = l3dgw_port in
                var __match =
                    "ip && ${ipX}.src == ${nat.nat.logical_ip}"
                    " && outport == ${json_string_escape(gwport.name)}" ++
                    if (mac == None) {
                        /* Flows for NAT rules that are centralized are only
                         * programmed on the "redirect-chassis". */
                        " && is_chassis_resident(${redirect_port_name})"
                    } else { "" } in
                (var ext_ip_match, var ext_flow) = lrouter_nat_add_ext_ip_match(
                    r, nat, __match, ipX, false, mask) in
                {
                    /* Distributed router. */
                    Some{var f} = ext_flow in Flow[f];

                    var actions =
                        match (mac) {
                            Some{mac_addr} -> "eth.src = ${mac_addr}; ",
                            _ -> ""
                        } ++ if (stateless) {
                            "${ipX}.src=${nat.nat.external_ip}; next;"
                        } else {
                            "ct_snat(${ip_and_ports});"
                        } in
                    /* The priority here is calculated such that the
                     * nat->logical_ip with the longest mask gets a higher
                     * priority. */
                    Some{var plen} = mask.cidr_bits() in
                    var priority = (plen as bit<64>) + 1 in
                    var centralized_boost = if (mac == None) 128 else 0 in
                    Flow(.logical_datapath = lr._uuid,
                         .stage            = s_ROUTER_OUT_SNAT(),
                         .priority         = priority + centralized_boost,
                         .__match          = __match ++ ext_ip_match,
                         .actions          = actions,
                         .external_ids     = stage_hint(nat.nat._uuid))
                }
            };

            /* Logical router ingress table ADMISSION:
             * For NAT on a distributed router, add rules allowing
             * ingress traffic with eth.dst matching nat->external_mac
             * on the l3dgw_port instance where nat->logical_port is
             * resident. */
            Some{var mac_addr} = mac in
            Some{var gwport} = l3dgw_port in
            Some{var logical_port} = nat.nat.logical_port in
            var __match =
                "eth.dst == ${mac_addr} && inport == ${json_string_escape(gwport.name)}"
                " && is_chassis_resident(${json_string_escape(logical_port)})" in
            /* Store the ethernet address of the port receiving the packet.
             * This will save us from having to match on inport further
             * down in the pipeline.
             */
            var actions = "${rEG_INPORT_ETH_ADDR()} = ${gwport.mac}; next;" in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = s_ROUTER_IN_ADMISSION(),
                 .priority         = 50,
                 .__match          = __match,
                 .actions          = actions,
                 .external_ids     = stage_hint(nat.nat._uuid));

            /* Ingress Gateway Redirect Table: For NAT on a distributed
             * router, add flows that are specific to a NAT rule.  These
             * flows indicate the presence of an applicable NAT rule that
             * can be applied in a distributed manner.
             * In particulr the IP src register and eth.src are set to NAT external IP and
             * NAT external mac so the ARP request generated in the following
             * stage is sent out with proper IP/MAC src addresses
             */
            Some{var mac_addr} = mac in
            Some{var gwport} = l3dgw_port in
            Some{var logical_port} = nat.nat.logical_port in
            Some{var external_mac} = nat.nat.external_mac in
            var __match =
                "${ipX}.src == ${nat.nat.logical_ip} && "
                "outport == ${json_string_escape(gwport.name)} && "
                "is_chassis_resident(${json_string_escape(logical_port)})" in
            var actions =
                "eth.src = ${external_mac}; "
                "${xx}${rEG_SRC()} = ${nat.nat.external_ip}; "
                "next;" in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = s_ROUTER_IN_GW_REDIRECT(),
                 .priority         = 100,
                 .__match          = __match,
                 .actions          = actions,
                 .external_ids     = stage_hint(nat.nat._uuid));

            /* Egress Loopback table: For NAT on a distributed router.
             * If packets in the egress pipeline on the distributed
             * gateway port have ip.dst matching a NAT external IP, then
             * loop a clone of the packet back to the beginning of the
             * ingress pipeline with inport = outport. */
            Some{var gwport} = l3dgw_port in
            /* Distributed router. */
            Some{var port} = match (mac) {
                Some{_} -> match (nat.nat.logical_port) {
                               Some{name} -> Some{json_string_escape(name)},
                               None -> None: Option<string>
                           },
                None -> Some{redirect_port_name}
            } in
            var __match = "${ipX}.dst == ${nat.nat.external_ip} && outport == ${json_string_escape(gwport.name)} && is_chassis_resident(${port})" in
            var regs = {
                var regs = vec_empty();
                for (j in range_vec(0, mFF_N_LOG_REGS(), 01)) {
                    regs.push("reg${j} = 0; ")
                };
                regs
            } in
            var actions =
                "clone { ct_clear; "
                "inport = outport; outport = \"\"; "
                "flags = 0; flags.loopback = 1; " ++
                regs.join("") ++
                "${rEGBIT_EGRESS_LOOPBACK()} = 1; "
                "next(pipeline=ingress, table=0); };" in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = s_ROUTER_OUT_EGR_LOOP(),
                 .priority         = 100,
                 .__match          = __match,
                 .actions          = actions,
                 .external_ids     = stage_hint(nat.nat._uuid))
        }
    };

    /* Handle force SNAT options set in the gateway router. */
    if (l3dgw_port == None) {
        var dnat_force_snat_ips = get_force_snat_ip(lr, "dnat") in
        if (not dnat_force_snat_ips.is_empty())
        LogicalRouterForceSnatFlows(.logical_router = lr._uuid,
                                    .ips = dnat_force_snat_ips,
                                    .context = "dnat");

        var lb_force_snat_ips = get_force_snat_ip(lr, "lb") in
        if (not lb_force_snat_ips.is_empty())
        LogicalRouterForceSnatFlows(.logical_router = lr._uuid,
                                    .ips = lb_force_snat_ips,
                                    .context = "lb");

       /* For gateway router, re-circulate every packet through
        * the DNAT zone.  This helps with the following.
        *
        * Any packet that needs to be unDNATed in the reverse
        * direction gets unDNATed. Ideally this could be done in
        * the egress pipeline. But since the gateway router
        * does not have any feature that depends on the source
        * ip address being external IP address for IP routing,
        * we can do it here, saving a future re-circulation. */
        Flow(.logical_datapath = lr._uuid,
             .stage            = s_ROUTER_IN_DNAT(),
             .priority         = 50,
             .__match          = "ip",
             .actions          = "flags.loopback = 1; ct_dnat;",
             .external_ids     = map_empty())
    }
}

function nats_contain_vip(nats: Vec<NAT>, vip: v46_ip): bool {
    for (nat in nats) {
        if (nat.external_ip == vip) {
            return true
        }
    };
    return false
}

/* Load balancing and packet defrag are only valid on
 * Gateway routers or router with gateway port. */
for (RouterLBVIP(
        .router = &Router{.lr = lr,
                          .l3dgw_port = l3dgw_port,
                          .redirect_port_name = redirect_port_name,
                          .is_gateway = is_gateway,
                          .nats = nats},
        .lb = lb,
        .vip = vip,
        .backends = backends)
     if l3dgw_port.is_some() or is_gateway)
{
    if (backends == "" and not lb.options.get_bool_def("reject", false)) {
        for (LoadBalancerEmptyEvents(lb)) {
            for (HasEventElbMeter(has_elb_meter)) {
                Some {(var __match, var __action)} =
                    build_empty_lb_event_flow(vip, lb, has_elb_meter) in
                Flow(.logical_datapath = lr._uuid,
                     .stage            = s_ROUTER_IN_DNAT(),
                     .priority         = 130,
                     .__match          = __match,
                     .actions          = __action,
                     .external_ids     = stage_hint(lb._uuid))
            }
        }
    };

    /* A set to hold all ips that need defragmentation and tracking. */

    /* vip contains IP:port or just IP. */
    Some{(var ip_address, var port)} = ip_address_and_port_from_lb_key(vip) in
    var ipX = ip_address.ipX() in
    var proto = match (lb.protocol) {
        Some{proto} -> proto,
        _ -> "tcp"
    } in {
        /* If there are any load balancing rules, we should send
         * the packet to conntrack for defragmentation and
         * tracking.  This helps with two things.
         *
         * 1. With tracking, we can send only new connections to
         *    pick a DNAT ip address from a group.
         * 2. If there are L4 ports in load balancing rules, we
         *    need the defragmentation to match on L4 ports. */
        var __match = "ip && ${ipX}.dst == ${ip_address}" in
        /* One of these flows must be created for each unique LB VIP address.
         * We create one for each VIP:port pair; flows with the same IP and
         * different port numbers will produce identical flows that will
         * get merged by DDlog. */
        Flow(.logical_datapath = lr._uuid,
             .stage            = s_ROUTER_IN_DEFRAG(),
             .priority         = 100,
             .__match          = __match,
             .actions          = "ct_next;",
             .external_ids     = stage_hint(lb._uuid));

        /* Higher priority rules are added for load-balancing in DNAT
         * table.  For every match (on a VIP[:port]), we add two flows
         * via add_router_lb_flow().  One flow is for specific matching
         * on ct.new with an action of "ct_lb($targets);".  The other
         * flow is for ct.est with an action of "ct_dnat;". */
        var match1 = "ip && ${ipX}.dst == ${ip_address}" in
        (var prio, var match2) =
            if (port != 0) {
                (120, " && ${proto} && ${proto}.dst == ${port}")
            } else {
                (110, "")
            } in
        var __match = match1 ++ match2 ++
            match ((l3dgw_port, backends != "" or lb.options.get_bool_def("reject", false))) {
                (Some{gwport}, true) -> " && is_chassis_resident(${redirect_port_name})",
                _ -> ""
            } in
        var force_snat_for_lb = force_snat_for_lb(lr) in
        {
            /* A match and actions for established connections. */
            var est_match = "ct.est && " ++ __match in
            var actions =
                match (force_snat_for_lb) {
                    true -> "flags.force_snat_for_lb = 1; ct_dnat;",
                    false -> "ct_dnat;"
                } in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = s_ROUTER_IN_DNAT(),
                 .priority         = prio,
                 .__match          = est_match,
                 .actions          = actions,
                 .external_ids     = stage_hint(lb._uuid));

            if (nats_contain_vip(nats, ip_address)) {
                /* The load balancer vip is also present in the NAT entries.
                 * So add a high priority lflow to advance the the packet
                 * destined to the vip (and the vip port if defined)
                 * in the S_ROUTER_IN_UNSNAT stage.
                 * There seems to be an issue with ovs-vswitchd. When the new
                 * connection packet destined for the lb vip is received,
                 * it is dnat'ed in the S_ROUTER_IN_DNAT stage in the dnat
                 * conntrack zone. For the next packet, if it goes through
                 * unsnat stage, the conntrack flags are not set properly, and
                 * it doesn't hit the established state flows in
                 * S_ROUTER_IN_DNAT stage. */
                var match3 = "${ipX} && ${ipX}.dst == ${ip_address} && ${proto}" ++
                             if (port != 0) { " && ${proto}.dst == ${port}" }
                             else { "" } in
                Flow(.logical_datapath = lr._uuid,
                     .stage            = s_ROUTER_IN_UNSNAT(),
                     .priority         = 120,
                     .__match          = match3,
                     .actions          = "next;",
                     .external_ids     = stage_hint(lb._uuid))
            };

            Some{var gwport} = l3dgw_port in
            /* Add logical flows to UNDNAT the load balanced reverse traffic in
             * the router egress pipleine stage - S_ROUTER_OUT_UNDNAT if the logical
             * router has a gateway router port associated.
             */
            var conds = {
                var conds = vec_empty();
                for (ip_str in string_split(backends, ",")) {
                    match (ip_address_and_port_from_lb_key(ip_str)) {
                        None -> () /* FIXME: put a break here */,
                        Some{(ip_address_, port_)} -> conds.push(
                            "(${ipX}.src == ${ip_address_}" ++
                            if (port_ != 0) {
                                " && ${proto}.src == ${port_})"
                            } else {
                                ")"
                            })
                    }
                };
                conds
            } in
            not conds.is_empty() in
            var undnat_match =
                "${ip_address.ipX()} && (" ++ conds.join(" || ") ++
                ") && outport == ${json_string_escape(gwport.name)} && "
                "is_chassis_resident(${redirect_port_name})" in
            var action =
                match (force_snat_for_lb) {
                    true -> "flags.force_snat_for_lb = 1; ct_dnat;",
                    false -> "ct_dnat;"
                } in
            Flow(.logical_datapath = lr._uuid,
                 .stage            = s_ROUTER_OUT_UNDNAT(),
                 .priority         = 120,
                 .__match          = undnat_match,
                 .actions          = action,
                 .external_ids     = stage_hint(lb._uuid))
        }
    }
}

/* Higher priority rules are added for load-balancing in DNAT
 * table.  For every match (on a VIP[:port]), we add two flows
 * via add_router_lb_flow().  One flow is for specific matching
 * on ct.new with an action of "ct_lb($targets);".  The other
 * flow is for ct.est with an action of "ct_dnat;". */
Flow(.logical_datapath = r.lr._uuid,
     .stage            = s_ROUTER_IN_DNAT(),
     .priority         = priority,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(lb._uuid)) :-
    r in &Router(),
    r.l3dgw_port.is_some() or r.is_gateway,
    LBVIPWithStatus[lbvip@&LBVIPWithStatus{.lb = lb}],
    r.lr.load_balancer.contains(lb._uuid),
    var __match
        = "ct.new && " ++
          get_match_for_lb_key(lbvip.vip_addr, lbvip.vip_port, lb.protocol, true) ++
          match (r.l3dgw_port) {
              Some{gwport} -> " && is_chassis_resident(${r.redirect_port_name})",
              _ -> ""
          },
    var priority = if (lbvip.vip_port != 0) 120 else 110,
    var force_snat = if (force_snat_for_lb(r.lr)) "flags.force_snat_for_lb = 1; " else "",
    var actions = build_lb_vip_actions(lbvip, s_ROUTER_OUT_SNAT(), force_snat).


/* Defaults based on MaxRtrInterval and MinRtrInterval from RFC 4861 section
 * 6.2.1
 */
function nD_RA_MAX_INTERVAL_DEFAULT(): integer = 600
function nD_RA_MAX_INTERVAL_RANGE(): (integer, integer) { (4, 1800) }

function nd_ra_min_interval_default(max: integer): integer =
{
    if (max >= 9) { max / 3 } else { max * 3 / 4 }
}

function nD_RA_MIN_INTERVAL_RANGE(max: integer): (integer, integer) = (3, ((max * 3) / 4))

function nD_MTU_DEFAULT(): integer = 0

function copy_ra_to_sb(port: RouterPort, address_mode: string): Map<string, string> =
{
    var options = port.sb_options;

    options.insert("ipv6_ra_send_periodic", "true");
    options.insert("ipv6_ra_address_mode", address_mode);

    var max_interval = port.lrp.ipv6_ra_configs
        .get_int_def("max_interval", nD_RA_MAX_INTERVAL_DEFAULT())
        .clamp(nD_RA_MAX_INTERVAL_RANGE());
    options.insert("ipv6_ra_max_interval", "${max_interval}");

    var min_interval = port.lrp.ipv6_ra_configs
        .get_int_def("min_interval", nd_ra_min_interval_default(max_interval))
        .clamp(nD_RA_MIN_INTERVAL_RANGE(max_interval));
    options.insert("ipv6_ra_min_interval", "${min_interval}");

    var mtu = port.lrp.ipv6_ra_configs.get_int_def("mtu", nD_MTU_DEFAULT());

    /* RFC 2460 requires the MTU for IPv6 to be at least 1280 */
    if (mtu != 0 and mtu >= 1280) {
        options.insert("ipv6_ra_mtu", "${mtu}")
    };

    var prefixes = vec_empty();
    for (addr in port.networks.ipv6_addrs) {
        if (addr.is_lla()) {
            options.insert("ipv6_ra_src_addr", "${addr.addr}")
        } else {
            prefixes.push(addr.match_network())
        }
    };
    match (port.sb_options.get("ipv6_ra_pd_list")) {
        Some{value} -> prefixes.push(value),
        _ -> ()
    };
    options.insert("ipv6_ra_prefixes", prefixes.join(" "));

    match (port.lrp.ipv6_ra_configs.get("rdnss")) {
        Some{value} -> options.insert("ipv6_ra_rdnss", value),
        _ -> ()
    };

    match (port.lrp.ipv6_ra_configs.get("dnssl")) {
        Some{value} -> options.insert("ipv6_ra_dnssl", value),
        _ -> ()
    };

    options.insert("ipv6_ra_src_eth", "${port.networks.ea}");

    var prf = match (port.lrp.ipv6_ra_configs.get("router_preference")) {
        Some{prf} -> if (prf == "HIGH" or prf == "LOW") prf else "MEDIUM",
        _ -> "MEDIUM"
    };
    options.insert("ipv6_ra_prf", prf);

    match (port.lrp.ipv6_ra_configs.get("route_info")) {
        Some{s} -> options.insert("ipv6_ra_route_info", s),
        _ -> ()
    };

    options
}

/* Logical router ingress table ND_RA_OPTIONS and ND_RA_RESPONSE: IPv6 Router
 * Adv (RA) options and response. */
// FIXME: do these rules apply to derived ports?
for (&RouterPort[port@RouterPort{.lrp = lrp@nb::Logical_Router_Port{.peer = None},
                                 .router = &router,
                                 .json_name = json_name,
                                 .networks = networks,
                                 .peer = PeerSwitch{}}]
     if (not networks.ipv6_addrs.is_empty()))
{
    Some{var address_mode} = lrp.ipv6_ra_configs.get("address_mode") in
    /* FIXME: we need a nicer wat to write this */
    true ==
        if ((address_mode != "slaac") and
            (address_mode != "dhcpv6_stateful") and
            (address_mode != "dhcpv6_stateless")) {
            warn("Invalid address mode [${address_mode}] defined");
            false
        } else { true } in
    {
        if (lrp.ipv6_ra_configs.get_bool_def("send_periodic", false)) {
            RouterPortRAOptions(lrp._uuid, copy_ra_to_sb(port, address_mode))
        };

        (true, var prefix) =
            {
                var add_rs_response_flow = false;
                var prefix = "";
                for (addr in networks.ipv6_addrs) {
                    if (not addr.is_lla()) {
                        prefix = prefix ++ ", prefix = ${addr.match_network()}";
                        add_rs_response_flow = true
                    } else ()
                };
                (add_rs_response_flow, prefix)
            } in
        {
            var __match = "inport == ${json_name} && ip6.dst == ff02::2 && nd_rs" in
            /* As per RFC 2460, 1280 is minimum IPv6 MTU. */
            var mtu = match(lrp.ipv6_ra_configs.get("mtu")) {
                    Some{mtu_s} -> {
                        match (parse_dec_u64(mtu_s)) {
                            None -> 0,
                            Some{mtu} -> if (mtu >= 1280) mtu else 0
                        }
                    },
                    None -> 0
                } in
            var actions0 =
                "${rEGBIT_ND_RA_OPTS_RESULT()} = put_nd_ra_opts("
                "addr_mode = ${json_string_escape(address_mode)}, "
                "slla = ${networks.ea}" ++
                if (mtu > 0) { ", mtu = ${mtu}" } else { "" } in
            var router_preference = match (lrp.ipv6_ra_configs.get("router_preference")) {
                    Some{"MEDIUM"} -> "",
                    None -> "",
                    Some{prf} -> ", router_preference = \"${prf}\""
                } in
            var actions = actions0 ++ router_preference ++ prefix ++ "); next;" in
            Flow(.logical_datapath = router.lr._uuid,
                 .stage            = s_ROUTER_IN_ND_RA_OPTIONS(),
                 .priority         = 50,
                 .__match          = __match,
                 .actions          = actions,
                 .external_ids     = stage_hint(lrp._uuid));

            var __match = "inport == ${json_name} && ip6.dst == ff02::2 && "
                          "nd_ra && ${rEGBIT_ND_RA_OPTS_RESULT()}" in
            var ip6_str = networks.ea.to_ipv6_lla().string_mapped() in
            var actions = "eth.dst = eth.src; eth.src = ${networks.ea}; "
                          "ip6.dst = ip6.src; ip6.src = ${ip6_str}; "
                          "outport = inport; flags.loopback = 1; "
                          "output;" in
            Flow(.logical_datapath = router.lr._uuid,
                 .stage            = s_ROUTER_IN_ND_RA_RESPONSE(),
                 .priority         = 50,
                 .__match          = __match,
                 .actions          = actions,
                 .external_ids     = stage_hint(lrp._uuid))
        }
    }
}


/* Logical router ingress table ND_RA_OPTIONS, ND_RA_RESPONSE: RS responder, by
 * default goto next.  (priority 0)*/
for (&Router(.lr = lr))
{
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_ND_RA_OPTIONS(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_ND_RA_RESPONSE(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Proxy table that stores per-port routes.
 * There routes get converted into logical flows by
 * the following rule.
 */
relation Route(key:         route_key,       // matching criteria
               port:        Ref<RouterPort>, // output port
               src_ip:      v46_ip,          // source IP address for output
               gateway:     Option<v46_ip>) // next hop (unless being delivered)

function build_route_match(key: route_key) : (string, bit<32>) =
{
    var ipX = key.ip_prefix.ipX();

    /* The priority here is calculated to implement longest-prefix-match
     * routing. */
    (var dir, var priority) = match (key.policy) {
        SrcIp -> ("src", key.plen * 2),
        DstIp -> ("dst", (key.plen * 2) + 1)
    };

    var network = key.ip_prefix.network(key.plen);
    var __match = "${ipX}.${dir} == ${network}/${key.plen}";

    (__match, priority)
}
for (Route(.port        = port,
           .key         = key,
           .src_ip      = src_ip,
           .gateway     = gateway))
{
    var ipX = key.ip_prefix.ipX() in
    var xx = key.ip_prefix.xxreg() in
    /* IPv6 link-local addresses must be scoped to the local router port. */
    var inport_match = match (key.ip_prefix) {
        IPv6{prefix} -> if (prefix.is_lla()) {
                            "inport == ${port.json_name} && "
                        } else "",
        _ -> ""
    } in
    (var ip_match, var priority) = build_route_match(key) in
    var __match = inport_match ++ ip_match in
    var nexthop = match (gateway) {
        Some{gw} -> "${gw}",
        None     -> "${ipX}.dst"
    } in
    var actions =
        "${rEG_ECMP_GROUP_ID()} = 0; "
        "${xx}${rEG_NEXT_HOP()} = ${nexthop}; "
        "${xx}${rEG_SRC()} = ${src_ip}; "
        "eth.src = ${port.networks.ea}; "
        "outport = ${port.json_name}; "
        "flags.loopback = 1; "
        "next;" in
    {
        Flow(.logical_datapath = port.router.lr._uuid,
             .stage            = s_ROUTER_IN_IP_ROUTING(),
             .priority         = priority as integer,
             .__match          = __match,
             .actions          = "ip.ttl--; ${actions}",
             .external_ids     = stage_hint(port.lrp._uuid));

        if (port.has_bfd) {
            Flow(.logical_datapath = port.router.lr._uuid,
                 .stage            = s_ROUTER_IN_IP_ROUTING(),
                 .priority         = priority as integer + 1,
                 .__match          = "${__match} && udp.dst == 3784",
                 .actions          = actions,
                 .external_ids     = stage_hint(port.lrp._uuid))
        }
    }
}

/* Logical router ingress table IP_ROUTING & IP_ROUTING_ECMP: IP Routing.
 *
 * A packet that arrives at this table is an IP packet that should be
 * routed to the address in 'ip[46].dst'.
 *
 * For regular routes without ECMP, table IP_ROUTING sets outport to the
 * correct output port, eth.src to the output port's MAC address, and
 * '[xx]${rEG_NEXT_HOP()}' to the next-hop IP address (leaving 'ip[46].dst', the
 * packets final destination, unchanged), and advances to the next table.
 *
 * For ECMP routes, i.e. multiple routes with same policy and prefix, table
 * IP_ROUTING remembers ECMP group id and selects a member id, and advances
 * to table IP_ROUTING_ECMP, which sets outport, eth.src, and the appropriate
 * next-hop register for the selected ECMP member.
 * */
Route(key, port, src_ip, None) :-
    RouterPortNetworksIPv4Addr(.port = port, .addr = addr),
    var key = RouteKey{DstIp, IPv4{addr.addr}, addr.plen},
    var src_ip = IPv4{addr.addr}.

Route(key, port, src_ip, None) :-
    RouterPortNetworksIPv6Addr(.port = port, .addr = addr),
    var key = RouteKey{DstIp, IPv6{addr.addr}, addr.plen},
    var src_ip = IPv6{addr.addr}.

Flow(.logical_datapath = r.lr._uuid,
     .stage            = s_ROUTER_IN_IP_ROUTING_ECMP(),
     .priority         = 150,
     .__match          = "${rEG_ECMP_GROUP_ID()} == 0",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    r in &Router().

/* Convert the static routes to flows. */
Route(key, dst.port, dst.src_ip, Some{dst.nexthop}) :-
    RouterStaticRoute(.router = &router, .key = key, .dsts = dsts),
    dsts.size() == 1,
    Some{var dst} = dsts.nth(0).

/* Return a vector of pairs (1, set[0]), ... (n, set[n - 1]). */
function numbered_vec(set: Set<'A>) : Vec<(bit<16>, 'A)> = {
    var vec = vec_with_capacity(set.size());
    var i = 1;
    for (x in set) {
        vec.push((i, x));
        i = i + 1
    };
    vec
}

relation EcmpGroup(
    group_id: bit<16>,
    router: Ref<Router>,
    key: route_key,
    dsts: Set<route_dst>,
    route_match: string,        // This is build_route_match(key).0
    route_priority: integer)    // This is build_route_match(key).1

EcmpGroup(group_id, router, key, dsts, route_match, route_priority) :-
    r in RouterStaticRoute(.router = router, .key = key, .dsts = dsts),
    dsts.size() > 1,
    var groups = (router, key, dsts).group_by(()).to_set(),
    var group_id_and_group = FlatMap(numbered_vec(groups)),
    (var group_id, (var router, var key, var dsts)) = group_id_and_group,
    (var route_match, var route_priority0) = build_route_match(key),
    var route_priority = route_priority0 as integer.

Flow(.logical_datapath = router.lr._uuid,
     .stage            = s_ROUTER_IN_IP_ROUTING(),
     .priority         = route_priority,
     .__match          = route_match,
     .actions          = actions,
     .external_ids     = map_empty()) :-
    EcmpGroup(group_id, router, key, dsts, route_match, route_priority),
    var all_member_ids = {
        var member_ids = vec_with_capacity(dsts.size());
        for (i in range_vec(1, dsts.size()+1, 1)) {
            member_ids.push("${i}")
        };
        member_ids.join(", ")
    },
    var actions =
        "ip.ttl--; "
        "flags.loopback = 1; "
        "${rEG_ECMP_GROUP_ID()} = ${group_id}; " /* XXX */
        "${rEG_ECMP_MEMBER_ID()} = select(${all_member_ids});".

Flow(.logical_datapath = router.lr._uuid,
     .stage            = s_ROUTER_IN_IP_ROUTING_ECMP(),
     .priority         = 100,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = map_empty()) :-
    EcmpGroup(group_id, router, key, dsts, _, _),
    var member_id_and_dst = FlatMap(numbered_vec(dsts)),
    (var member_id, var dst) = member_id_and_dst,
    var xx = dst.nexthop.xxreg(),
    var __match = "${rEG_ECMP_GROUP_ID()} == ${group_id} && "
                  "${rEG_ECMP_MEMBER_ID()} == ${member_id}",
    var actions = "${xx}${rEG_NEXT_HOP()} = ${dst.nexthop}; "
                  "${xx}${rEG_SRC()} = ${dst.src_ip}; "
                  "eth.src = ${dst.port.networks.ea}; "
                  "outport = ${dst.port.json_name}; "
                  "next;".

/* If symmetric ECMP replies are enabled, then packets that arrive over
 * an ECMP route need to go through conntrack.
 */
relation EcmpSymmetricReply(
    router: Ref<Router>,
    dst: route_dst,
    route_match: string,
    tunkey: integer)
EcmpSymmetricReply(router, dst, route_match, tunkey) :-
    EcmpGroup(.router = router, .dsts = dsts, .route_match = route_match),
    router.is_gateway,
    var dst = FlatMap(dsts),
    dst.ecmp_symmetric_reply,
    PortTunKeyAllocation(.port = dst.port.lrp._uuid, .tunkey = tunkey).

Flow(.logical_datapath = router.lr._uuid,
     .stage = s_ROUTER_IN_DEFRAG(),
     .priority = 100,
     .__match = __match,
     .actions = "ct_next;",
     .external_ids = map_empty()) :-
    EcmpSymmetricReply(router, dst, route_match, _),
    var __match = "inport == ${dst.port.json_name} && ${route_match}".

/* And packets that go out over an ECMP route need conntrack.
   XXX this seems to exactly duplicate the above flow? */

/* Save src eth and inport in ct_label for packets that arrive over
 * an ECMP route.
 */
Flow(.logical_datapath = router.lr._uuid,
     .stage = s_ROUTER_IN_ECMP_STATEFUL(),
     .priority = 100,
     .__match = __match,
     .actions = actions,
     .external_ids = map_empty()) :-
    EcmpSymmetricReply(router, dst, route_match, tunkey),
    var __match = "inport == ${dst.port.json_name} && ${route_match} && "
                  "(ct.new && !ct.est)",
    var actions = "ct_commit { ct_label.ecmp_reply_eth = eth.src;"
                  " ct_label.ecmp_reply_port = ${tunkey};}; next;".

/* Bypass ECMP selection if we already have ct_label information
 * for where to route the packet.
 */
Flow(.logical_datapath = router.lr._uuid,
     .stage = s_ROUTER_IN_IP_ROUTING(),
     .priority = 100,
     .__match = "${ecmp_reply} && ${route_match}",
     .actions = "ip.ttl--; "
                "flags.loopback = 1; "
                "eth.src = ${dst.port.networks.ea}; "
                "${xx}reg1 = ${dst.src_ip}; "
                "outport = ${dst.port.json_name}; "
                "next;",
     .external_ids = map_empty()),
/* Egress reply traffic for symmetric ECMP routes skips router policies. */
Flow(.logical_datapath = router.lr._uuid,
     .stage = s_ROUTER_IN_POLICY(),
     .priority = 65535,
     .__match = ecmp_reply,
     .actions = "next;",
     .external_ids = map_empty()),
Flow(.logical_datapath = router.lr._uuid,
     .stage = s_ROUTER_IN_ARP_RESOLVE(),
     .priority = 200,
     .__match = ecmp_reply,
     .actions = "eth.dst = ct_label.ecmp_reply_eth; next;",
     .external_ids = map_empty()) :-
    EcmpSymmetricReply(router, dst, route_match, tunkey),
    var ecmp_reply = "ct.rpl && ct_label.ecmp_reply_port == ${tunkey}",
    var xx = dst.nexthop.xxreg().


/* IP Multicast lookup. Here we set the output port, adjust TTL and advance
 * to next table (priority 500).
 */
/* Drop IPv6 multicast traffic that shouldn't be forwarded,
 * i.e., router solicitation and router advertisement.
 */
Flow(.logical_datapath = router.lr._uuid,
     .stage            = s_ROUTER_IN_IP_ROUTING(),
     .priority         = 550,
     .__match          = "nd_rs || nd_ra",
     .actions          = "drop;",
     .external_ids     = map_empty()) :-
    router in &Router().

for (IgmpRouterMulticastGroup(address, &rtr, ports)) {
    for (RouterMcastFloodPorts(&rtr, flood_ports) if rtr.mcast_cfg.relay) {
        var flood_static = not flood_ports.is_empty() in
        var mc_static = json_string_escape(mC_STATIC().0) in
        var static_act = {
            if (flood_static) {
                "clone { "
                    "outport = ${mc_static}; "
                    "ip.ttl--; "
                    "next; "
                "}; "
            } else {
                ""
            }
        } in
        Some{var ip} = ip46_parse(address) in
        var ipX = ip.ipX() in
        UniqueFlow[Flow{.logical_datapath = rtr.lr._uuid,
                        .stage            = s_ROUTER_IN_IP_ROUTING(),
                        .priority         = 500,
                        .__match          = "${ipX} && ${ipX}.dst == ${address} ",
                        .actions          =
                           "${static_act}outport = ${json_string_escape(address)}; "
                           "ip.ttl--; next;",
                        .external_ids     = map_empty()}]
    }
}

/* If needed, flood unregistered multicast on statically configured ports.
 * Priority 450. Otherwise drop any multicast traffic.
 */
for (RouterMcastFloodPorts(&rtr, flood_ports) if rtr.mcast_cfg.relay) {
    var mc_static = json_string_escape(mC_STATIC().0) in
    var flood_static = not flood_ports.is_empty() in
    var actions = if (flood_static) {
        "clone { "
            "outport = ${mc_static}; "
            "ip.ttl--; "
            "next; "
        "};"
    } else {
        "drop;"
    } in
    AnnotatedFlow(.f = Flow{.logical_datapath = rtr.lr._uuid,
                            .stage            = s_ROUTER_IN_IP_ROUTING(),
                            .priority         = 450,
                            .__match          = "ip4.mcast || ip6.mcast",
                            .actions          = actions,
                            .external_ids     = map_empty()},
                  .shared = not flood_static)
}

/* Logical router ingress table POLICY: Policy.
 *
 * A packet that arrives at this table is an IP packet that should be
 * permitted/denied/rerouted to the address in the rule's nexthop.
 * This table sets outport to the correct out_port,
 * eth.src to the output port's MAC address,
 * the appropriate register to the next-hop IP address (leaving
 * 'ip[46].dst', the packets final destination, unchanged), and
 * advances to the next table for ARP/ND resolution. */
for (&Router(.lr = lr)) {
    /* This is a catch-all rule. It has the lowest priority (0)
     * does a match-all("1") and pass-through (next) */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_POLICY(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "${rEG_ECMP_GROUP_ID()} = 0; next;",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_POLICY_ECMP(),
         .priority         = 150,
         .__match          = "${rEG_ECMP_GROUP_ID()} == 0",
         .actions          = "next;",
         .external_ids     = map_empty())
}

function stage_hint(_uuid: uuid): Map<string,string> = {
    ["stage-hint" -> "${hex(_uuid[127:96])}"]
}


/* Convert routing policies to flows. */
function pkt_mark_policy(options: Map<string,string>): string {
    var pkt_mark = options.get("pkt_mark").and_then(parse_dec_u64).unwrap_or(0);
    if (pkt_mark > 0 and pkt_mark < (1 << 32)) {
        "pkt.mark = ${pkt_mark}; "
    } else {
        ""
    }
}
Flow(.logical_datapath = r.lr._uuid,
     .stage            = s_ROUTER_IN_POLICY(),
     .priority         = policy.priority,
     .__match          = policy.__match,
     .actions          = actions,
     .external_ids     = stage_hint(policy._uuid)) :-
    r in &Router(),
    var policy_uuid = FlatMap(r.lr.policies),
    policy in nb::Logical_Router_Policy(._uuid = policy_uuid),
    policy.action == "reroute",
    Some{var nexthop_s} = match (policy.nexthops.size()) {
        0 -> policy.nexthop,
        1 -> policy.nexthops.nth(0),
        _ -> None       /* >1 nexthops handled separately as ECMP. */
    },
    Some{var nexthop} = ip46_parse(nexthop_s),
    out_port in &RouterPort(.router = r),
    Some{var src_ip} = find_lrp_member_ip(out_port.networks, nexthop),
    /*
    None:
    VLOG_WARN_RL(&rl, "lrp_addr not found for routing policy "
                 " priority %"PRId64" nexthop %s",
                 rule->priority, rule->nexthop);
    */
    var xx = src_ip.xxreg(),
    var actions = (pkt_mark_policy(policy.options) ++
                   "${xx}${rEG_NEXT_HOP()} = ${nexthop}; "
                   "${xx}${rEG_SRC()} = ${src_ip}; "
                   "eth.src = ${out_port.networks.ea}; "
                   "outport = ${out_port.json_name}; "
                   "flags.loopback = 1; "
                   "${rEG_ECMP_GROUP_ID()} = 0; "
                   "next;").

/* Returns true if the addresses in 'addrs' are all IPv4 or all IPv6,
   false if they are a mix. */
function all_same_addr_family(addrs: Set<string>): bool {
    var addr_families = set_empty();
    for (a in addrs) {
        addr_families.insert(a.contains("."))
    };
    addr_families.size() <= 1
}

relation EcmpReroutePolicy(
    r: Ref<Router>,
    policy: nb::Logical_Router_Policy,
    ecmp_group_id: usize
)
EcmpReroutePolicy(r, policy, ecmp_group_id) :-
    r in &Router(),
    var policy_uuid = FlatMap(r.lr.policies),
    policy in nb::Logical_Router_Policy(._uuid = policy_uuid),
    policy.action == "reroute",
    policy.nexthops.size() > 1,
    var policies = policy.group_by(r).to_vec(),
    var ecmp_group_ids = range_vec(1, policies.len() + 1, 1),
    var numbered_policies = policies.zip(ecmp_group_ids),
    var pair = FlatMap(numbered_policies),
    (var policy, var ecmp_group_id) = pair,
    all_same_addr_family(policy.nexthops).
Flow(.logical_datapath = r.lr._uuid,
     .stage            = s_ROUTER_IN_POLICY_ECMP(),
     .priority         = 100,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = stage_hint(policy._uuid)) :-
    EcmpReroutePolicy(r, policy, ecmp_group_id),
    var member_ids = range_vec(1, policy.nexthops.size() + 1, 1),
    var numbered_nexthops = policy.nexthops.to_vec().zip(member_ids),
    var pair = FlatMap(numbered_nexthops),
    (var nexthop_s, var member_id) = pair,
    Some{var nexthop} = ip46_parse(nexthop_s),
    out_port in &RouterPort(.router = r),
    Some{var src_ip} = find_lrp_member_ip(out_port.networks, nexthop), // or warn
    var xx = src_ip.xxreg(),
    var actions = (pkt_mark_policy(policy.options) ++
                   "${xx}${rEG_NEXT_HOP()} = ${nexthop}; "
                   "${xx}${rEG_SRC()} = ${src_ip}; "
                   "eth.src = ${out_port.networks.ea}; "
                   "outport = ${out_port.json_name}; "
                   "flags.loopback = 1; "
                   "next;"),
    var __match = ("${rEG_ECMP_GROUP_ID()} == ${ecmp_group_id} && "
                   "${rEG_ECMP_MEMBER_ID()} == ${member_id}").
Flow(.logical_datapath = r.lr._uuid,
     .stage            = s_ROUTER_IN_POLICY(),
     .priority         = policy.priority,
     .__match          = policy.__match,
     .actions          = actions,
     .external_ids     = stage_hint(policy._uuid)) :-
    EcmpReroutePolicy(r, policy, ecmp_group_id),
    var member_ids = {
        var n = policy.nexthops.size();
        var member_ids = vec_with_capacity(n);
        for (i in range_vec(1, n + 1, 1)) {
            member_ids.push("${i}")
        };
        member_ids.join(", ")
    },
    var actions = ("${rEG_ECMP_GROUP_ID()} = ${ecmp_group_id}; "
                   "${rEG_ECMP_MEMBER_ID()} = select(${member_ids});").
    
Flow(.logical_datapath = r.lr._uuid,
     .stage            = s_ROUTER_IN_POLICY(),
     .priority         = policy.priority,
     .__match          = policy.__match,
     .actions          = "drop;",
     .external_ids     = stage_hint(policy._uuid)) :-
    r in &Router(),
    var policy_uuid = FlatMap(r.lr.policies),
    policy in nb::Logical_Router_Policy(._uuid = policy_uuid),
    policy.action == "drop".
Flow(.logical_datapath = r.lr._uuid,
     .stage            = s_ROUTER_IN_POLICY(),
     .priority         = policy.priority,
     .__match          = policy.__match,
     .actions          = pkt_mark_policy(policy.options) ++ "${rEG_ECMP_GROUP_ID()} = 0; next;",
     .external_ids     = stage_hint(policy._uuid)) :-
    r in &Router(),
    var policy_uuid = FlatMap(r.lr.policies),
    policy in nb::Logical_Router_Policy(._uuid = policy_uuid),
    policy.action == "allow".


/* XXX destination unreachable */

/* Local router ingress table ARP_RESOLVE: ARP Resolution.
 *
 * Multicast packets already have the outport set so just advance to next
 * table (priority 500).
 */
for (&Router(.lr = lr)) {
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_ARP_RESOLVE(),
         .priority         = 500,
         .__match          = "ip4.mcast || ip6.mcast",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Local router ingress table ARP_RESOLVE: ARP Resolution.
 *
 * Any packet that reaches this table is an IP packet whose next-hop IP
 * address is in the next-hop register. (ip4.dst is the final destination.) This table
 * resolves the IP address in the next-hop register into an output port in outport and an
 * Ethernet address in eth.dst. */
// FIXME: does this apply to redirect ports?
for (rp in &RouterPort(.peer = PeerRouter{peer_port, _},
                       .router = &router,
                       .networks = networks))
{
    for (&RouterPort(.lrp = nb::Logical_Router_Port{._uuid = peer_port},
                     .json_name = peer_json_name,
                     .router = &peer_router))
    {
        /* This is a logical router port. If next-hop IP address in
         * the next-hop register matches IP address of this router port, then
         * the packet is intended to eventually be sent to this
         * logical port. Set the destination mac address using this
         * port's mac address.
         *
         * The packet is still in peer's logical pipeline. So the match
         * should be on peer's outport. */
        if (not networks.ipv4_addrs.is_empty()) {
            var __match = "outport == ${peer_json_name} && "
                          "${rEG_NEXT_HOP()} == " ++
                          format_v4_networks(networks, false) in
            Flow(.logical_datapath = peer_router.lr._uuid,
                 .stage            = s_ROUTER_IN_ARP_RESOLVE(),
                 .priority         = 100,
                 .__match          = __match,
                 .actions          = "eth.dst = ${networks.ea}; next;",
                 .external_ids     = stage_hint(rp.lrp._uuid))
        };

        if (not networks.ipv6_addrs.is_empty()) {
            var __match = "outport == ${peer_json_name} && "
                          "xx${rEG_NEXT_HOP()} == " ++
                          format_v6_networks(networks) in
            Flow(.logical_datapath = peer_router.lr._uuid,
                 .stage            = s_ROUTER_IN_ARP_RESOLVE(),
                 .priority         = 100,
                 .__match          = __match,
                 .actions          = "eth.dst = ${networks.ea}; next;",
                 .external_ids     = stage_hint(rp.lrp._uuid))
        }
    }
}

/* Packet is on a non gateway chassis and
 * has an unresolved ARP on a network behind gateway
 * chassis attached router port. Since, redirect type
 * is "bridged", instead of calling "get_arp"
 * on this node, we will redirect the packet to gateway
 * chassis, by setting destination mac router port mac.*/
Flow(.logical_datapath = router.lr._uuid,
     .stage            = s_ROUTER_IN_ARP_RESOLVE(),
     .priority         = 50,
     .__match          = "outport == ${rp.json_name} && "
                         "!is_chassis_resident(${router.redirect_port_name})",
     .actions          = "eth.dst = ${rp.networks.ea}; next;",
     .external_ids     = stage_hint(lrp._uuid)) :-
    rp in &RouterPort(.lrp = lrp, .router = router),
    router.redirect_port_name != "",
    Some{"bridged"} = lrp.options.get("redirect-type").


/* Drop IP traffic destined to router owned IPs. Part of it is dropped
 * in stage "lr_in_ip_input" but traffic that could have been unSNATed
 * but didn't match any existing session might still end up here.
 *
 * Priority 1.
 */
Flow(.logical_datapath = lr_uuid,
     .stage = s_ROUTER_IN_ARP_RESOLVE(),
     .priority = 1,
     .__match = "ip4.dst == {" ++ match_ips.join(", ") ++ "}",
     .actions = "drop;",
     .external_ids = stage_hint(lrp_uuid)) :-
    &RouterPort(.lrp = nb::Logical_Router_Port{._uuid = lrp_uuid},
                .router = &Router{.snat_ips = snat_ips,
                                  .lr = nb::Logical_Router{._uuid = lr_uuid}},
                .networks = networks),
    var addr = FlatMap(networks.ipv4_addrs),
    snat_ips.contains_key(IPv4{addr.addr}),
    var match_ips = "${addr.addr}".group_by((lr_uuid, lrp_uuid)).to_vec().
Flow(.logical_datapath = lr_uuid,
     .stage = s_ROUTER_IN_ARP_RESOLVE(),
     .priority = 1,
     .__match = "ip6.dst == {" ++ match_ips.join(", ") ++ "}",
     .actions = "drop;",
     .external_ids = stage_hint(lrp_uuid)) :-
    &RouterPort(.lrp = nb::Logical_Router_Port{._uuid = lrp_uuid},
                .router = &Router{.snat_ips = snat_ips,
                                  .lr = nb::Logical_Router{._uuid = lr_uuid}},
                .networks = networks),
    var addr = FlatMap(networks.ipv6_addrs),
    snat_ips.contains_key(IPv6{addr.addr}),
    var match_ips = "${addr.addr}".group_by((lr_uuid, lrp_uuid)).to_vec().

/* This is a logical switch port that backs a VM or a container.
 * Extract its addresses. For each of the address, go through all
 * the router ports attached to the switch (to which this port
 * connects) and if the address in question is reachable from the
 * router port, add an ARP/ND entry in that router's pipeline. */
for (SwitchPortIPv4Address(
        .port = &SwitchPort{.lsp = lsp, .sw = &sw},
        .ea = ea,
        .addr = addr)
     if lsp.__type != "router" and lsp.__type != "virtual" and lsp.is_enabled())
{
    for (&SwitchPort(.sw = &Switch{.ls = nb::Logical_Switch{._uuid = sw.ls._uuid}},
                     .peer = Some{&peer@RouterPort{.router = &peer_router}}))
    {
        Some{_} = find_lrp_member_ip(peer.networks, IPv4{addr.addr}) in
        Flow(.logical_datapath = peer_router.lr._uuid,
             .stage            = s_ROUTER_IN_ARP_RESOLVE(),
             .priority         = 100,
             .__match          = "outport == ${peer.json_name} && "
                                 "${rEG_NEXT_HOP()} == ${addr.addr}",
             .actions          = "eth.dst = ${ea}; next;",
             .external_ids     = stage_hint(lsp._uuid))
    }
}

for (SwitchPortIPv6Address(
        .port = &SwitchPort{.lsp = lsp, .sw = &sw},
        .ea = ea,
        .addr = addr)
     if lsp.__type != "router" and lsp.__type != "virtual" and lsp.is_enabled())
{
    for (&SwitchPort(.sw = &Switch{.ls = nb::Logical_Switch{._uuid = sw.ls._uuid}},
                     .peer = Some{&peer@RouterPort{.router = &peer_router}}))
    {
        Some{_} = find_lrp_member_ip(peer.networks, IPv6{addr.addr}) in
        Flow(.logical_datapath = peer_router.lr._uuid,
             .stage            = s_ROUTER_IN_ARP_RESOLVE(),
             .priority         = 100,
             .__match          = "outport == ${peer.json_name} && "
                                 "xx${rEG_NEXT_HOP()} == ${addr.addr}",
             .actions          = "eth.dst = ${ea}; next;",
             .external_ids     = stage_hint(lsp._uuid))
    }
}

/* True if 's' is an empty set or a set that contains just an empty string,
 * false otherwise.
 *
 * This is meant for sets of 0 or 1 elements, like the OVSDB integration
 * with DDlog uses. */
function is_empty_set_or_string(s: Option<string>): bool = {
    match (s) {
        None -> true,
        Some{""} -> true,
        _ -> false
    }
}

/* This is a virtual port. Add ARP replies for the virtual ip with
 * the mac of the present active virtual parent.
 * If the logical port doesn't have virtual parent set in
 * Port_Binding table, then add the flow to set eth.dst to
 * 00:00:00:00:00:00 and advance to next table so that ARP is
 * resolved by router pipeline using the arp{} action.
 * The MAC_Binding entry for the virtual ip might be invalid. */
Flow(.logical_datapath = peer.router.lr._uuid,
     .stage            = s_ROUTER_IN_ARP_RESOLVE(),
     .priority         = 100,
     .__match          = "outport == ${peer.json_name} && "
                         "${rEG_NEXT_HOP()} == ${virtual_ip}",
     .actions          = "eth.dst = 00:00:00:00:00:00; next;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(.lsp = lsp@nb::Logical_Switch_Port{.__type = "virtual"}),
    Some{var virtual_ip_s} = lsp.options.get("virtual-ip"),
    Some{var virtual_parents} = lsp.options.get("virtual-parents"),
    Some{var virtual_ip} = ip_parse(virtual_ip_s),
    pb in sb::Port_Binding(.logical_port = sp.lsp.name),
    is_empty_set_or_string(pb.virtual_parent) or pb.chassis == None,
    sp2 in &SwitchPort(.sw = sp.sw, .peer = Some{peer}),
    Some{_} = find_lrp_member_ip(peer.networks, IPv4{virtual_ip}).
Flow(.logical_datapath = peer.router.lr._uuid,
     .stage            = s_ROUTER_IN_ARP_RESOLVE(),
     .priority         = 100,
     .__match          = "outport == ${peer.json_name} && "
                         "${rEG_NEXT_HOP()} == ${virtual_ip}",
     .actions          = "eth.dst = ${address.ea}; next;",
     .external_ids     = stage_hint(sp.lsp._uuid)) :-
    sp in &SwitchPort(.lsp = lsp@nb::Logical_Switch_Port{.__type = "virtual"}),
    Some{var virtual_ip_s} = lsp.options.get("virtual-ip"),
    Some{var virtual_parents} = lsp.options.get("virtual-parents"),
    Some{var virtual_ip} = ip_parse(virtual_ip_s),
    pb in sb::Port_Binding(.logical_port = sp.lsp.name),
    not (is_empty_set_or_string(pb.virtual_parent) or pb.chassis == None),
    Some{var virtual_parent} = pb.virtual_parent,
    vp in &SwitchPort(.lsp = nb::Logical_Switch_Port{.name = virtual_parent}),
    var address = FlatMap(vp.static_addresses),
    sp2 in &SwitchPort(.sw = sp.sw, .peer = Some{peer}),
    Some{_} = find_lrp_member_ip(peer.networks, IPv4{virtual_ip}).

/* This is a logical switch port that connects to a router. */

/* The peer of this switch port is the router port for which
 * we need to add logical flows such that it can resolve
 * ARP entries for all the other router ports connected to
 * the switch in question. */
for (&SwitchPort(.lsp = lsp1,
                 .peer = Some{&peer1@RouterPort{.router = &peer_router}},
                 .sw = &sw)
     if lsp1.is_enabled() and
        not peer_router.lr.options.get_bool_def("dynamic_neigh_routers", false))
{
    for (&SwitchPort(.lsp = lsp2, .peer = Some{&peer2},
                     .sw = &Switch{.ls = nb::Logical_Switch{._uuid = sw.ls._uuid}})
         /* Skip the router port under consideration. */
         if peer2.lrp._uuid != peer1.lrp._uuid)
    {
        if (not peer2.networks.ipv4_addrs.is_empty()) {
            Flow(.logical_datapath = peer_router.lr._uuid,
                 .stage            = s_ROUTER_IN_ARP_RESOLVE(),
                 .priority         = 100,
                 .__match          = "outport == ${peer1.json_name} && "
                                     "${rEG_NEXT_HOP()} == ${format_v4_networks(peer2.networks, false)}",
                 .actions          = "eth.dst = ${peer2.networks.ea}; next;",
                 .external_ids     = stage_hint(lsp1._uuid))
        };

        if (not peer2.networks.ipv6_addrs.is_empty()) {
            Flow(.logical_datapath = peer_router.lr._uuid,
                 .stage            = s_ROUTER_IN_ARP_RESOLVE(),
                 .priority         = 100,
                 .__match          = "outport == ${peer1.json_name} && "
                                     "xx${rEG_NEXT_HOP()} == ${format_v6_networks(peer2.networks)}",
                 .actions          = "eth.dst = ${peer2.networks.ea}; next;",
                 .external_ids     = stage_hint(lsp1._uuid))
        }
    }
}

for (&Router(.lr = lr))
{
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_ARP_RESOLVE(),
         .priority         = 0,
         .__match          = "ip4",
         .actions          = "get_arp(outport, ${rEG_NEXT_HOP()}); next;",
         .external_ids     = map_empty());
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_ARP_RESOLVE(),
         .priority         = 0,
         .__match          = "ip6",
         .actions          = "get_nd(outport, xx${rEG_NEXT_HOP()}); next;",
         .external_ids     = map_empty())
}

/* Local router ingress table CHK_PKT_LEN: Check packet length.
 *
 * Any IPv4 packet with outport set to the distributed gateway
 * router port, check the packet length and store the result in the
 * 'REGBIT_PKT_LARGER' register bit.
 *
 * Local router ingress table LARGER_PKTS: Handle larger packets.
 *
 * Any IPv4 packet with outport set to the distributed gateway
 * router port and the 'REGBIT_PKT_LARGER' register bit is set,
 * generate ICMPv4 packet with type 3 (Destination Unreachable) and
 * code 4 (Fragmentation needed).
 * */
Flow(.logical_datapath = lr._uuid,
     .stage            = s_ROUTER_IN_CHK_PKT_LEN(),
     .priority         = 0,
     .__match          = "1",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = s_ROUTER_IN_LARGER_PKTS(),
     .priority         = 0,
     .__match          = "1",
     .actions          = "next;",
     .external_ids     = map_empty()) :-
    &Router(.lr = lr).
Flow(.logical_datapath = lr._uuid,
     .stage            = s_ROUTER_IN_CHK_PKT_LEN(),
     .priority         = 50,
     .__match          = "outport == ${l3dgw_port_json_name}",
     .actions          = "${rEGBIT_PKT_LARGER()} = check_pkt_larger(${mtu}); "
                         "next;",
     .external_ids     = stage_hint(l3dgw_port._uuid)) :-
    r in &Router(.lr = lr),
    Some{var l3dgw_port} = r.l3dgw_port,
    var l3dgw_port_json_name = json_string_escape(l3dgw_port.name),
    r.redirect_port_name != "",
    var gw_mtu = l3dgw_port.options.get_int_def("gateway_mtu", 0),
    gw_mtu > 0,
    var mtu = gw_mtu + vLAN_ETH_HEADER_LEN().
Flow(.logical_datapath = lr._uuid,
     .stage            = s_ROUTER_IN_LARGER_PKTS(),
     .priority         = 50,
     .__match          = "inport == ${rp.json_name} && outport == ${l3dgw_port_json_name} && "
                         "ip4 && ${rEGBIT_PKT_LARGER()}",
     .actions          = "icmp4_error {"
                         "${rEGBIT_EGRESS_LOOPBACK()} = 1; "
                         "eth.dst = ${rp.networks.ea}; "
                         "ip4.dst = ip4.src; "
                         "ip4.src = ${first_ipv4.addr}; "
                         "ip.ttl = 255; "
                         "icmp4.type = 3; /* Destination Unreachable. */ "
                         "icmp4.code = 4; /* Frag Needed and DF was Set. */ "
                         /* Set icmp4.frag_mtu to gw_mtu */
                         "icmp4.frag_mtu = ${gw_mtu}; "
                         "next(pipeline=ingress, table=0); "
                         "};",
     .external_ids     = stage_hint(rp.lrp._uuid)) :-
    r in &Router(.lr = lr),
    Some{var l3dgw_port} = r.l3dgw_port,
    var l3dgw_port_json_name = json_string_escape(l3dgw_port.name),
    r.redirect_port_name != "",
    var gw_mtu = l3dgw_port.options.get_int_def("gateway_mtu", 0),
    gw_mtu > 0,
    rp in &RouterPort(.router = r),
    rp.lrp != l3dgw_port,
    Some{var first_ipv4} = rp.networks.ipv4_addrs.nth(0).
Flow(.logical_datapath = lr._uuid,
     .stage            = s_ROUTER_IN_LARGER_PKTS(),
     .priority         = 50,
     .__match          = "inport == ${rp.json_name} && outport == ${l3dgw_port_json_name} && "
                         "ip6 && ${rEGBIT_PKT_LARGER()}",
     .actions          = "icmp6_error {"
                         "${rEGBIT_EGRESS_LOOPBACK()} = 1; "
                         "eth.dst = ${rp.networks.ea}; "
                         "ip6.dst = ip6.src; "
                         "ip6.src = ${first_ipv6.addr}; "
                         "ip.ttl = 255; "
                         "icmp6.type = 2; /* Packet Too Big. */ "
                         "icmp6.code = 0; "
                         /* Set icmp6.frag_mtu to gw_mtu */
                         "icmp6.frag_mtu = ${gw_mtu}; "
                         "next(pipeline=ingress, table=0); "
                         "};",
     .external_ids     = stage_hint(rp.lrp._uuid)) :-
    r in &Router(.lr = lr),
    Some{var l3dgw_port} = r.l3dgw_port,
    var l3dgw_port_json_name = json_string_escape(l3dgw_port.name),
    r.redirect_port_name != "",
    var gw_mtu = l3dgw_port.options.get_int_def("gateway_mtu", 0),
    gw_mtu > 0,
    rp in &RouterPort(.router = r),
    rp.lrp != l3dgw_port,
    Some{var first_ipv6} = rp.networks.ipv6_addrs.nth(0).

/* Logical router ingress table GW_REDIRECT: Gateway redirect.
 *
 * For traffic with outport equal to the l3dgw_port
 * on a distributed router, this table redirects a subset
 * of the traffic to the l3redirect_port which represents
 * the central instance of the l3dgw_port.
 */
for (&Router(.lr = lr,
             .l3dgw_port = l3dgw_port,
             .redirect_port_name = redirect_port_name))
{
    /* For traffic with outport == l3dgw_port, if the
     * packet did not match any higher priority redirect
     * rule, then the traffic is redirected to the central
     * instance of the l3dgw_port. */
    Some{var gwport} = l3dgw_port in
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_GW_REDIRECT(),
         .priority         = 50,
         .__match          = "outport == ${json_string_escape(gwport.name)}",
         .actions          = "outport = ${redirect_port_name}; next;",
         .external_ids     = stage_hint(gwport._uuid));

    /* Packets are allowed by default. */
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_GW_REDIRECT(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "next;",
         .external_ids     = map_empty())
}

/* Local router ingress table ARP_REQUEST: ARP request.
 *
 * In the common case where the Ethernet destination has been resolved,
 * this table outputs the packet (priority 0).  Otherwise, it composes
 * and sends an ARP/IPv6 NA request (priority 100). */
Flow(.logical_datapath = router.lr._uuid,
     .stage            = s_ROUTER_IN_ARP_REQUEST(),
     .priority         = 200,
     .__match          = __match,
     .actions          = actions,
     .external_ids     = map_empty()) :-
    rsr in RouterStaticRoute(.router = &router),
    var dst = FlatMap(rsr.dsts),
    IPv6{var gw_ip6} = dst.nexthop,
    var __match = "eth.dst == 00:00:00:00:00:00 && "
                  "ip6 && xx${rEG_NEXT_HOP()} == ${dst.nexthop}",
    var sn_addr = gw_ip6.solicited_node(),
    var eth_dst = sn_addr.multicast_to_ethernet(),
    var sn_addr_s = sn_addr.string_mapped(),
    var actions = "nd_ns { "
                  "eth.dst = ${eth_dst}; "
                  "ip6.dst = ${sn_addr_s}; "
                  "nd.target = ${dst.nexthop}; "
                  "output; "
                  "};".

for (&Router(.lr = lr))
{
    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_ARP_REQUEST(),
         .priority         = 100,
         .__match          = "eth.dst == 00:00:00:00:00:00 && ip4",
         .actions          = "arp { "
                             "eth.dst = ff:ff:ff:ff:ff:ff; "
                             "arp.spa = ${rEG_SRC()}; "
                             "arp.tpa = ${rEG_NEXT_HOP()}; "
                             "arp.op = 1; " /* ARP request */
                             "output; "
                             "};",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_ARP_REQUEST(),
         .priority         = 100,
         .__match          = "eth.dst == 00:00:00:00:00:00 && ip6",
         .actions          = "nd_ns { "
                             "nd.target = xx${rEG_NEXT_HOP()}; "
                             "output; "
                             "};",
         .external_ids     = map_empty());

    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_IN_ARP_REQUEST(),
         .priority         = 0,
         .__match          = "1",
         .actions          = "output;",
         .external_ids     = map_empty())
}


/* Logical router egress table DELIVERY: Delivery (priority 100).
 *
 * Priority 100 rules deliver packets to enabled logical ports. */
for (&RouterPort(.lrp = lrp,
                 .json_name = json_name,
                 .networks = lrp_networks,
                 .router = &Router{.lr = lr, .mcast_cfg = &mcast_cfg})
     /* Drop packets to disabled logical ports (since logical flow
      * tables are default-drop). */
     if lrp.is_enabled())
{
    /* If multicast relay is enabled then also adjust source mac for IP
     * multicast traffic.
     */
    if (mcast_cfg.relay) {
        Flow(.logical_datapath = lr._uuid,
             .stage            = s_ROUTER_OUT_DELIVERY(),
             .priority         = 110,
             .__match          = "(ip4.mcast || ip6.mcast) && "
                                 "outport == ${json_name}",
             .actions          = "eth.src = ${lrp_networks.ea}; output;",
             .external_ids     = stage_hint(lrp._uuid))
    };
    /* No egress packets should be processed in the context of
     * a chassisredirect port.  The chassisredirect port should
     * be replaced by the l3dgw port in the local output
     * pipeline stage before egress processing. */

    Flow(.logical_datapath = lr._uuid,
         .stage            = s_ROUTER_OUT_DELIVERY(),
         .priority         = 100,
         .__match          = "outport == ${json_name}",
         .actions          = "output;",
         .external_ids     = stage_hint(lrp._uuid))
}

/*
 * Datapath tunnel key allocation:
 *
 * Allocates a globally unique tunnel id in the range 1...2**24-1 for
 * each Logical_Switch and Logical_Router.
 */

function oVN_MAX_DP_KEY(): integer { (64'd1 << 24) - 1 }
function oVN_MAX_DP_GLOBAL_NUM(): integer { (64'd1 << 16) - 1 }
function oVN_MIN_DP_KEY_LOCAL(): integer { 1 }
function oVN_MAX_DP_KEY_LOCAL(): integer { oVN_MAX_DP_KEY() - oVN_MAX_DP_GLOBAL_NUM() }
function oVN_MIN_DP_KEY_GLOBAL(): integer { oVN_MAX_DP_KEY_LOCAL() + 1 }
function oVN_MAX_DP_KEY_GLOBAL(): integer { oVN_MAX_DP_KEY() }

function oVN_MAX_DP_VXLAN_KEY(): integer { (64'd1 << 12) - 1 }
function oVN_MAX_DP_VXLAN_KEY_LOCAL(): integer { oVN_MAX_DP_KEY() - oVN_MAX_DP_GLOBAL_NUM() }

/* If any chassis uses VXLAN encapsulation, then the entire deployment is in VXLAN mode. */
relation IsVxlanMode0()
IsVxlanMode0() :-
    sb::Chassis(.encaps = encaps),
    var encap_uuid = FlatMap(encaps),
    sb::Encap(._uuid = encap_uuid, .__type = "vxlan").

relation IsVxlanMode[bool]
IsVxlanMode[true] :-
    IsVxlanMode0().
IsVxlanMode[false] :-
    Unit(),
    not IsVxlanMode0().

/* The maximum datapath tunnel key that may be used. */
relation OvnMaxDpKeyLocal[integer]
/* OVN_MAX_DP_GLOBAL_NUM doesn't apply for vxlan mode. */
OvnMaxDpKeyLocal[oVN_MAX_DP_VXLAN_KEY()] :- IsVxlanMode[true].
OvnMaxDpKeyLocal[oVN_MAX_DP_KEY() - oVN_MAX_DP_GLOBAL_NUM()] :- IsVxlanMode[false].

function get_dp_tunkey(map: Map<string,string>, key: string): Option<integer> {
    map.get(key)
       .and_then(parse_dec_u64)
       .and_then(|x| if (x > 0 and x < (2<<24)) {
                         Some{x}
                     } else {
                         None
                     })
}

// Tunnel keys requested by datapaths.
relation RequestedTunKey(datapath: uuid, tunkey: integer)
RequestedTunKey(uuid, tunkey) :-
    ls in nb::Logical_Switch(._uuid = uuid),
    Some{var tunkey} = get_dp_tunkey(ls.other_config, "requested-tnl-key").
RequestedTunKey(uuid, tunkey) :-
    lr in nb::Logical_Router(._uuid = uuid),
    Some{var tunkey} = get_dp_tunkey(lr.options, "requested-tnl-key").
Warning[message] :-
    RequestedTunKey(datapath, tunkey),
    var count = datapath.group_by((tunkey)).size(),
    count > 1,
    var message = "${count} logical switches or routers request "
                  "datapath tunnel key ${tunkey}".

// Assign tunnel keys:
// - First priority to requested tunnel keys.
// - Second priority to already assigned tunnel keys.
// In either case, make an arbitrary choice in case of conflicts within a
// priority level.
relation AssignedTunKey(datapath: uuid, tunkey: integer)
AssignedTunKey(datapath, tunkey) :-
    RequestedTunKey(datapath, tunkey),
    var datapath = datapath.group_by(tunkey).first().
AssignedTunKey(datapath, tunkey) :-
    sb::Datapath_Binding(._uuid = datapath, .tunnel_key = tunkey),
    not RequestedTunKey(_, tunkey),
    not RequestedTunKey(datapath, _),
    var datapath = datapath.group_by(tunkey).first().

// all tunnel keys already in use in the Realized table
relation AllocatedTunKeys(keys: Set<integer>)
AllocatedTunKeys(keys) :-
    AssignedTunKey(.tunkey = tunkey),
    var keys = tunkey.group_by(()).to_set().

// Datapath_Binding's not yet in the Realized table
relation NotYetAllocatedTunKeys(datapaths: Vec<uuid>)

NotYetAllocatedTunKeys(datapaths) :-
    OutProxy_Datapath_Binding(._uuid = datapath),
    not AssignedTunKey(datapath, _),
    var datapaths = datapath.group_by(()).to_vec().

// Perform the allocation
relation TunKeyAllocation(datapath: uuid, tunkey: integer)

TunKeyAllocation(datapath, tunkey) :- AssignedTunKey(datapath, tunkey).

// Case 1: AllocatedTunKeys relation is not empty (i.e., contains
// a single record that stores a set of allocated keys)
TunKeyAllocation(datapath, tunkey) :-
    NotYetAllocatedTunKeys(unallocated),
    AllocatedTunKeys(allocated),
    OvnMaxDpKeyLocal[max_dp_key_local],
    var allocation = FlatMap(allocate(allocated, unallocated, 1, max_dp_key_local)),
    (var datapath, var tunkey) = allocation.

// Case 2: AllocatedTunKeys relation is empty
TunKeyAllocation(datapath, tunkey) :-
    NotYetAllocatedTunKeys(unallocated),
    not AllocatedTunKeys(_),
    OvnMaxDpKeyLocal[max_dp_key_local],
    var allocation = FlatMap(allocate(set_empty(), unallocated, 1, max_dp_key_local)),
    (var datapath, var tunkey) = allocation.

/*
 * Port id allocation:
 *
 * Port IDs in a per-datapath space in the range 1...2**15-1
 */

function get_port_tunkey(map: Map<string,string>, key: string): Option<integer> {
    map.get(key)
       .and_then(parse_dec_u64)
       .and_then(|x| if (x > 0 and x < (2<<15)) {
                         Some{x}
                     } else {
                         None
                     })
}

// Tunnel keys requested by port bindings.
relation RequestedPortTunKey(datapath: uuid, port: uuid, tunkey: integer)
RequestedPortTunKey(datapath, port, tunkey) :-
    sp in &SwitchPort(),
    var datapath = sp.sw.ls._uuid,
    var port = sp.lsp._uuid,
    Some{var tunkey} = get_port_tunkey(sp.lsp.options, "requested-tnl-key").
RequestedPortTunKey(datapath, port, tunkey) :-
    rp in &RouterPort(),
    var datapath = rp.router.lr._uuid,
    var port = rp.lrp._uuid,
    Some{var tunkey} = get_port_tunkey(rp.lrp.options, "requested-tnl-key").
Warning[message] :-
    RequestedPortTunKey(datapath, port, tunkey),
    var count = port.group_by((datapath, tunkey)).size(),
    count > 1,
    var message = "${count} logical ports in the same datapath "
                  "request port tunnel key ${tunkey}".

// Assign tunnel keys:
// - First priority to requested tunnel keys.
// - Second priority to already assigned tunnel keys.
// In either case, make an arbitrary choice in case of conflicts within a
// priority level.
relation AssignedPortTunKey(datapath: uuid, port: uuid, tunkey: integer)
AssignedPortTunKey(datapath, port, tunkey) :-
    RequestedPortTunKey(datapath, port, tunkey),
    var port = port.group_by((datapath, tunkey)).first().
AssignedPortTunKey(datapath, port, tunkey) :-
    sb::Port_Binding(._uuid = port_uuid,
                    .datapath = datapath,
                    .tunnel_key = tunkey),
    not RequestedPortTunKey(datapath, _, tunkey),
    not RequestedPortTunKey(datapath, port_uuid, _),
    var port = port_uuid.group_by((datapath, tunkey)).first().

// all tunnel keys already in use in the Realized table
relation AllocatedPortTunKeys(datapath: uuid, keys: Set<integer>)

AllocatedPortTunKeys(datapath, keys) :-
    AssignedPortTunKey(datapath, port, tunkey),
    var keys = tunkey.group_by(datapath).to_set().

// Port_Binding's not yet in the Realized table
relation NotYetAllocatedPortTunKeys(datapath: uuid, all_logical_ids: Vec<uuid>)

NotYetAllocatedPortTunKeys(datapath, all_names) :-
    OutProxy_Port_Binding(._uuid = port_uuid, .datapath = datapath),
    not AssignedPortTunKey(datapath, port_uuid, _),
    var all_names = port_uuid.group_by(datapath).to_vec().

// Perform the allocation.
relation PortTunKeyAllocation(port: uuid, tunkey: integer)

// Transfer existing allocations from the realized table.
PortTunKeyAllocation(port, tunkey) :- AssignedPortTunKey(_, port, tunkey).

// Case 1: AllocatedPortTunKeys(datapath) is not empty (i.e., contains
// a single record that stores a set of allocated keys).
PortTunKeyAllocation(port, tunkey) :-
    AllocatedPortTunKeys(datapath, allocated),
    NotYetAllocatedPortTunKeys(datapath, unallocated),
    var allocation = FlatMap(allocate(allocated, unallocated, 1, 64'hffff)),
    (var port, var tunkey) = allocation.

// Case 2: PortAllocatedTunKeys(datapath) relation is empty
PortTunKeyAllocation(port, tunkey) :-
    NotYetAllocatedPortTunKeys(datapath, unallocated),
    not AllocatedPortTunKeys(datapath, _),
    var allocation = FlatMap(allocate(set_empty(), unallocated, 1, 64'hffff)),
    (var port, var tunkey) = allocation.

/*
 * Multicast group tunnel_key allocation:
 *
 * Tunnel-keys in a per-datapath space in the range 32770...65535
 */

// All tunnel keys already in use in the Realized table.
relation AllocatedMulticastGroupTunKeys(datapath_uuid: uuid, keys: Set<integer>)

AllocatedMulticastGroupTunKeys(datapath_uuid, keys) :-
    sb::Multicast_Group(.datapath = datapath_uuid, .tunnel_key = tunkey),
    //sb::UUIDMap_Datapath_Binding(datapath, Left{datapath_uuid}),
    var keys = tunkey.group_by(datapath_uuid).to_set().

// Multicast_Group's not yet in the Realized table.
relation NotYetAllocatedMulticastGroupTunKeys(datapath_uuid: uuid,
                                              all_logical_ids: Vec<string>)

NotYetAllocatedMulticastGroupTunKeys(datapath_uuid, all_names) :-
    OutProxy_Multicast_Group(.name = name, .datapath = datapath_uuid),
    not sb::Multicast_Group(.name = name, .datapath = datapath_uuid),
    var all_names = name.group_by(datapath_uuid).to_vec().

// Perform the allocation
relation MulticastGroupTunKeyAllocation(datapath_uuid: uuid, group: string, tunkey: integer)

// transfer existing allocations from the realized table
MulticastGroupTunKeyAllocation(datapath_uuid, group, tunkey) :-
    //sb::UUIDMap_Datapath_Binding(_, datapath_uuid),
    sb::Multicast_Group(.name = group,
                       .datapath = datapath_uuid,
                       .tunnel_key = tunkey).

// Case 1: AllocatedMulticastGroupTunKeys(datapath) is not empty (i.e.,
// contains a single record that stores a set of allocated keys)
MulticastGroupTunKeyAllocation(datapath_uuid, group, tunkey) :-
    AllocatedMulticastGroupTunKeys(datapath_uuid, allocated),
    NotYetAllocatedMulticastGroupTunKeys(datapath_uuid, unallocated),
    (_, var min_key) = mC_IP_MCAST_MIN(),
    (_, var max_key) = mC_IP_MCAST_MAX(),
    var allocation = FlatMap(allocate(allocated, unallocated,
                                      min_key, max_key)),
    (var group, var tunkey) = allocation.

// Case 2: AllocatedMulticastGroupTunKeys(datapath) relation is empty
MulticastGroupTunKeyAllocation(datapath_uuid, group, tunkey) :-
    NotYetAllocatedMulticastGroupTunKeys(datapath_uuid, unallocated),
    not AllocatedMulticastGroupTunKeys(datapath_uuid, _),
    (_, var min_key) = mC_IP_MCAST_MIN(),
    (_, var max_key) = mC_IP_MCAST_MAX(),
    var allocation = FlatMap(allocate(set_empty(), unallocated,
                                      min_key, max_key)),
    (var group, var tunkey) = allocation.

/*
 * Queue ID allocation
 *
 * Queue IDs on a chassis, for routers that have QoS enabled, in a per-chassis
 * space in the range 1...0xf000.  It looks to me like there'd only be a small
 * number of these per chassis, and probably a small number overall, in case it
 * matters.
 *
 * Queue ID may also need to be deallocated if port loses QoS attributes
 *
 * This logic applies mainly to sb::Port_Binding records bound to a chassis
 * (i.e. with the chassis column nonempty) but "localnet" ports can also
 * have a queue ID.  For those we use the port's own UUID as the chassis UUID.
 */

function port_has_qos_params(opts: Map<string, string>): bool = {
    opts.contains_key("qos_max_rate") or opts.contains_key("qos_burst")
}


// ports in Out_Port_Binding that require queue ID on chassis
relation PortRequiresQID(port: uuid, chassis: uuid)

PortRequiresQID(pb._uuid, chassis) :-
    pb in OutProxy_Port_Binding(),
    pb.__type != "localnet",
    port_has_qos_params(pb.options),
    sb::Port_Binding(._uuid = pb._uuid, .chassis = chassis_set),
    Some{var chassis} = chassis_set.
PortRequiresQID(pb._uuid, pb._uuid) :-
    pb in OutProxy_Port_Binding(),
    pb.__type == "localnet",
    port_has_qos_params(pb.options),
    sb::Port_Binding(._uuid = pb._uuid).

relation AggPortRequiresQID(chassis: uuid, ports: Vec<uuid>)

AggPortRequiresQID(chassis, ports) :-
    PortRequiresQID(port, chassis),
    var ports = port.group_by(chassis).to_vec().

relation AllocatedQIDs(chassis: uuid, allocated_ids: Map<uuid, integer>)

AllocatedQIDs(chassis, allocated_ids) :-
    pb in sb::Port_Binding(),
    pb.__type != "localnet",
    Some{var chassis} = pb.chassis,
    Some{var qid_str} = pb.options.get("qdisc_queue_id"),
    Some{var qid} = parse_dec_u64(qid_str),
    var allocated_ids = (pb._uuid, qid).group_by(chassis).to_map().
AllocatedQIDs(chassis, allocated_ids) :-
    pb in sb::Port_Binding(),
    pb.__type == "localnet",
    var chassis = pb._uuid,
    Some{var qid_str} = pb.options.get("qdisc_queue_id"),
    Some{var qid} = parse_dec_u64(qid_str),
    var allocated_ids = (pb._uuid, qid).group_by(chassis).to_map().

// allocate queue IDs to ports
relation QueueIDAllocation(port: uuid, qids: Option<integer>)

// None for ports that do not require a queue
QueueIDAllocation(port, None) :-
    OutProxy_Port_Binding(._uuid = port),
    not PortRequiresQID(port, _).

QueueIDAllocation(port, Some{qid}) :-
    AggPortRequiresQID(chassis, ports),
    AllocatedQIDs(chassis, allocated_ids),
    var allocations = FlatMap(adjust_allocation(allocated_ids, ports, 1, 64'hf000)),
    (var port, var qid) = allocations.

QueueIDAllocation(port, Some{qid}) :-
    AggPortRequiresQID(chassis, ports),
    not AllocatedQIDs(chassis, _),
    var allocations = FlatMap(adjust_allocation(map_empty(), ports, 1, 64'hf000)),
    (var port, var qid) = allocations.

/*
 * This allows ovn-northd to preserve options:ipv6_ra_pd_list, which is set by
 * ovn-controller.
 */
relation PreserveIPv6RAPDList(lrp_uuid: uuid, ipv6_ra_pd_list: Option<string>)
PreserveIPv6RAPDList(lrp_uuid, ipv6_ra_pd_list) :-
    sb::Port_Binding(._uuid = lrp_uuid, .options = options),
    var ipv6_ra_pd_list = options.get("ipv6_ra_pd_list").
PreserveIPv6RAPDList(lrp_uuid, None) :-
    nb::Logical_Router_Port(._uuid = lrp_uuid),
    not sb::Port_Binding(._uuid = lrp_uuid).

/*
 * Tag allocation for nested containers.
 */

/* Reserved tags for each parent port, including:
 * 1. For ports that need a dynamically allocated tag, existing tag, if any,
 * 2. For ports that have a statically assigned tag (via `tag_request`), the
 *    `tag_request` value.
 * 3. For ports that do not have a tag_request, but have a tag statically assigned
 *    by directly setting the `tag` field, use this value.
 */
relation SwitchPortReservedTag(parent_name: string, tags: integer)

SwitchPortReservedTag(parent_name, tag) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = needs_dynamic_tag, .parent_name = Some{parent_name}),
    Some{var tag} = if (needs_dynamic_tag) {
        lsp.tag
    } else {
        match (lsp.tag_request) {
            Some{req} -> Some{req},
            None      -> lsp.tag
        }
    }.

relation SwitchPortReservedTags(parent_name: string, tags: Set<integer>)

SwitchPortReservedTags(parent_name, tags) :-
    SwitchPortReservedTag(parent_name, tag),
    var tags = tag.group_by(parent_name).to_set().

SwitchPortReservedTags(parent_name, set_empty()) :-
    nb::Logical_Switch_Port(.name = parent_name),
    not SwitchPortReservedTag(.parent_name = parent_name).

/* Allocate tags for ports that require dynamically allocated tags and do not
 * have any yet.
 */
relation SwitchPortAllocatedTags(lsp_uuid: uuid, tag: Option<integer>)

SwitchPortAllocatedTags(lsp_uuid, tag) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = true, .parent_name = Some{parent_name}),
    lsp.tag == None,
    var lsps_need_tag = lsp._uuid.group_by(parent_name).to_vec(),
    SwitchPortReservedTags(parent_name, reserved),
    var dyn_tags = allocate_opt(reserved,
                                lsps_need_tag,
                                1, /* Tag 0 is invalid for nested containers. */
                                4095),
    var lsp_tag = FlatMap(dyn_tags),
    (var lsp_uuid, var tag) = lsp_tag.

/* New tag-to-port assignment:
 * Case 1. Statically reserved tag (via `tag_request`), if any.
 * Case 2. Existing tag for ports that require a dynamically allocated tag and already have one.
 * Case 3. Use newly allocated tags (from `SwitchPortAllocatedTags`) for all other ports.
 */
relation SwitchPortNewDynamicTag(port: uuid, tag: Option<integer>)

/* Case 1 */
SwitchPortNewDynamicTag(lsp._uuid, tag) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = false),
    var tag = match (lsp.tag_request) {
        Some{0} -> None,
        treq    -> treq
    }.

/* Case 2 */
SwitchPortNewDynamicTag(lsp._uuid, Some{tag}) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = true),
    Some{var tag} = lsp.tag.

/* Case 3 */
SwitchPortNewDynamicTag(lsp._uuid, tag) :-
    &SwitchPort(.lsp = lsp, .needs_dynamic_tag = true),
    lsp.tag == None,
    SwitchPortAllocatedTags(lsp._uuid, tag).

/* IP_Multicast table (only applicable for Switches). */
sb::Out_IP_Multicast(._uuid = cfg.datapath,
                    .datapath = cfg.datapath,
                    .enabled = Some{cfg.enabled},
                    .querier = Some{cfg.querier},
                    .eth_src = cfg.eth_src,
                    .ip4_src = cfg.ip4_src,
                    .ip6_src = cfg.ip6_src,
                    .table_size = Some{cfg.table_size},
                    .idle_timeout = Some{cfg.idle_timeout},
                    .query_interval = Some{cfg.query_interval},
                    .query_max_resp = Some{cfg.query_max_resp}) :-
    &McastSwitchCfg[cfg].


relation PortExists(name: string)
PortExists(name) :- nb::Logical_Switch_Port(.name = name).
PortExists(name) :- nb::Logical_Router_Port(.name = name).

sb::Out_Load_Balancer(._uuid = lb._uuid,
                      .name = lb.name,
                      .vips = lb.vips,
                      .protocol = lb.protocol,
                      .datapaths = datapaths,
                      .external_ids = ["lb_id" -> uuid2str(lb_uuid)],
                      .options = options) :-
    nb in nb::Logical_Switch(._uuid = ls_uuid, .load_balancer = lb_uuids),
    var lb_uuid = FlatMap(lb_uuids),
    var datapaths = ls_uuid.group_by(lb_uuid).to_set(),
    lb in nb::Load_Balancer(._uuid = lb_uuid),
    /* Store the fact that northd provides the original (destination IP +
     * transport port) tuple.
     */
    var options = lb.options.insert_imm("hairpin_orig_tuple", "true").

sb::Out_Service_Monitor(._uuid = hash128((svc_monitor.port_name, lbvipbackend.ip, lbvipbackend.port, protocol)),
                       .ip = "${lbvipbackend.ip}",
                       .protocol = Some{protocol},
                       .port = lbvipbackend.port as integer,
                       .logical_port = svc_monitor.port_name,
                       .src_mac = to_string(svc_monitor_mac),
                       .src_ip = svc_monitor.src_ip,
                       .options = health_check.options,
                       .external_ids = map_empty()) :-
    SvcMonitorMac(svc_monitor_mac),
    LBVIP[lbvip@&LBVIP{.lb = lb}],
    Some{var health_check} = lbvip.health_check,
    var lbvipbackend = FlatMap(lbvip.backends),
    Some{var svc_monitor} = lbvipbackend.svc_monitor,
    PortExists(svc_monitor.port_name),
    var protocol = default_protocol(lb.protocol),
    protocol != "sctp".

Warning["SCTP load balancers do not currently support "
        "health checks. Not creating health checks for "
        "load balancer ${uuid2str(lb._uuid)}"] :-
    LBVIP[lbvip@&LBVIP{.lb = lb}],
    default_protocol(lb.protocol) == "sctp",
    Some{var health_check} = lbvip.health_check,
    var lbvipbackend = FlatMap(lbvip.backends),
    Some{var svc_monitor} = lbvipbackend.svc_monitor.

/*
 * BFD table.
 */

/*
 * BFD source port allocation.
 *
 * We need to assign a unique source port to each (logical_port, dst_ip) pair.
 * RFC 5881 section 4 says:
 *
 *   The source port MUST be in the range 49152 through 65535.
 *   The same UDP source port number MUST be used for all BFD
 *   Control packets associated with a particular session.
 *   The source port number SHOULD be unique among all BFD
 *   sessions on the system
 */
function bFD_UDP_SRC_PORT_MIN(): integer { 49152 }
function bFD_UDP_SRC_PORT_MAX(): integer { 65535 }

// Get already assigned BFD source ports.
// If there's a conflict, make an arbitrary choice.
relation AssignedSrcPort(
    logical_port: string,
    dst_ip: string,
    src_port: integer)
AssignedSrcPort(logical_port, dst_ip, src_port) :-
    sb::BFD(.logical_port = logical_port, .dst_ip = dst_ip, .src_port = src_port),
    var pair = (logical_port, dst_ip).group_by(src_port).first(),
    (var logical_port, var dst_ip) = pair.

// All source ports already in use.
relation AllocatedSrcPorts0(src_ports: Set<integer>)
AllocatedSrcPorts0(src_ports) :-
    AssignedSrcPort(.src_port = src_port),
    var src_ports = src_port.group_by(()).to_set().

relation AllocatedSrcPorts(src_ports: Set<integer>)
AllocatedSrcPorts(src_ports) :- AllocatedSrcPorts0(src_ports).
AllocatedSrcPorts(set_empty()) :- Unit(), not AllocatedSrcPorts0(_).

// (logical_port, dst_ip) pairs not yet in the Realized table
relation NotYetAllocatedSrcPorts(pairs: Vec<(string, string)>)
NotYetAllocatedSrcPorts(pairs) :-
    nb::BFD(.logical_port = logical_port, .dst_ip = dst_ip),
    not AssignedSrcPort(logical_port, dst_ip, _),
    var pairs = (logical_port, dst_ip).group_by(()).to_vec().

// Perform the allocation
relation SrcPortAllocation(
    logical_port: string,
    dst_ip: string,
    src_port: integer)
SrcPortAllocation(logical_port, dst_ip, src_port) :- AssignedSrcPort(logical_port, dst_ip, src_port).
SrcPortAllocation(logical_port, dst_ip, src_port) :-
    NotYetAllocatedSrcPorts(unallocated),
    AllocatedSrcPorts(allocated),
    var allocation = FlatMap(allocate(allocated, unallocated,
                                      bFD_UDP_SRC_PORT_MIN(), bFD_UDP_SRC_PORT_MAX())),
    ((var logical_port, var dst_ip), var src_port) = allocation.

relation SouthboundBFDStatus(
    logical_port: string,
    dst_ip: string,
    status: Option<string>
)
SouthboundBFDStatus(bfd.logical_port, bfd.dst_ip, Some{bfd.status}) :- bfd in sb::BFD().
SouthboundBFDStatus(logical_port, dst_ip, None) :-
    nb::BFD(.logical_port = logical_port, .dst_ip = dst_ip),
    not sb::BFD(.logical_port = logical_port, .dst_ip = dst_ip).

function bFD_DEF_MINTX(): integer { 1000 } // 1 second
function bFD_DEF_MINRX(): integer { 1000 } // 1 second
function bFD_DEF_DETECT_MULT(): integer { 5 }
sb::Out_BFD(._uuid = hash,
            .src_port = src_port,
            .disc = max(1, hash as u32) as integer,
            .logical_port = nb.logical_port,
            .dst_ip = nb.dst_ip,
            .min_tx = nb.min_tx.unwrap_or(bFD_DEF_MINTX()),
            .min_rx = nb.min_rx.unwrap_or(bFD_DEF_MINRX()),
            .detect_mult = nb.detect_mult.unwrap_or(bFD_DEF_DETECT_MULT()),
            .status = status,
            .external_ids = map_empty(),
            .options = ["nb_status" -> nb.status.unwrap_or(""),
                        "sb_status" -> sb_status.unwrap_or(""),
                        "referenced" -> referenced.to_string()]) :-
    nb in nb::BFD(),
    SrcPortAllocation(nb.logical_port, nb.dst_ip, src_port),
    SouthboundBFDStatus(nb.logical_port, nb.dst_ip, sb_status),
    BFDReferenced(nb._uuid, referenced),
    var status = bfd_new_status(referenced, nb.status, sb_status).1,
    var hash = hash128((nb.logical_port, nb.dst_ip)).

relation BFDReferenced0(bfd_uuid: uuid)
BFDReferenced0(bfd_uuid) :-
    nb::Logical_Router_Static_Route(.bfd = Some{bfd_uuid}, .nexthop = nexthop),
    nb::BFD(._uuid = bfd_uuid, .dst_ip = nexthop).

relation BFDReferenced(bfd_uuid: uuid, referenced: bool)
BFDReferenced(bfd_uuid, true) :- BFDReferenced0(bfd_uuid).
BFDReferenced(bfd_uuid, false) :-
    nb::BFD(._uuid = bfd_uuid),
    not BFDReferenced0(bfd_uuid).

// Given the following:
//    - 'referenced': whether a BFD object is referenced by a route
//    - 'nb_status0': 'status' in the existing nb::BFD record
//    - 'sb_status0': 'status' in the existing sb::BFD record (None, if none exists yet)
// computes and returns (nb_status, sb_status), which are the values to use next in these records
function bfd_new_status(referenced: bool,
                        nb_status0: Option<string>,
                        sb_status0: Option<string>): (string, string) {
    var nb_status = nb_status0.unwrap_or("admin_down");
    match (sb_status0) {
        Some{sb_status} -> if (nb_status != "admin_down" and sb_status != "admin_down") {
                               nb_status = sb_status
                           },
        _ -> ()
    };
    var sb_status = nb_status;
    if (referenced) {
        if (nb_status == "admin_down") {
            nb_status = "down"
        }
    } else {
        nb_status = "admin_down"
    };
    warn("nb_status=${nb_status} sb_status=${sb_status} referenced=${referenced}");
    (nb_status, sb_status)
}
nb::Out_BFD(bfd_uuid, Some{status}) :-
    nb in nb::BFD(._uuid = bfd_uuid),
    BFDReferenced(bfd_uuid, referenced),
    SouthboundBFDStatus(nb.logical_port, nb.dst_ip, sb_status),
    var status = bfd_new_status(referenced, nb.status, sb_status).0.

/*
 * Logical router BFD flows
 */

function lrouter_bfd_flows(lr_uuid: uuid, lrp_uuid: uuid, ipX: string, networks: string)
    : (Flow, Flow)
{
    (Flow{.logical_datapath = lr_uuid,
          .stage            = s_ROUTER_IN_IP_INPUT(),
          .priority         = 110,
          .__match          = "${ipX}.src == ${networks} && udp.dst == 3784",
          .actions          = "next; ",
          .external_ids     = stage_hint(lrp_uuid)},
     Flow{.logical_datapath = lr_uuid,
          .stage            = s_ROUTER_IN_IP_INPUT(),
          .priority         = 110,
          .__match          = "${ipX}.dst == ${networks} && udp.dst == 3784",
          .actions          = "handle_bfd_msg(); ",
          .external_ids     = stage_hint(lrp_uuid)})
}
for (&RouterPort(.router = &router, .networks = networks, .lrp = lrp, .has_bfd = true)) {
    if (not networks.ipv4_addrs.is_empty()) {
        (var a, var b) = lrouter_bfd_flows(router.lr._uuid, lrp._uuid, "ip4",
                                           format_v4_networks(networks, false)) in {
            Flow[a];
            Flow[b]
        }
    };

    if (not networks.ipv6_addrs.is_empty()) {
        (var a, var b) = lrouter_bfd_flows(router.lr._uuid, lrp._uuid, "ip6",
                                           format_v6_networks(networks)) in {
            Flow[a];
            Flow[b]
        }
    }
}    
                                          
/* Clean up stale FDB entries. */
sb::Out_FDB(_uuid, mac, dp_key, port_key) :-
    sb::FDB(_uuid, mac, dp_key, port_key),
    sb::Out_Datapath_Binding(._uuid = dp_uuid, .tunnel_key = dp_key),
    sb::Out_Port_Binding(.datapath = dp_uuid, .tunnel_key = port_key).
